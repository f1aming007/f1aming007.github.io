[{"categories":["文档"],"content":"Kubernetes 的 Limits 和 Requests 在k8s适应容器时， 要知道所涉及的资源时什么以及如何需要他们，有些进程比其他进程需要更多的CPU和内存 知道这些之后， 才能正确的配置我们的容器和pod Kubernetes 的Limits和Requests介绍 实践案例 Kubernetes Requests Kubernetes Limits CPU的特殊性 内存的特殊性 Namespace ResourceQuta Namespace LimitRange 总结 ","date":"2023-10-24","objectID":"/k8s_limit_quests/:0:0","tags":["k8s"],"title":"K8s_limit_quests","uri":"/k8s_limit_quests/"},{"categories":["文档"],"content":"Jsonparser 开源的JSON包 号称比JSON包性能高10倍，内存分配优化到0，提高JSON操作的性能 jsonparser 的性能在很大程度上取决于使用情况，当不需要处理完成记录而只需要处理某几个字段时（尤其是访问第三方接口时，大多数情况下只需要几个字段）性能表现的非常好 ","date":"2023-08-11","objectID":"/golang-jsonparser/:0:0","tags":["golang","go第三方库"],"title":"Golang Jsonparser","uri":"/golang-jsonparser/"},{"categories":["文档"],"content":"方法对应关系 jsonparser标准库JSON工作方式不同，不会 编码/解码 整个数据结构， 而是按需操作 标准库 jsonparser 编码 Marshal Set 解码 Unmarshal Get jsonparser 在Get 的基础上封装了很多针对单个字段的使用方法，例如 package main import ( \"fmt\" \"log\" \"github.com/buger/jsonparser\" ) var ( // JSON 字符串 dataJson = []byte(` { \"person\": { \"name\": { \"first\": \"Leonid\", \"last\": \"Bugaev\", \"fullName\": \"Leonid Bugaev\" }, \"github\": { \"handle\": \"buger\", \"followers\": 109 }, \"avatars\": [ { \"url\": \"https://avatars1.githubusercontent.com/u/14009?v=3\u0026s=460\", \"type\": \"thumbnail\" } ] }, \"company\": { \"name\": \"Acme\" } } `) ) func main() { // 解析对象 github := struct { Handle string `json:\"handle\"` Followers int `json:\"followers\"` }{} err := jsonparser.ObjectEach(dataJson, func(key []byte, value []byte, dataType jsonparser.ValueType, offset int) error { switch string(key) { case \"handle\": github.Handle = string(value) case \"followers\": followers, _ := jsonparser.ParseInt(value) github.Followers = int(followers) } return nil }, \"person\", \"github\") if err != nil { log.Fatal(err) } fmt.Printf(\"github = %+v\\n\\n\", github) // 编码结构体 githubJson, err := jsonparser.Set([]byte(`{}`), []byte(fmt.Sprintf(`{\"handle: %s\", \"followers\": \"%d\"}`, github.Handle, github.Followers)), \"github\") if err != nil { log.Fatal(err) } fmt.Printf(\"github json = %s\\n\\n\", githubJson) // 解析多个 key paths := [][]string{ {\"person\", \"name\", \"fullName\"}, {\"person\", \"avatars\", \"[0]\", \"url\"}, {\"company\", \"name\"}, } jsonparser.EachKey(dataJson, func(i int, bytes []byte, valueType jsonparser.ValueType, err error) { switch i { case 0: fmt.Printf(\"fullName = %s\\n\", bytes) case 1: fmt.Printf(\"avatars[0].url = %s\\n\", bytes) case 2: fmt.Printf(\"company.name = %s\\n\\n\", bytes) } }, paths...) // 解析整数 n, err := jsonparser.GetInt(dataJson, \"person\", \"github\", \"followers\") if err != nil { log.Fatal(err) } fmt.Printf(\"n = %d\\n\\n\", n) // 解析字符串 name, err := jsonparser.GetString(dataJson, \"company\", \"name\") if err != nil { log.Fatal(err) } fmt.Printf(\"name = %s\\n\", name) } ","date":"2023-08-11","objectID":"/golang-jsonparser/:1:0","tags":["golang","go第三方库"],"title":"Golang Jsonparser","uri":"/golang-jsonparser/"},{"categories":["文档"],"content":"代码实现 jsonparser 的核心代码全部放在了一个文件中 parser.go, 我们主要关注两种操作的实现: 解码GET 和 编码Set ","date":"2023-08-11","objectID":"/golang-jsonparser/:2:0","tags":["golang","go第三方库"],"title":"Golang Jsonparser","uri":"/golang-jsonparser/"},{"categories":["文档"],"content":"数据类型 jsonparser 将合法的JSON数据类型简单进行常量映射 // JSON 数据类型常量 type ValueType int const ( NotExist = ValueType(iota) String Number Object Array Boolean Null Unknown ) 为了规避 GC, 用于 JSON 字符串转义分配的 []byte 切片容量上限，超过这个上限值后，转义结果会被分配到 堆上 引发 GC， 也就是 []byte 切片的长度超过 64 之后，会被分配到 堆上 // 规避 GC 的切片容量上限常量 const unescapeStackBufSize = 64 ","date":"2023-08-11","objectID":"/golang-jsonparser/:2:1","tags":["golang","go第三方库"],"title":"Golang Jsonparser","uri":"/golang-jsonparser/"},{"categories":["文档"],"content":"辅助方法 stringEnd 尝试寻找当前字符串的结尾，也就是 “, 支持转义的情况，例如 \" func stringEnd(data []byte) (int, bool) {} blockEnd 尝试寻找当前数组或对象的结尾，数组的开始和结尾表示为 [ 和 ], 对象的开始和结尾表示为 { 和 }。 func blockEnd(data []byte, openSym byte, closeSym byte) int {} ","date":"2023-08-11","objectID":"/golang-jsonparser/:3:0","tags":["golang","go第三方库"],"title":"Golang Jsonparser","uri":"/golang-jsonparser/"},{"categories":["文档"],"content":"searchKeys 状态机 searchKeys 方法是整个 解析操作 的核心方法，内部实现类似于 有限状态机 机制，通过将 JSON 字符串作为输入参数，并根据定义的状态转换规则逐个解析字符， 结果返回解析到的索引，或者 -1 (解析失败)。 ","date":"2023-08-11","objectID":"/golang-jsonparser/:4:0","tags":["golang","go第三方库"],"title":"Golang Jsonparser","uri":"/golang-jsonparser/"},{"categories":["文档"],"content":"状态机组成部分 输入参数： 存储解析的JSON字符串 解析器： 解析 JSON 字符串并返回相应的数据结构 (searchKeys 方法返回的是 []byte) 状态转移表： 定义状态转换规则，包括当前状态、下一个字符以及下一个状态 (searchKeys 主要是通过上面提到的辅助方法来完成的) 状态栈 : 记录状态转换过程中的状态 (searchKeys 用了几个变量来记录状态，例如 keyLevel, level, ln, lk 等) ","date":"2023-08-11","objectID":"/golang-jsonparser/:4:1","tags":["golang","go第三方库"],"title":"Golang Jsonparser","uri":"/golang-jsonparser/"},{"categories":["文档"],"content":"单例模式 单例模式宏观介绍 饿汉式单例模式实现思路 懒汉式单例模式实现推演 Golang 单例工具 sync.Once 源码解析 单例模式背景 在单例模式下， 声明一个类并保证这个类只存在全局唯一的实例供外部反复使用 单例模式的适用场景 一些只允许存在一个实例的类，比如全局统一的监控统计模块。 一些实例化很耗费资源的类，比如协程池、连接池、和第三方交互的客户端等 一些入参复杂的系统模块组件，比如 controller、service、dao等 ","date":"2023-08-05","objectID":"/golang-%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F/:0:0","tags":["golang"],"title":"Golang 设计模式 单例模式","uri":"/golang-%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F/"},{"categories":["文档"],"content":"实现模式 在单例模式的实现上， 可以分为饿汉式和懒汉式两种类型 饿汉式： 从一开始就完成单例的初始化工作， 以备不时只需 懒汉式： 贯彻佛系思想，不到逼不得已（需要被使用了），不执行单例的初始化工作 ","date":"2023-08-05","objectID":"/golang-%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F/:1:0","tags":["golang"],"title":"Golang 设计模式 单例模式","uri":"/golang-%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F/"},{"categories":["文档"],"content":"饿汉式单例模式 “饿” 指的是，对于单例对象而言，不论其后续有没有被使用到以及何时才会被使用到，都会在程序启动之初完成其初始化工作. 饿汉式单例模式的执行步骤 单例类和构建方法声明为不可导出类型，避免被外部直接获取到 在代码启动之初，酒初始化一个全局单一的实例， 作为后续所谓的“单例” 暴露一个可倒出的单例获取方法，GetXXX()，用于返回这个单例对象 ","date":"2023-08-05","objectID":"/golang-%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F/:2:0","tags":["golang"],"title":"Golang 设计模式 单例模式","uri":"/golang-%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F/"},{"categories":["文档"],"content":"Iota 介绍 在常量声明中，预先声明的标识符iota代表连续的无类型的整数常量， 他的值是该常量声明中对应ConstSpec的索引，从零开始计数。 iota： 可以在常量声明中自动创建一系列连续的整数值，值从零开始， 不需要手动指定每个常量的值 ","date":"2023-08-05","objectID":"/golang-iota/:0:0","tags":["golang"],"title":"Golang Iota","uri":"/golang-iota/"},{"categories":["文档"],"content":"iota的应用场景 ","date":"2023-08-05","objectID":"/golang-iota/:1:0","tags":["golang"],"title":"Golang Iota","uri":"/golang-iota/"},{"categories":["文档"],"content":"自动生成递增的常量值 iota 可以方便生成递增的常量值， 在常量声明中的第一个使用iota的常量初始化未0， 而后的常量都会自动递增，这是得在定义一组递增常量时无需手动指定每个常量的值， 提高了代码的 可读性和维护性 const ( Apple = iota // 0 Banana // 1 Cherry // 2 ) ","date":"2023-08-05","objectID":"/golang-iota/:1:1","tags":["golang"],"title":"Golang Iota","uri":"/golang-iota/"},{"categories":["文档"],"content":"构建枚举类型常量 使用iota 可以轻松定义一系列相关的枚举值， 而无需为每个值手动指定具体的数字，这样的枚举类型定义更加简洁，易于扩展和修改 type WeekDay int const ( Sunday WeekDay = iota // 0 Tuesday // 1 Wednesday // 2 Thursday // 3 Friday // 4 Saturday // 5 Monday // 6 ) ","date":"2023-08-05","objectID":"/golang-iota/:1:2","tags":["golang"],"title":"Golang Iota","uri":"/golang-iota/"},{"categories":["文档"],"content":"表达式计算 通过在常量声明中使用iota， 可以创建复杂的表达式， 并在每个常量表达式中， 根据需要调整iota的值， 可以轻松生成一组具有特定规律的常量 const ( _ = iota KB = 1 \u003c\u003c (10 * iota) // 1 \u003c\u003c (10 * 1) = 1024B = 1KB MB = 1 \u003c\u003c (10 * iota) // 1 \u003c\u003c (10 * 2) = 1048576B = 1MB GB = 1 \u003c\u003c (10 * iota) // 1 \u003c\u003c (10 * 3) = 1073741824B = 1GB TB = 1 \u003c\u003c (10 * iota) // 1 \u003c\u003c (10 * 4) = 1099511627776B = 1TB ) ","date":"2023-08-05","objectID":"/golang-iota/:1:3","tags":["golang"],"title":"Golang Iota","uri":"/golang-iota/"},{"categories":["文档"],"content":"位运算 通过左移运算符 （«）与iota配合使用，方便地生成一组按位运算的常量 const ( FlagNone = 0 // 0 FlagRead = 1 \u003c\u003c iota // 1 FlagWrite // 2 FlagExec // 4 ) ","date":"2023-08-05","objectID":"/golang-iota/:1:4","tags":["golang"],"title":"Golang Iota","uri":"/golang-iota/"},{"categories":["文档"],"content":"Iota 的使用技巧和注意事项 ","date":"2023-08-05","objectID":"/golang-iota/:2:0","tags":["golang"],"title":"Golang Iota","uri":"/golang-iota/"},{"categories":["文档"],"content":"跳值使用 使用_下划线来忽略某些值， const ( Apple = iota // 0 _ Banana // 2 ) ","date":"2023-08-05","objectID":"/golang-iota/:2:1","tags":["golang"],"title":"Golang Iota","uri":"/golang-iota/"},{"categories":["文档"],"content":"不同常量块，iota是独立的 iota 的作用范围是整个常量块， 不同常量块的iota是独立的， 每个常量块中第一个iota的值都是0 const ( A = iota // 0 B // 1 ) const ( C = iota // 0 D // 1 ) ","date":"2023-08-05","objectID":"/golang-iota/:2:2","tags":["golang"],"title":"Golang Iota","uri":"/golang-iota/"},{"categories":["文档"],"content":"Redfish Api Redfish 利用常见的互联网和web 服务标准将信息直接提供给相关的工具链 IPMI 是一种较早的带外管理管理工具，仅限最小公共集命令集（开机/关机/重启/温度值/文本控制台）还是需要带内管理软件 当管控设备多的时候， 需要统一管理， 需要对接不同供应商的API， 基础的IMPI功能不好满足横向扩展环境，需要更便捷的方式调用服务器高级管理功能新的需求 Redfish可扩展平台管理API是一种新的规范，使用RESTful语句来访问定义在模型格式的数据，用于执行带外系统管理 ","date":"2023-07-08","objectID":"/redfish-api/:0:0","tags":["redfish-api"],"title":"Redfish Api","uri":"/redfish-api/"},{"categories":["文档"],"content":"Redfish应用场景 用户期望能够批量管理服务器，比如笔者想一次性给100个服务器安装系统，并且这100个服务器并不都是同一厂商，不同厂商的IPMI操作都不一样，比如Dell是iDRAC，你还需要专门学习iDRAC使用和各种对接，这会带来很多困扰。而Redfish标准的出现彻底改变这种情况，它是凌驾于所有服务器之上的一个标准，对服务器的基本操作都是统一的，并且是基于Restful API的方式实现 ","date":"2023-07-08","objectID":"/redfish-api/:1:0","tags":["redfish-api"],"title":"Redfish Api","uri":"/redfish-api/"},{"categories":["文档"],"content":"选择REST、HTTP以及JSON 除了REST、HTTP和JSON之外，Redfish还采用常见的OData v4约定来描述模式、URL约定和命名，以及JSON有效负载中常见属性的结构。越来越多的通用客户端库、应用程序和工具生态系统使用Redfish。 它有多简单?下面显示了使用Redfish从服务器检索序列号的示例Python代码：此示例中的输出如下所示 awData= urllib.urlopen(‘http://192.168.1.135/redfish/v1/Systems/1’) jsonData=json.loads(rawData) print(jsonData[‘SerialNumber’]) 1A87CA442K ","date":"2023-07-08","objectID":"/redfish-api/:2:0","tags":["redfish-api"],"title":"Redfish Api","uri":"/redfish-api/"},{"categories":["文档"],"content":"golang 的SDK https://github.com/Nordix/go-redfish 封装客户端 cfg := \u0026redfish.Configuration{ BasePath: \"http://localhost:8000\", DefaultHeader: make(map[string]string), UserAgent: \"go-redfish/client\", } redfishApi := redfish.NewAPIClient(cfg).DefaultApi 列出可用的计算机系统 sl, _, _ := redfishApi.ListSystems(context.Background()) 重置计算机系统 system_id := \"dd9fd064-263b-469c-91d4-d45f341fe2c5\" systemReq := redfish.ComputerSystem{ResetType: \"ForceRestart\"} reset_resp, _, _ = redfishApi.ResetSystem(context.Background(), system_id, reset_type) 给计算器插入虚拟媒体 manager_id := \"58893887-8974-2487-2389-841168418919\" insertReq := redfish.InsertMediaRequestBody{} insertReq.Image = \"http://releases.ubuntu.com/19.04/ubuntu-19.04-live-server-amd64.iso\" insertReq.Inserted = true redfishApi.InsertVirtualMedia(context.Background(), manager_id, \"Cd\", insertReq) 为下次启动设置启动设备 system_id := \"dd9fd064-263b-469c-91d4-d45f341fe2c5\" systemReq := redfish.ComputerSystem{} systemReq.Boot.BootSourceOverrideTarget = \"Cd\" redfishApi.SetSystem(context.Background(), system_id, systemReq) ","date":"2023-07-08","objectID":"/redfish-api/:3:0","tags":["redfish-api"],"title":"Redfish Api","uri":"/redfish-api/"},{"categories":["文档"],"content":"Redfish实践 The python-redfish project Python环境redfish接口获取泰山服务器和鲲鹏CPU信息 redfish是当前主流的服务器监控协议，通过redfish协议可以通过带外管理通道获取服务器状态和详细硬件信息 pip install python-redfish import redfish login_host=\"https://10.93.20.10\" login_account=\"ADMIN\" login_password=\"ADMIN\" REDFISH_OBJ = redfish.redfish_client(base_url=login_host, username=login_account, password=login_password, default_prefix='/redfish/v1') REDFISH_OBJ.login(auth=\"session\") response = REDFISH_OBJ.get(\"/redfish/v1/Systems/1\", None) print(response) REDFISH_OBJ.logout() 参考链接 ","date":"2023-07-08","objectID":"/redfish-api/:4:0","tags":["redfish-api"],"title":"Redfish Api","uri":"/redfish-api/"},{"categories":["文档"],"content":"Supermicro Redfish 特点 获取系统/机箱信息 管理用户账号和权限 BMC配置（AD、LDAP、SNMP、SMTP、RADIUS、Fan mode、Mouse mode、NTP、Snooping 等等） BIOS 配置 开机顺序变更 RAID 储存装置管理（For Broadcom 3108, 3008, 3216, 3616 \u0026 Marvel SE9230） 磁盘管理 获取 NIC MAC 信息（NIC 资讯） BMC／BIOS／3108韧体更新 获取温度／电源／传感器讯息 ","date":"2023-07-08","objectID":"/redfish-api/:5:0","tags":["redfish-api"],"title":"Redfish Api","uri":"/redfish-api/"},{"categories":["文档"],"content":" 🔥 gRpc 教程- protobuf 通信模式 四种通信模式 Simple RPC Server-Streaming RPC Client-Streaming RPC Bidirectionnal-Streaming RPC ","date":"2023-07-01","objectID":"/golang-protobuf-messagemode/:0:0","tags":["golang","rpc","protobuf"],"title":"Golang Protobuf MessageMode","uri":"/golang-protobuf-messagemode/"},{"categories":["文档"],"content":"Simple RPC syntax = \"proto3\"; package ecommerce; import \"google/protobuf/wrappers.proto\"; option go_package = \"ecommerce/\"; message Order { string id = 1; repeated string items = 2; string description = 3; float price = 4; string destination = 5; } service OrderManagement { rpc getOrder(google.protobuf.StringValue) returns (Order); } 注意事项 使用protobuf最新版本syntax = “proto3”; protoc-gen-go要求 pb 文件必须指定 go 包的路径。即option go_package = “ecommerce/”; 定义的method仅能有一个入参和出参数。如果需要传递多个参数需要定义成message 使用import引用另外一个文件的 pb。google/protobuf/wrappers.proto是 google 内置的类型 生成 go 和 grpc 的代码 $ protoc -I ./pb \\ --go_out ./ecommerce --go_opt paths=source_relative \\ --go-grpc_out ./ecommerce --go-grpc_opt paths=source_relative \\ ./pb/product.proto ","date":"2023-07-01","objectID":"/golang-protobuf-messagemode/:1:0","tags":["golang","rpc","protobuf"],"title":"Golang Protobuf MessageMode","uri":"/golang-protobuf-messagemode/"},{"categories":["文档"],"content":"server实现","date":"2023-07-01","objectID":"/golang-protobuf-messagemode/:1:1","tags":["golang","rpc","protobuf"],"title":"Golang Protobuf MessageMode","uri":"/golang-protobuf-messagemode/"},{"categories":["文档"],"content":" 🔥 gRpc 教程- protobuf 基础 序列化协议： grpc 使用 protobuf, 首先使用protobuf 定义服务，然后使用这个文件来生成客户端和服务端的代码， 因为pb是跨语言的， 因此使用服务端和客户端语言并不一致也可以相互序列化和反序列化 网络传输层： grpc使用的是http2.0协议， ","date":"2023-07-01","objectID":"/golang-protobuf-base/:0:0","tags":["golang","rpc","protobuf"],"title":"Golang Protobuf Base","uri":"/golang-protobuf-base/"},{"categories":["文档"],"content":"Protobuf IDL 序列化通俗来说就是把内存的一段数据转化为二进制并存储或者通过网络传输， 读取磁盘或另一端收到后可以在内存中重建这段数据 protobuf 协议是跨语言跨平台的序列化协议 protobuf 本身并不是和gPRC绑定的， 它可以被用于非RPC场景， 如内存等 json、xml 都是一种序列化方式， 只是他们不需要提前预定义 idl， 且具备可读性， https://protobuf.dev/programming-guides/proto3/ ","date":"2023-07-01","objectID":"/golang-protobuf-base/:1:0","tags":["golang","rpc","protobuf"],"title":"Golang Protobuf Base","uri":"/golang-protobuf-base/"},{"categories":["文档"],"content":"定义消息类型 protobuf里最基础的类型就是 message, 每一个message都会有一个或者多个字段（field）， 其中字段包含如下元素 类型： 类型不仅可以是标量类型（int、string等），也可以是复合类型（enum等），也可以是其他message 字段名： 字段名比较推荐的是使用下划线/分隔名称 字段编号： 一个message内每一个字段编号都必须唯一的，在编码后其实传递的是这个编号而不是字段名 字段规则：消息字段可以是以下字段之一 singular：格式正确的消息可以有零个或一个字段（但不能超过一个）。使用 proto3 语法时，如果未为给定字段指定其他字段规则，则这是默认字段规则 optional：与 singular 相同，不过您可以检查该值是否明确设置 repeated：在格式正确的消息中，此字段类型可以重复零次或多次。系统会保留重复值的顺序 map：这是一个成对的键值对字段 保留字段：为了避免再次使用到已移除的字段可以设定保留字段。如果任何未来用户尝试使用这些字段标识符，协议缓冲区编译器就会报错 ","date":"2023-07-01","objectID":"/golang-protobuf-base/:2:0","tags":["golang","rpc","protobuf"],"title":"Golang Protobuf Base","uri":"/golang-protobuf-base/"},{"categories":["文档"],"content":"复合类型 ","date":"2023-07-01","objectID":"/golang-protobuf-base/:3:0","tags":["golang","rpc","protobuf"],"title":"Golang Protobuf Base","uri":"/golang-protobuf-base/"},{"categories":["文档"],"content":"数组 message SearchResponse { repeated Result results = 1; } message Result { string url = 1; string title = 2; repeated string snippets = 3; } ","date":"2023-07-01","objectID":"/golang-protobuf-base/:3:1","tags":["golang","rpc","protobuf"],"title":"Golang Protobuf Base","uri":"/golang-protobuf-base/"},{"categories":["文档"],"content":"枚举 message SearchRequest { string query = 1; int32 page_number = 2; int32 result_per_page = 3; enum Corpus { UNIVERSAL = 0; WEB = 1; IMAGES = 2; LOCAL = 3; NEWS = 4; PRODUCTS = 5; VIDEO = 6; } Corpus corpus = 4; } ","date":"2023-07-01","objectID":"/golang-protobuf-base/:3:2","tags":["golang","rpc","protobuf"],"title":"Golang Protobuf Base","uri":"/golang-protobuf-base/"},{"categories":["文档"],"content":"服务 定义的method仅能有一个入参和出参数。如果需要传递多个参数需要定义成message service SearchService { rpc Search(SearchRequest) returns (SearchResponse); } ","date":"2023-07-01","objectID":"/golang-protobuf-base/:3:3","tags":["golang","rpc","protobuf"],"title":"Golang Protobuf Base","uri":"/golang-protobuf-base/"},{"categories":["文档"],"content":"使用其他消息类型 使用import引用另外一个文件的pb syntax = \"proto3\"; import \"google/protobuf/wrappers.proto\"; package ecommerce; message Order { string id = 1; repeated string items = 2; string description = 3; float price = 4; google.protobuf.StringValue destination = 5; } ","date":"2023-07-01","objectID":"/golang-protobuf-base/:3:4","tags":["golang","rpc","protobuf"],"title":"Golang Protobuf Base","uri":"/golang-protobuf-base/"},{"categories":["文档"],"content":"protoc使用 protoc就是protobuf的编译器，它把proto文件编译成不同的语言 ","date":"2023-07-01","objectID":"/golang-protobuf-base/:4:0","tags":["golang","rpc","protobuf"],"title":"Golang Protobuf Base","uri":"/golang-protobuf-base/"},{"categories":["文档"],"content":"安装 Linux, using apt or apt-get, for example: $ apt install -y protobuf-compiler $ protoc --version # Ensure compiler version is 3+ MacOS, using Homebrew[1]: $ brew install protobuf $ protoc --version # Ensure compiler version is 3+ ","date":"2023-07-01","objectID":"/golang-protobuf-base/:5:0","tags":["golang","rpc","protobuf"],"title":"Golang Protobuf Base","uri":"/golang-protobuf-base/"},{"categories":["文档"],"content":"使用 $ protoc --help Usage: protoc [OPTION] PROTO_FILES -IPATH, --proto_path=PATH 指定搜索路径 --plugin=EXECUTABLE: .... --cpp_out=OUT_DIR Generate C++ header and source. --csharp_out=OUT_DIR Generate C# source file. --java_out=OUT_DIR Generate Java source file. --js_out=OUT_DIR Generate JavaScript source. --objc_out=OUT_DIR Generate Objective C header and source. --php_out=OUT_DIR Generate PHP source file. --python_out=OUT_DIR Generate Python source file. --ruby_out=OUT_DIR Generate Ruby source file @\u003cfilename\u003e proto文件的具体位置 ","date":"2023-07-01","objectID":"/golang-protobuf-base/:5:1","tags":["golang","rpc","protobuf"],"title":"Golang Protobuf Base","uri":"/golang-protobuf-base/"},{"categories":["文档"],"content":"搜索路径参数 第一个比较重要的参数就是搜索路径参数，即上述展示的-IPATH, –proto_path=PATH。它表示的是我们要在哪个路径下搜索.proto文件，这个参数既可以用-I指定，也可以使用–proto_path=指定 ","date":"2023-07-01","objectID":"/golang-protobuf-base/:5:2","tags":["golang","rpc","protobuf"],"title":"Golang Protobuf Base","uri":"/golang-protobuf-base/"},{"categories":["文档"],"content":"语言插件参数 Language C++ (include C++ runtime and protoc) Java Python Objective-C C# Ruby PHP ","date":"2023-07-01","objectID":"/golang-protobuf-base/:5:3","tags":["golang","rpc","protobuf"],"title":"Golang Protobuf Base","uri":"/golang-protobuf-base/"},{"categories":["文档"],"content":"proto文件位置参数 proto文件位置参数即上述的@参数，指定了我们proto文件的具体位置，如proto1/greeter/greeter.proto ","date":"2023-07-01","objectID":"/golang-protobuf-base/:5:4","tags":["golang","rpc","protobuf"],"title":"Golang Protobuf Base","uri":"/golang-protobuf-base/"},{"categories":["文档"],"content":"golang插件 安装 非内置的语言支持就得自己单独安装语言插件，比如–go_out=对应的是protoc-gen-go，安装命令如下 # 最新版 $ go install google.golang.org/protobuf/cmd/protoc-gen-go@latest # 指定版本 $ go install google.golang.org/protobuf/cmd/protoc-gen-go@v1.3.0 生成代码 $ protoc --proto_path=src --go_out=out --go_opt=paths=source_relative foo.proto bar/baz.proto ","date":"2023-07-01","objectID":"/golang-protobuf-base/:6:0","tags":["golang","rpc","protobuf"],"title":"Golang Protobuf Base","uri":"/golang-protobuf-base/"},{"categories":["文档"],"content":" 🔥Golang算法 - 快速排序（Quicksort） 广度优先算法的核心思想是：从初始节点开始，应用算符生成第一层节点，检查目标节点是否在这些后继节点中，若没有，再用产生式规则将所有第一层的节点逐一扩展，得到第二层节点，并逐一检查第二层节点中是否包含目标节点。若没有，再用算符逐一扩展第二层的所有节点……，如此依次扩展，检查下去，直到发现目标节点为止。即 ","date":"2023-06-10","objectID":"/golang-beradth-firstsearch/:0:0","tags":["golang","算法"],"title":"🔥Golang Beradth FirstSearch","uri":"/golang-beradth-firstsearch/"},{"categories":["文档"],"content":"图（Graph）是什么？ 图是用来对不同事物间如何管理进行建模的一种方式 ","date":"2023-06-10","objectID":"/golang-beradth-firstsearch/:1:0","tags":["golang","算法"],"title":"🔥Golang Beradth FirstSearch","uri":"/golang-beradth-firstsearch/"},{"categories":["文档"],"content":"数据结构 Queue 现进来的数据先处理（FIFO） 无法随机的访问Queue 里面的元素 相关操作 enqueue: 添加元素 dequeue: 移除元素 代码示例 package main import \"fmt\" type GraphMap map[string][]string func main() { var graphMap GraphMap = make(GraphMap, 0) graphMap[\"you\"] = []string{\"alice\", \"bob\", \"claire\"} graphMap[\"bob\"] = []string{\"anuj\", \"peggy\"} graphMap[\"alice\"] = []string{\"peggy\"} graphMap[\"claire\"] = []string{\"tom\", \"johnny\"} graphMap[\"anuj\"] = []string{} graphMap[\"peggy\"] = []string{} graphMap[\"tom\"] = []string{} graphMap[\"johnny\"] = []string{} searchQueue := graphMap[\"you\"] for { if len(searchQueue) \u003e 0 { var person string person, searchQueue = searchQueue[0], searchQueue[1:] if personIsTom(person) { fmt.Printf(\"%s is the man\\n\", person) break } else { searchQueue = append(searchQueue, graphMap[person]...) } } else { fmt.Println(\"Not Found\") break } } } func personIsTom(p string) bool { return p == \"tom\" } 参考视频 ","date":"2023-06-10","objectID":"/golang-beradth-firstsearch/:2:0","tags":["golang","算法"],"title":"🔥Golang Beradth FirstSearch","uri":"/golang-beradth-firstsearch/"},{"categories":["文档"],"content":" golang-viper 介绍 viper 是一个配置解决方案，用于丰富的特性 支持 JSON/TOML/YAML/HCL/envfile/Java properties 等多种格式的配置文件 可以设置监听配置文件的修改，修改时自动加载新的配置； 从环境变量、命令行选项和io.Reader中读取配置 从远程配置系统中读取和监听修改，如 etcd/Consul； 代码逻辑中显示设置健值 ","date":"2023-06-09","objectID":"/golang-viper/:0:0","tags":["golang","go第三方库"],"title":"Golang Viper","uri":"/golang-viper/"},{"categories":["文档"],"content":"使用 安装 go get github.com/spf13/viper 使用 package main import ( \"fmt\" \"log\" \"github.com/spf13/viper\" ) func main() { viper.SetConfigName(\"config\") viper.SetConfigType(\"toml\") viper.AddConfigPath(\".\") viper.SetDefault(\"redis.port\", 6381) err := viper.ReadInConfig() if err != nil { log.Fatal(\"read config failed: %v\", err) } fmt.Println(viper.Get(\"app_name\")) fmt.Println(viper.Get(\"log_level\")) fmt.Println(\"mysql ip: \", viper.Get(\"mysql.ip\")) fmt.Println(\"mysql port: \", viper.Get(\"mysql.port\")) fmt.Println(\"mysql user: \", viper.Get(\"mysql.user\")) fmt.Println(\"mysql password: \", viper.Get(\"mysql.password\")) fmt.Println(\"mysql database: \", viper.Get(\"mysql.database\")) fmt.Println(\"redis ip: \", viper.Get(\"redis.ip\")) fmt.Println(\"redis port: \", viper.Get(\"redis.port\")) } viper的配置 SetConfigName： 设置文件名 SetConfigType： 配置类型 AddConfigPath： 搜索路径 ReadInConfig： 读取配置 viper.Get ： 获取键值 ⚠️注意 设置文件名时不要带后缀 搜索路径可以设置多个，viper会根据设置顺序依次查找 viper 获取值使用section.key的形式，即传入嵌套的键名 默认值可以调用 viper.SetDefault设置 ","date":"2023-06-09","objectID":"/golang-viper/:1:0","tags":["golang","go第三方库"],"title":"Golang Viper","uri":"/golang-viper/"},{"categories":["文档"],"content":"读取键 GetType 系列方法可以返回指定类型的值， type可以时Bool/Float64/Int/String/Time/Duration/IntSlice/StringSlice 如果指定的键不存在或者类型不正确，GetType方法返回对应类型时零值 判断某个键是否存在， 使用IsSet GetStringMap： 直接以 map 返回某个键下面所有的键值对 GetStringMapString： 返回map[string]string package main import ( \"fmt\" \"log\" \"github.com/spf13/viper\" ) func main() { viper.SetConfigName(\"config\") viper.SetConfigType(\"toml\") viper.AddConfigPath(\".\") err := viper.ReadInConfig() if err != nil { log.Fatalf(\"read config failed: %v\", err) } fmt.Println(\"protocols: \", viper.GetStringSlice(\"server.protocols\")) fmt.Println(\"ports: \", viper.GetIntSlice(\"server.ports\")) fmt.Println(\"timeout: \", viper.GetDuration(\"server.timeout\")) fmt.Println(\"mysql ip: \", viper.GetString(\"mysql.ip\")) fmt.Println(\"mysql port: \", viper.GetInt(\"mysql.port\")) if viper.IsSet(\"redis.port\") { fmt.Println(\"redis.port is set\") } else { fmt.Println(\"redis.port is not set\") } fmt.Println(\"mysql settings: \", viper.GetStringMap(\"mysql\")) fmt.Println(\"redis settings: \", viper.GetStringMap(\"redis\")) fmt.Println(\"all settings: \", viper.AllSettings()) } ","date":"2023-06-09","objectID":"/golang-viper/:2:0","tags":["golang","go第三方库"],"title":"Golang Viper","uri":"/golang-viper/"},{"categories":["文档"],"content":"设置键值 viper 支持在多个地方设置，使用下面的顺序依次读取 调用 Set 显示设置的 命令行选项； 环境变量 默认值 viper.Set 如果某个键通过 viper.set 设置了值， 这个值优先级最高 viper.Set(\"redis.port\", 5381) ","date":"2023-06-09","objectID":"/golang-viper/:3:0","tags":["golang","go第三方库"],"title":"Golang Viper","uri":"/golang-viper/"},{"categories":["文档"],"content":"命令行选项 viper使用pflag库来解析选项，首先在 init 方法中定义选项， 并且在viper.BindPFlags 绑定选项来配置中 func init() { pflag.Int(\"redis.port\", 8381, \"Redis port to connect\") // 绑定命令行 viper.BindPFlags(pflag.CommandLine) } ","date":"2023-06-09","objectID":"/golang-viper/:4:0","tags":["golang","go第三方库"],"title":"Golang Viper","uri":"/golang-viper/"},{"categories":["文档"],"content":"环境变量 在init方法中调用AutomaticEnv方法绑定全部环境变量 func init() { // 绑定环境变量 viper.AutomaticEnv() } 单独绑定环境变量 func init() { // 绑定环境变量 viper.BindEnv(\"redis.port\") viper.BindEnv(\"go.path\", \"GOPATH\") } func main() { // 省略部分代码 fmt.Println(\"go path: \", viper.Get(\"go.path\")) } 调用 BindEnv 方法 只传一个参数， 即表示键名，又表示环境变量名 传入两个参数， 第一个参数表示键名，第二个表示环境变量名 ","date":"2023-06-09","objectID":"/golang-viper/:5:0","tags":["golang","go第三方库"],"title":"Golang Viper","uri":"/golang-viper/"},{"categories":["文档"],"content":"读取配置 ","date":"2023-06-09","objectID":"/golang-viper/:6:0","tags":["golang","go第三方库"],"title":"Golang Viper","uri":"/golang-viper/"},{"categories":["文档"],"content":"从io.Reader 中读取 viper 支持从 io.Reader 中读取配置， 配置灵活 文件 程序中生成的字符串 从网络中链接中读取的字节流 package main import ( \"bytes\" \"fmt\" \"log\" \"github.com/spf13/viper\" ) func main() { viper.SetConfigType(\"toml\") tomlConfig := []byte(` app_name = \"awesome web\" # possible values: DEBUG, INFO, WARNING, ERROR, FATAL log_level = \"DEBUG\" [mysql] ip = \"127.0.0.1\" port = 3306 user = \"dj\" password = 123456 database = \"awesome\" [redis] ip = \"127.0.0.1\" port = 7381 `) err := viper.ReadConfig(bytes.NewBuffer(tomlConfig)) if err != nil { log.Fatal(\"read config failed: %v\", err) } fmt.Println(\"redis port: \", viper.GetInt(\"redis.port\")) } ","date":"2023-06-09","objectID":"/golang-viper/:6:1","tags":["golang","go第三方库"],"title":"Golang Viper","uri":"/golang-viper/"},{"categories":["文档"],"content":"Unmarshal viper 支持将配置Unmarshal到一个结构体中，为结构体中的对应字段赋值 package main import ( \"fmt\" \"log\" \"github.com/spf13/viper\" ) type Config struct { AppName string LogLevel string MySQL MySQLConfig Redis RedisConfig } type MySQLConfig struct { IP string Port int User string Password string Database string } type RedisConfig struct { IP string Port int } func main() { viper.SetConfigName(\"config\") viper.SetConfigType(\"toml\") viper.AddConfigPath(\".\") err := viper.ReadInConfig() if err != nil { log.Fatal(\"read config failed: %v\", err) } var c Config viper.Unmarshal(\u0026c) fmt.Println(c.MySQL) } ","date":"2023-06-09","objectID":"/golang-viper/:6:2","tags":["golang","go第三方库"],"title":"Golang Viper","uri":"/golang-viper/"},{"categories":["文档"],"content":"保存配置 将程序中生成的配置，或者所做的修改保存下来 WriteConfig： 将当前的viper配置写到预定义路径， 如果没有预定义路径，返回错误，将会覆盖当前配置 SafeWriteConfig： 与上面功能一样，如果配置文件存在，则不覆盖 WriteConfigAs： 保存配置到指定路径，如果文件存在，则覆盖 SafeWriteConfig： 与上面功能一样，但是入股配置文件存在，则不覆盖 package main import ( \"log\" \"github.com/spf13/viper\" ) func main() { viper.SetConfigName(\"config\") viper.SetConfigType(\"toml\") viper.AddConfigPath(\".\") viper.Set(\"app_name\", \"awesome web\") viper.Set(\"log_level\", \"DEBUG\") viper.Set(\"mysql.ip\", \"127.0.0.1\") viper.Set(\"mysql.port\", 3306) viper.Set(\"mysql.user\", \"root\") viper.Set(\"mysql.password\", \"123456\") viper.Set(\"mysql.database\", \"awesome\") viper.Set(\"redis.ip\", \"127.0.0.1\") viper.Set(\"redis.port\", 6381) err := viper.SafeWriteConfig() if err != nil { log.Fatal(\"write config failed: \", err) } } ","date":"2023-06-09","objectID":"/golang-viper/:7:0","tags":["golang","go第三方库"],"title":"Golang Viper","uri":"/golang-viper/"},{"categories":["文档"],"content":"监听文件修改 viper 可以监听文件修改， 热加载配置，不需要重启服务器， 让配置生效 package main import ( \"fmt\" \"log\" \"time\" \"github.com/spf13/viper\" ) func main() { viper.SetConfigName(\"config\") viper.SetConfigType(\"toml\") viper.AddConfigPath(\".\") err := viper.ReadInConfig() if err != nil { log.Fatal(\"read config failed: %v\", err) } viper.WatchConfig() fmt.Println(\"redis port before sleep: \", viper.Get(\"redis.port\")) time.Sleep(time.Second * 10) fmt.Println(\"redis port after sleep: \", viper.Get(\"redis.port\")) } viper.WatchConfig： viper 会自动监听配置修改，如果有修改，重新加载的配置 为配置修改增加一个回调 viper.OnConfigChange(func(e fsnotify.Event) { fmt.Printf(\"Config file:%s Op:%s\\n\", e.Name, e.Op) }) 参考链接 https://darjun.github.io/2020/01/18/godailylib/viper/ ","date":"2023-06-09","objectID":"/golang-viper/:8:0","tags":["golang","go第三方库"],"title":"Golang Viper","uri":"/golang-viper/"},{"categories":["文档"],"content":"# golang-cobra 介绍 cobra 是一个命令行程序库 提供了脚手架，用于生成基于cobra的应用程序框架 ","date":"2023-06-08","objectID":"/golang-cobra/:0:0","tags":["golang","go第三方库"],"title":"Golang Cobra","uri":"/golang-cobra/"},{"categories":["文档"],"content":"安装\u0026使用 安装 cobra go get github.com/spf13/cobra/cobra 实现一个git 模拟命令, 通过os/exec 库调用外部程序执行真实的git命令 目录结构如下 tree . ├── cmd │ ├── helper.go │ ├── root.go │ └── version.go └── main.go root.go package cmd import ( \"errors\" \"github.com/spf13/cobra\" ) var rootCmd = \u0026cobra.Command{ Use: \"git\", Short: \"Git is a distributed version control system.\", Long: `Git is a free and open source distributed version control system designed to handle everything from small to very large projects with speed and efficiency.`, Run: func(cmd *cobra.Command, args []string) { Error(cmd, args, errors.New(\"unrecognized command\")) }, } func Execute() { rootCmd.Execute() } version.go package cmd import ( \"fmt\" \"os\" \"github.com/spf13/cobra\" ) var versionCmd = \u0026cobra.Command{ Use: \"version\", Short: \"version subcommand show git version info.\", Run: func(cmd *cobra.Command, args []string) { output, err := ExecuteCommand(\"git\", \"version\", args...) if err != nil { Error(cmd, args, err) } fmt.Fprint(os.Stdout, output) }, } func init() { rootCmd.AddCommand(versionCmd) } main.go package main import ( \"demo/dajun/cobra/cmd\" ) func main() { cmd.Execute() } helper.go 封装了调用外部程序和错误处理函数 package cmd import ( \"fmt\" \"os\" \"os/exec\" \"github.com/spf13/cobra\" ) func ExecuteCommand(name string, subname string, args ...string) (string, error) { args = append([]string{subname}, args...) cmd := exec.Command(name, args...) bytes, err := cmd.CombinedOutput() return string(bytes), err } func Error(cmd *cobra.Command, args []string, err error) { fmt.Fprintf(os.Stderr, \"execute %s args:%v error:%v\\n\", cmd.Name(), args, err) os.Exit(1) } 每个cobra 程序都有一个根命令，可以给他添加任意多个子命令， 在version.go init函数将子命令添加到跟命令中 不能直接go run main.go，这已经不是单文件程序了。如果强行要用，请使用go run . go build -o main cobra 自动生成的帮助信息 ./main -h Git is a free and open source distributed version control system designed to handle everything from small to very large projects with speed and efficiency. Usage: git [flags] git [command] Available Commands: completion Generate the autocompletion script for the specified shell help Help about any command version version subcommand show git version info. Flags: -h, --help help for git Use \"git [command] --help\" for more information about a command 单个子命令的帮助信息 ./main version -h version subcommand show git version info. Usage: git version [flags] Flags: -h, --help help for version 调用子命令 ./main version git version 2.39.2 (Apple Git-143) ","date":"2023-06-08","objectID":"/golang-cobra/:1:0","tags":["golang","go第三方库"],"title":"Golang Cobra","uri":"/golang-cobra/"},{"categories":["文档"],"content":"特性 cobra 提供非常丰富的功能 轻松支持子命令如 app server, app fetch等 完全兼容POSIX选项（包括短，长选项）； 嵌套子命令 全局/本地层级选项，可以在多处设置选项， 按照一定的顺序调用 使用脚手架轻松胜出程序框架和命令 ","date":"2023-06-08","objectID":"/golang-cobra/:2:0","tags":["golang","go第三方库"],"title":"Golang Cobra","uri":"/golang-cobra/"},{"categories":["文档"],"content":"基本概念 命令(Command): 需要执行的的操作。 参数(Arg) ： 命令的参数， 即要操作的对象。 选项(Flag)： 命令选项可以调整命令的行为。 ","date":"2023-06-08","objectID":"/golang-cobra/:2:1","tags":["golang","go第三方库"],"title":"Golang Cobra","uri":"/golang-cobra/"},{"categories":["文档"],"content":"命令 在cobra中， 命令和子命令都是用 Command 结构表示的，Command有非常多的字段，用来制定命令的行为， Use: 使用信息，即命令怎么被调用，Example: add [-F file | -D dir]... [-f format] profile Short\\Long：命令的帮助信息，前者是简短的，后者是详细的 Run： 实际执行的操作函数 定义新的子命令很简单， 创建一个cobra.Command变量， 设置一些字段，添加到根命令 添加一个clone package cmd import ( \"fmt\" \"os\" \"github.com/spf13/cobra\" ) var cloneCmd = \u0026cobra.Command { Use: \"clone url [destination]\", Short: \"Clone a repository into a new directory\", Run: func(cmd *cobra.Command, args []string) { output, err := ExecuteCommand(\"git\", \"clone\", args...) if err != nil { Error(cmd, args, err) } fmt.Fprintf(os.Stdout, output) }, } func init() { rootCmd.AddCommand(cloneCmd) } Use： clone url [destination] clone: 子命令 url： 参数 destination : 目标路径 ","date":"2023-06-08","objectID":"/golang-cobra/:3:0","tags":["golang","go第三方库"],"title":"Golang Cobra","uri":"/golang-cobra/"},{"categories":["文档"],"content":"选项 cobra 的选项分为两种 永久选项：定义的命令和其子命令都可以使用，通过给跟命令添加一个选项定义全局选项 本地选项：定义它 的命令中使用 cobra 使用pflag 解析命令行选项， 存储选项的变量需要提前定义好 var Verbose bool var Source string 设置永久选项 rootCmd.PersistentFlags().BoolVarP(\u0026Verbose, \"verbose\", \"v\", false, \"verbose output\") 设置本地选项 localCmd.Flags().StringVarP(\u0026Source, \"source\", \"s\", \"\", \"Source directory to read from\") 座一个计算机功能， 支持加、减、乘、除操作。并且可以通过选项设置是否忽略非数字参数，设置除 0 是否报错。 显然，前一个选项应该放在全局选项中，后一个应该放在除法命令中 程序结构 ├── cmd │ ├── add.go │ ├── divide.go │ ├── helper.go │ ├── minus.go │ ├── multiply.go │ └── root.go └── main.go devide.go package cmd import ( \"fmt\" \"strings\" \"github.com/spf13/cobra\" ) var ( dividedByZeroHanding int // 除 0 如何处理 ) var divideCmd = \u0026cobra.Command { Use: \"divide\", Short: \"Divide subcommand divide all passed args.\", Run: func(cmd *cobra.Command, args []string) { values := ConvertArgsToFloat64Slice(args, ErrorHandling(parseHandling)) result := calc(values, DIVIDE) fmt.Printf(\"%s = %.2f\\n\", strings.Join(args, \"/\"), result) }, } func init() { divideCmd.Flags().IntVarP(\u0026dividedByZeroHanding, \"divide_by_zero\", \"d\", int(PanicOnDividedByZero), \"do what when divided by zero\") rootCmd.AddCommand(divideCmd) } root.go var ( parseHandling int ) var rootCmd = \u0026cobra.Command { Use: \"math\", Short: \"Math calc the accumulative result.\", Run: func(cmd *cobra.Command, args []string) { Error(cmd, args, errors.New(\"unrecognized subcommand\")) }, } func init() { rootCmd.PersistentFlags().IntVarP(\u0026parseHandling, \"parse_error\", \"p\", int(ContinueOnParseError), \"do what when parse arg error\") } func Execute() { rootCmd.Execute() } 在divide.go中定义了如何处理除 0 错误的选项，在root.go中定义了如何处理解析错误的选项。选项枚举如下： const ( ContinueOnParseError ErrorHandling = 1 // 解析错误尝试继续处理 ExitOnParseError ErrorHandling = 2 // 解析错误程序停止 PanicOnParseError ErrorHandling = 3 // 解析错误 panic ReturnOnDividedByZero ErrorHandling = 4 // 除0返回 PanicOnDividedByZero ErrorHandling = 5 // 除0 painc ) 测试程序 $ go build -o math $ ./math add 1 2 3 4 1+2+3+4 = 10.00 $ ./math minus 1 2 3 4 1-2-3-4 = -8.00 $ ./math multiply 1 2 3 4 1*2*3*4 = 24.00 $ ./math divide 1 2 3 4 1/2/3/4 = 0.04 默认情况下， 解析错误被忽略， $ ./math add 1 2a 3b 4 1+2a+3b+4 = 5.00 $ ./math divide 1 2a 3b 4 1/2a/3b/4 = 0.25 设置解析失败的处理，2 表示退出程序，3 表示 panic ./math add 1 2a 3b 4 -p 2 invalid number: 2a $ ./math add 1 2a 3b 4 -p 3 panic: strconv.ParseFloat: parsing \"2a\": invalid syntax goroutine 1 [running]: ","date":"2023-06-08","objectID":"/golang-cobra/:4:0","tags":["golang","go第三方库"],"title":"Golang Cobra","uri":"/golang-cobra/"},{"categories":["文档"],"content":"脚手架 始化一个新的Go模块： 创建一个新目录 cd进入那个目录 run go mod init cd $HOME/code mkdir myapp cd myapp go mod init github.com/spf13/myapp cobra-cli init也可以从子目录运行 –author标志的作者姓名。例如cobra-cli init –author “Steve Francia spf@spf13.com” –license一起使用的许可证，例如cobra-cli init –license apache ","date":"2023-06-08","objectID":"/golang-cobra/:5:0","tags":["golang","go第三方库"],"title":"Golang Cobra","uri":"/golang-cobra/"},{"categories":["文档"],"content":"给项目添加命令 cobra-cli add serve cobra-cli add config cobra-cli add create -p 'configCmd' 运行了这三个命令，你就会有一个类似于以下内容的应用程序结构： ▾ app/ ▾ cmd/ config.go create.go serve.go root.go main.go 参考链接 https://github.com/spf13/cobra-cli https://darjun.github.io/2020/01/17/godailylib/cobra/ ","date":"2023-06-08","objectID":"/golang-cobra/:5:1","tags":["golang","go第三方库"],"title":"Golang Cobra","uri":"/golang-cobra/"},{"categories":["文档"],"content":" 🔥Golang算法 - 快速排序（Quicksort） 不需要排序的数组（Base case 基线条件） [],空数组 [s], 单元素数组 容易排序的数组 [a,b],两个元素的数组，只需坚持它们之间的大小即可，调整位置 ","date":"2023-06-08","objectID":"/golang-quicksort/:0:0","tags":["golang","算法"],"title":"🔥Golang Quicksort","uri":"/golang-quicksort/"},{"categories":["文档"],"content":"使用Quicksort 排序数组 3个元素的数组（例如[23, 19, 35]） 使用D \u0026 C策略， 简化为基线条件（Base case） 从数组中随便找一个元素， 例如35， 这个元素叫做pivot(基准元素) 找到比pivot小的元素，找到比pivot大的元素， 这叫做分区：[23, 19],(35),[] 如果左右两个子数组已排好序（达到基线条件）， 结果： 左边 + [pivot] + 右边 如果左右两个子数组没有已排好序（没有达到基线条件）， 那么： quiksort左边 + [pivot] + quicksort右边 ","date":"2023-06-08","objectID":"/golang-quicksort/:1:0","tags":["golang","算法"],"title":"🔥Golang Quicksort","uri":"/golang-quicksort/"},{"categories":["文档"],"content":"使用Quicksourt 排序数组的步骤 选择一个pivot 将数组分为两个子数组 左侧数组的元素都比pivot小 右侧数组的元素都比pivot大 在两个子数组上递归的调用quicksort 代码示例01 package main import \"fmt\" func main() { arr := []int{12, 87, 62, 66, 30, 12, 328, 121, 67, 98, 3, 256, 81} result := quicksort(arr) fmt.Println(result) } func quicksort(arr []int) []int { if len(arr) \u003c 2 { return arr } pivot := arr[0] var left, right []int for _, ele := range arr[1:] { if ele \u003c= pivot { left = append(left, ele) } else { right = append(right, ele) } } return append(quicksort(left), append([]int{pivot}, quicksort(right)...)...) } 参考视频 ","date":"2023-06-08","objectID":"/golang-quicksort/:2:0","tags":["golang","算法"],"title":"🔥Golang Quicksort","uri":"/golang-quicksort/"},{"categories":["文档"],"content":" 🔥Golang算法 - D\u0026C 算法 Devide \u0026 Conquer D \u0026 C 的步骤 找到一个简单的基线条件（Base Case） 把问题分开处理。直到它变为极限条件 ","date":"2023-06-07","objectID":"/golang-divide_conquer/:0:0","tags":["golang","算法"],"title":"🔥Golang Divide_Conquer","uri":"/golang-divide_conquer/"},{"categories":["文档"],"content":"例子 需求： 将数组[1,3,5,7,9]求和 思路1： 使用循环（例如for循环） 思路2: D \u0026 C策略 基线条件： 空数组[], 其和为0， 递归：[1,3,5,7,9] 1 + SUM([3,5,7,9]) 3 + SUM([5,7,9]) 5 + SUM([7,9]) 7 + SUM([9]) 9 + SUM([]) ","date":"2023-06-07","objectID":"/golang-divide_conquer/:1:0","tags":["golang","算法"],"title":"🔥Golang Divide_Conquer","uri":"/golang-divide_conquer/"},{"categories":["文档"],"content":"代码示例 package main import \"fmt\" func main() { totals := sum([]int{1, 3, 5, 7, 9}) fmt.Println(totals) } func sum(arr []int) int { if len(arr) == 0 { return 0 } return arr[0] + sum(arr[1:]) } 参考视频 ","date":"2023-06-07","objectID":"/golang-divide_conquer/:2:0","tags":["golang","算法"],"title":"🔥Golang Divide_Conquer","uri":"/golang-divide_conquer/"},{"categories":["文档"],"content":" git tag (figure) 🚀git tag 标签管理 可以在版本库中打一个标签，确定打标签的版本 标签就是版本库的快照 ","date":"2023-06-06","objectID":"/git-tag/:0:0","tags":["git"],"title":"Git Tag","uri":"/git-tag/"},{"categories":["文档"],"content":"创建标签 切换到需要打标签的分支上 $ git branch * dev master $ git checkout master Switched to branch 'master' 打一个新标签 git tag v1.0 查看所有标签 git tag v1.0 默认标签是打在最新提交的commit上 找到历史提交的commit id，然后打 git log --pretty=oneline --abbrev-commit 12a631b (HEAD -\u003e master, tag: v1.0, origin/master) merged bug fix 101 4c805e2 fix bug 101 e1e9c68 merge with no-ff f52c633 add merge cf810e4 conflict fixed 要对add merge这次提交打标签 git tag v0.9 f52c633 再次查看标签 git tag v0.9 v1.0 标签不是按时间顺序列出，而是按字母排序的。可以用git show 查看标签信息 git show v0.9 commit f52c63349bc3c1593499807e5c8e972b82c8f286 (tag: v0.9) Author: Michael Liao \u003caskxuefeng@gmail.com\u003e Date: Fri May 18 21:56:54 2018 +0800 add merge diff --git a/readme.txt b/readme.txt 可以创建带有说明的标签，用-a指定标签名，-m指定说明文字 git tag -a v0.1 -m \"version 0.1 released\" 1094adb ","date":"2023-06-06","objectID":"/git-tag/:1:0","tags":["git"],"title":"Git Tag","uri":"/git-tag/"},{"categories":["文档"],"content":"操作标签 删除标签 git tag -d v0.1 推送某个标签到远程 git push origin v1.0 推送所有标签 git push origin --tags 删除远程标签 ## 本地删除标签 git tag -d v0.9 ## 远程删除 git push origin :refs/tags/v0.9 ","date":"2023-06-06","objectID":"/git-tag/:2:0","tags":["git"],"title":"Git Tag","uri":"/git-tag/"},{"categories":["文档"],"content":"命令总结 git tag 用于新建一个标签，默认为HEAD，也可以指定一个commit id； git tag -a -m “blablabla…“可以指定标签信息； git tag可以查看所有标签 git push origin 可以推送一个本地标签； git push origin –tags可以推送全部未推送过的本地标签； git tag -d 可以删除一个本地标签； git push origin :refs/tags/可以删除一个远程标签 参考链接 https://www.liaoxuefeng.com/wiki/896043488029600/900788941487552 ","date":"2023-06-06","objectID":"/git-tag/:3:0","tags":["git"],"title":"Git Tag","uri":"/git-tag/"},{"categories":["文档"],"content":" git (figure) 🚀git 常用命令和技巧 列举一些常用的git命令和一些小技巧 统一概念 工作区： 该动（增删文件和内容） 暂存区： 输入命令，git add 改动的文件名，此次改动就放到了 ‘暂存区’ 本地仓库： 输入命令：git commit 此次修改的描述，此次改动就放到了本地仓库，每个 commit，我叫它为一个版本 远程仓库： 输入命令：git push 远程仓库，此次改动就放到了远程仓库（GitHub 等) commit-id：输出命令：git log，最上面那行 commit xxxxxx，后面的字符串就是 commit-id ","date":"2023-06-03","objectID":"/git-skill/:0:0","tags":["git"],"title":"Git Skill","uri":"/git-skill/"},{"categories":["文档"],"content":"git 基础介绍 创建新仓库 # 创建新文件夹， 打开， 然后执行 git init 检出仓库 # 执行命令以创建一个本地仓库的克隆版本 git clone /path/to/repository # 远端服务器的仓库 git clone username@host:/path/to/repository 工作流 本地仓库有git维护三颗树组成 工作目录： 持有实际的文件 暂存区 ： 缓存区域，临时保存你的改动 HEAD： 指向你最后一次提交的结果 添加和提交 ## 提出更改（把它们添加到暂存区） git add \u003cfilename\u003e git add * ## 改动已经提交到了 HEAD git commit -m \"代码提交信息\" 推送改动 ## 将改动提交到 远端仓库 git push origin master ## 将你的仓库连接到某个远程服务器，你可以使用如下命令添加 git remote add origin \u003cserver\u003e 分支 ## 创建一个分支 git checkout -b feature_x ## 切换回主分支 git checkout master ## 把新建的分支删除 git branch -d feature_x ## 除非你将分支推送到远端仓库，不然该分支就是 不为他人所见的 git push origin \u003cbranch\u003e 更新与合并 ## 更新你的本地仓库至最新改动 git pull ## 合并其他分支到你的当前分支 git merge \u003cbranch\u003e ## 在这两种情况下，git 都会尝试去自动合并改动。遗憾的是，这可能并非每次都成功，并可能出现冲突（conflicts）。 这时候就需要你修改这些文件来手动合并这些冲突（conflicts）。改完之后，你需要执行如下命令以将它们标记为合并成功 git add \u003cfilename\u003e ## 在合并改动之前，你可以使用如下命令预览差异 git diff \u003csource_branch\u003e \u003ctarget_branch\u003e 标签 ## 创建一个 1.00 的标签 git tag 1.0.0 1b2e1d63ff ## 1b2e1d63ff 是你想要标记的提交 ID 的前 10 位字符。可以使用下列命令获取提交 ID git log log ## 本地仓库的历史记录 git log ## 只看某人的提交记录 git log --author=bob ## 一个压缩后的每一条提交记录只占一行输出 git log --pretty=oneline ## 通过 ASCII 艺术的树形结构来展示所有的分支 git log --graph --oneline --decorate --all ## 查看那些文件改变了 git log --name-status 替换本地改动 ## 替换掉本地的改动 git checkout -- \u003cfilename\u003e ## 丢弃本地所有的改动和提交，可以到服务器上获取最新的版本历史，并将你本地主分支指向它 git fetch origin git reset --hard origin/master ","date":"2023-06-03","objectID":"/git-skill/:1:0","tags":["git"],"title":"Git Skill","uri":"/git-skill/"},{"categories":["文档"],"content":"回到远程仓库的状态 抛弃本地所有的修改，回到远程仓库的状态的 git fetch --all \u0026\u0026 git reset --hard origin/master ","date":"2023-06-03","objectID":"/git-skill/:2:0","tags":["git"],"title":"Git Skill","uri":"/git-skill/"},{"categories":["文档"],"content":"重设第一个 commit 把所有的修改都重新放回工作区， 并清空所有的 commit， 这样可以重新提交第一个commit git update-ref -d HEAD ","date":"2023-06-03","objectID":"/git-skill/:3:0","tags":["git"],"title":"Git Skill","uri":"/git-skill/"},{"categories":["文档"],"content":"查看冲突文件列表 展示工作区的冲突文件列表 git diff --name-only --diff-filter=U ","date":"2023-06-03","objectID":"/git-skill/:4:0","tags":["git"],"title":"Git Skill","uri":"/git-skill/"},{"categories":["文档"],"content":"展示工作区和暂存区的不同 ## 输出**工作区**和**暂存区**的 different git diif ## 还可以展示本地仓库中任意两个 commit 之间的文件变动 git diff \u003ccommit-id\u003e \u003ccommit-id\u003e ","date":"2023-06-03","objectID":"/git-skill/:5:0","tags":["git"],"title":"Git Skill","uri":"/git-skill/"},{"categories":["文档"],"content":"展示暂存区和最近版本的不同 ## 输出暂存区和本地最近的版本 (commit) 的 different (不同) git diff --cached ","date":"2023-06-03","objectID":"/git-skill/:6:0","tags":["git"],"title":"Git Skill","uri":"/git-skill/"},{"categories":["文档"],"content":"快速切换到上一个分支 git checkout - ","date":"2023-06-03","objectID":"/git-skill/:7:0","tags":["git"],"title":"Git Skill","uri":"/git-skill/"},{"categories":["文档"],"content":"删除已经合并到 master 的分支 git branch --merged master | grep -v '^\\*\\| master' | xargs -n 1 git branch -d ","date":"2023-06-03","objectID":"/git-skill/:8:0","tags":["git"],"title":"Git Skill","uri":"/git-skill/"},{"categories":["文档"],"content":"展示本地分支关联远程仓库的情况 git branch -vv ","date":"2023-06-03","objectID":"/git-skill/:9:0","tags":["git"],"title":"Git Skill","uri":"/git-skill/"},{"categories":["文档"],"content":"关联远程分支 ## 关联之后，git branch -vv 就可以展示关联的远程分支名了，同时推送到远程仓库直接：git push，不需要指定远程仓库 git branch -u origin/mybranch ## 或者在 push 时加上 -u 参数 git push origin/mybranch -u ","date":"2023-06-03","objectID":"/git-skill/:10:0","tags":["git"],"title":"Git Skill","uri":"/git-skill/"},{"categories":["文档"],"content":"列出所有的远程分支 ## -r 参数相当于：remote git branch -r ","date":"2023-06-03","objectID":"/git-skill/:11:0","tags":["git"],"title":"Git Skill","uri":"/git-skill/"},{"categories":["文档"],"content":"列出本地和远程分支 ## -a 参数相当于：all git branch -a ","date":"2023-06-03","objectID":"/git-skill/:12:0","tags":["git"],"title":"Git Skill","uri":"/git-skill/"},{"categories":["文档"],"content":"查看远程分支和本地分支的对应关系 git remote show origin ","date":"2023-06-03","objectID":"/git-skill/:13:0","tags":["git"],"title":"Git Skill","uri":"/git-skill/"},{"categories":["文档"],"content":"远程删除了分支本地也想删除 git remote prune origin ","date":"2023-06-03","objectID":"/git-skill/:14:0","tags":["git"],"title":"Git Skill","uri":"/git-skill/"},{"categories":["文档"],"content":"创建并切换到本地分支 git checkout -b \u003cbranch-name\u003e ","date":"2023-06-03","objectID":"/git-skill/:15:0","tags":["git"],"title":"Git Skill","uri":"/git-skill/"},{"categories":["文档"],"content":"从远程分支中创建并切换到本地分支 git checkout -b \u003cbranch-name\u003e origin/\u003cbranch-name\u003e ","date":"2023-06-03","objectID":"/git-skill/:16:0","tags":["git"],"title":"Git Skill","uri":"/git-skill/"},{"categories":["文档"],"content":"删除本地分支 git branch -d \u003clocal-branchname\u003e ","date":"2023-06-03","objectID":"/git-skill/:17:0","tags":["git"],"title":"Git Skill","uri":"/git-skill/"},{"categories":["文档"],"content":"删除远程分支 git push origin --delete \u003cremote-branchname\u003e ## 或者 git push origin :\u003cremote-branchname\u003e ","date":"2023-06-03","objectID":"/git-skill/:18:0","tags":["git"],"title":"Git Skill","uri":"/git-skill/"},{"categories":["文档"],"content":"重命名本地分支 git branch -m \u003cnew-branch-name\u003e ","date":"2023-06-03","objectID":"/git-skill/:19:0","tags":["git"],"title":"Git Skill","uri":"/git-skill/"},{"categories":["文档"],"content":"查看标签 git tag ## 展示当前分支的最近的 tag git describe --tags --abbrev=0 ","date":"2023-06-03","objectID":"/git-skill/:20:0","tags":["git"],"title":"Git Skill","uri":"/git-skill/"},{"categories":["文档"],"content":"查看标签的详细信息 git tag -ln ","date":"2023-06-03","objectID":"/git-skill/:21:0","tags":["git"],"title":"Git Skill","uri":"/git-skill/"},{"categories":["文档"],"content":"本地创建标签 git tag \u003cversion-number\u003e ## 默认 tag 是打在最近的一次 commit 上，如果需要指定 commit 打 tag： $ git tag -a \u003cversion-number\u003e -m \"v1.0 发布(描述)\" \u003ccommit-id\u003e ","date":"2023-06-03","objectID":"/git-skill/:22:0","tags":["git"],"title":"Git Skill","uri":"/git-skill/"},{"categories":["文档"],"content":"推送标签到远程仓库 ## 首先要保证本地创建好了标签才可以推送标签到远程仓库： git push origin \u003clocal-version-number\u003e ## 一次性推送所有标签，同步到远程仓库： git push origin --tags ","date":"2023-06-03","objectID":"/git-skill/:23:0","tags":["git"],"title":"Git Skill","uri":"/git-skill/"},{"categories":["文档"],"content":"删除本地标签 git tag -d \u003ctag-name\u003e ","date":"2023-06-03","objectID":"/git-skill/:24:0","tags":["git"],"title":"Git Skill","uri":"/git-skill/"},{"categories":["文档"],"content":"删除远程标签 git push origin --delete tag \u003ctagname\u003e ","date":"2023-06-03","objectID":"/git-skill/:25:0","tags":["git"],"title":"Git Skill","uri":"/git-skill/"},{"categories":["文档"],"content":"切回到某个标签 ## 一般上线之前都会打 tag，就是为了防止上线后出现问题，方便快速回退到上一版本。下面的命令是回到某一标签下的状态 git checkout -b branch_name tag_name ","date":"2023-06-03","objectID":"/git-skill/:26:0","tags":["git"],"title":"Git Skill","uri":"/git-skill/"},{"categories":["文档"],"content":"放弃工作区的修改 git checkout \u003cfile-name\u003e ## 或者放弃所有修改 git checkout . ","date":"2023-06-03","objectID":"/git-skill/:27:0","tags":["git"],"title":"Git Skill","uri":"/git-skill/"},{"categories":["文档"],"content":"恢复删除的文件 #得到 deleting_commit git rev-list -n 1 HEAD -- \u003cfile_path\u003e #回到删除文件 deleting_commit 之前的状态 git checkout \u003cdeleting_commit\u003e^ -- \u003cfile_path\u003e ","date":"2023-06-03","objectID":"/git-skill/:28:0","tags":["git"],"title":"Git Skill","uri":"/git-skill/"},{"categories":["文档"],"content":"以新增一个 commit 的方式还原某一个 commit 的修改 git revert \u003ccommit-id\u003e ","date":"2023-06-03","objectID":"/git-skill/:29:0","tags":["git"],"title":"Git Skill","uri":"/git-skill/"},{"categories":["文档"],"content":"回到某个 commit 的状态，并删除后面的 commit ## 和 revert 的区别：reset 命令会抹去某个 commit id 之后的所有 commit git reset \u003ccommit-id\u003e #默认就是-mixed参数。 git reset --mixed HEAD^ #回退至上个版本，它将重置HEAD到另外一个commit,并且重置暂存区以便和HEAD相匹配，但是也到此为止。工作区不会被更改。 git reset --soft HEAD~3 #回退至三个版本之前，只回退了commit的信息，暂存区和工作区与回退之前保持一致。如果还要提交，直接commit即可 git reset --hard \u003ccommit-id\u003e #彻底回退到指定commit-id的状态，暂存区和工作区也会变为指定commit-id版本的内容 ","date":"2023-06-03","objectID":"/git-skill/:30:0","tags":["git"],"title":"Git Skill","uri":"/git-skill/"},{"categories":["文档"],"content":"修改上一个 commit 的描述 ## 如果暂存区有改动，同时也会将暂存区的改动提交到上一个 commit git commit --amend ","date":"2023-06-03","objectID":"/git-skill/:31:0","tags":["git"],"title":"Git Skill","uri":"/git-skill/"},{"categories":["文档"],"content":"查看 commit 历史 git log ","date":"2023-06-03","objectID":"/git-skill/:32:0","tags":["git"],"title":"Git Skill","uri":"/git-skill/"},{"categories":["文档"],"content":"查看某段代码是谁写的 ## blame 的意思为‘责怪’，你懂的。 git blame \u003cfile-name\u003e ","date":"2023-06-03","objectID":"/git-skill/:33:0","tags":["git"],"title":"Git Skill","uri":"/git-skill/"},{"categories":["文档"],"content":"显示本地更新过 HEAD 的 git 命令记录 ## 每次更新了 HEAD 的 git 命令比如 commit、amend、cherry-pick、reset、revert 等都会被记录下来（不限分支），就像 shell 的 history 一样。 这样你可以 reset 到任何一次更新了 HEAD 的操作之后，而不仅仅是回到当前分支下的某个 commit 之后的状态 git reflog ","date":"2023-06-03","objectID":"/git-skill/:34:0","tags":["git"],"title":"Git Skill","uri":"/git-skill/"},{"categories":["文档"],"content":"修改作者名 git commit --amend --author='Author Name \u003cemail@address.com\u003e' ","date":"2023-06-03","objectID":"/git-skill/:35:0","tags":["git"],"title":"Git Skill","uri":"/git-skill/"},{"categories":["文档"],"content":"修改远程仓库的 url git remote set-url origin \u003cURL\u003e ","date":"2023-06-03","objectID":"/git-skill/:36:0","tags":["git"],"title":"Git Skill","uri":"/git-skill/"},{"categories":["文档"],"content":"增加远程仓库 git remote add origin \u003cremote-url\u003e ","date":"2023-06-03","objectID":"/git-skill/:37:0","tags":["git"],"title":"Git Skill","uri":"/git-skill/"},{"categories":["文档"],"content":"列出所有远程仓库 git remote ","date":"2023-06-03","objectID":"/git-skill/:38:0","tags":["git"],"title":"Git Skill","uri":"/git-skill/"},{"categories":["文档"],"content":"查看两个星期内的改动 git whatchanged --since='2 weeks ago' ","date":"2023-06-03","objectID":"/git-skill/:39:0","tags":["git"],"title":"Git Skill","uri":"/git-skill/"},{"categories":["文档"],"content":"把 A 分支的某一个 commit，放到 B 分支上 ## 这个过程需要 cherry-pick 命令 git checkout \u003cbranch-name\u003e \u0026\u0026 git cherry-pick \u003ccommit-id\u003e ","date":"2023-06-03","objectID":"/git-skill/:40:0","tags":["git"],"title":"Git Skill","uri":"/git-skill/"},{"categories":["文档"],"content":"给 git 命令起别名 git config --global alias.\u003chandle\u003e \u003ccommand\u003e 比如：git status 改成 git st，这样可以简化命令 git config --global alias.st status ","date":"2023-06-03","objectID":"/git-skill/:41:0","tags":["git"],"title":"Git Skill","uri":"/git-skill/"},{"categories":["文档"],"content":"存储当前的修改，但不用提交 commit 详解可以参考廖雪峰老师的 git 教程 https://www.liaoxuefeng.com/wiki/896043488029600/900388704535136 git stash ","date":"2023-06-03","objectID":"/git-skill/:42:0","tags":["git"],"title":"Git Skill","uri":"/git-skill/"},{"categories":["文档"],"content":"保存当前状态，包括 untracked 的文件 ## untracked 文件：新建的文件 git stash -u ## 展示所有 stashes git stash list ## 回到某个 stash 的状态 git stash apply \u003cstash@{n}\u003e ## 回到最后一个 stash 的状态，并删除这个 stash git stash pop ## 删除所有的 stash git stash clear ## 从 stash 中拿出某个文件的修改 git checkout \u003cstash@{n}\u003e -- \u003cfile-path\u003e ## 展示所有 tracked 的文件 git ls-files -t ## 展示所有 untracked 的文件 git ls-files --others ","date":"2023-06-03","objectID":"/git-skill/:43:0","tags":["git"],"title":"Git Skill","uri":"/git-skill/"},{"categories":["文档"],"content":"展示所有忽略的文件 git ls-files --others -i --exclude-standard ","date":"2023-06-03","objectID":"/git-skill/:44:0","tags":["git"],"title":"Git Skill","uri":"/git-skill/"},{"categories":["文档"],"content":"展示简化的 commit 历史 git log --pretty=oneline --graph --decorate --all ","date":"2023-06-03","objectID":"/git-skill/:45:0","tags":["git"],"title":"Git Skill","uri":"/git-skill/"},{"categories":["文档"],"content":"把某一个分支导出成一个文件 git bundle create \u003cfile\u003e \u003cbranch-name\u003e ","date":"2023-06-03","objectID":"/git-skill/:46:0","tags":["git"],"title":"Git Skill","uri":"/git-skill/"},{"categories":["文档"],"content":"从包中导入分支 ## 新建一个分支，分支内容就是上面 git bundle create 命令导出的内容 git clone repo.bundle \u003crepo-dir\u003e -b \u003cbranch-name\u003e ","date":"2023-06-03","objectID":"/git-skill/:47:0","tags":["git"],"title":"Git Skill","uri":"/git-skill/"},{"categories":["文档"],"content":"从远程仓库根据 ID，拉下某一状态，到本地分支 git fetch origin pull/\u003cid\u003e/head:\u003cbranch-name\u003e ","date":"2023-06-03","objectID":"/git-skill/:48:0","tags":["git"],"title":"Git Skill","uri":"/git-skill/"},{"categories":["文档"],"content":"清除 gitignore 文件中记录的文件 git clean -X -f ","date":"2023-06-03","objectID":"/git-skill/:49:0","tags":["git"],"title":"Git Skill","uri":"/git-skill/"},{"categories":["文档"],"content":"展示所有 alias 和 configs ## 注意： config 分为：当前目录（local）和全局（golbal）的 config，默认为当前目录的 config git config --local --list (当前目录) git config --global --list (全局) ","date":"2023-06-03","objectID":"/git-skill/:50:0","tags":["git"],"title":"Git Skill","uri":"/git-skill/"},{"categories":["文档"],"content":"展示忽略的文件 git status --ignored ","date":"2023-06-03","objectID":"/git-skill/:51:0","tags":["git"],"title":"Git Skill","uri":"/git-skill/"},{"categories":["文档"],"content":"删除全局设置 git config --global --unset \u003centry-name\u003e ","date":"2023-06-03","objectID":"/git-skill/:52:0","tags":["git"],"title":"Git Skill","uri":"/git-skill/"},{"categories":["文档"],"content":"新建并切换到新分支上，同时这个分支没有任何 commit ## 相当于保存修改，但是重写 commit 历史 git checkout --orphan \u003cbranch-name\u003e ","date":"2023-06-03","objectID":"/git-skill/:53:0","tags":["git"],"title":"Git Skill","uri":"/git-skill/"},{"categories":["文档"],"content":"git checkout –orphan git show \u003cbranch-name\u003e:\u003cfile-name\u003e ","date":"2023-06-03","objectID":"/git-skill/:54:0","tags":["git"],"title":"Git Skill","uri":"/git-skill/"},{"categories":["文档"],"content":"clone 下来指定的单一分支 git clone -b \u003cbranch-name\u003e --single-branch https://github.com/user/repo.git ","date":"2023-06-03","objectID":"/git-skill/:55:0","tags":["git"],"title":"Git Skill","uri":"/git-skill/"},{"categories":["文档"],"content":"忽略文件的权限变化 ## 不再将文件的权限变化视作改动 git config core.fileMode false ","date":"2023-06-03","objectID":"/git-skill/:56:0","tags":["git"],"title":"Git Skill","uri":"/git-skill/"},{"categories":["文档"],"content":"在 commit log 中查找相关内容 ## 通过 grep 查找，given-text：所需要查找的字段 git log --all --grep='\u003cgiven-text\u003e' ","date":"2023-06-03","objectID":"/git-skill/:57:0","tags":["git"],"title":"Git Skill","uri":"/git-skill/"},{"categories":["文档"],"content":"把暂存区的指定 file 放到工作区中 ## 不添加参数，默认是 -mixed git reset \u003cfile-name\u003e ","date":"2023-06-03","objectID":"/git-skill/:58:0","tags":["git"],"title":"Git Skill","uri":"/git-skill/"},{"categories":["文档"],"content":"强制推送 git push -f \u003cremote-name\u003e \u003cbranch-name\u003e ","date":"2023-06-03","objectID":"/git-skill/:59:0","tags":["git"],"title":"Git Skill","uri":"/git-skill/"},{"categories":["文档"],"content":" go-work (figure) 🔥Golang算法 - 递归 递归： 在运行的过程中调用自己 ","date":"2023-05-30","objectID":"/golang-recursion01/:0:0","tags":["golang","算法"],"title":"🔥Golang Recursion","uri":"/golang-recursion01/"},{"categories":["文档"],"content":"递归函数 关键点 在同一函数调用的函数 在递归函数中指定一个退出条件总是好的 它可以检查不必要的函数调用和代码行 递归的缺点 代码逻辑性强， 难以调试和代码检查 go-work (figure) 示例 package main import \"fmt\" func main() { doll := Item{ ID: 1, Type: \"doll\", Child: \u0026Item{ ID: 2, Type: \"doll\", Child: \u0026Item{ ID: 3, Type: \"doll\", Child: \u0026Item{ ID: 4, Type: \"diamond\", Child: nil, }, }, }, } diamond := findDiamond(doll) fmt.Printf(\"Item %d is diamond\\n\", diamond.ID) } func findDiamond(item Item) Item { if item.IsDoll() { return findDiamond(*item.Child) } else { return item } } type Item struct { ID int Type string Child *Item } type ItemClassifier interface { IsDoll() bool } func (it *Item) IsDoll() bool { if it.Type == \"doll\" { return true } return false } 输出结果 go run main.go Item 4 is diamond 示例二 （递归函数实现斐波那契数） package main import \"fmt\" func fibonacci(n int) int { if n \u003c 2 { return n } return fibonacci(n-2) + fibonacci(n-1) } func main() { var i int for i = 0; i \u003c 10; i++ { fmt.Printf(\"%d\\t\", fibonacci(i)) } } ","date":"2023-05-30","objectID":"/golang-recursion01/:1:0","tags":["golang","算法"],"title":"🔥Golang Recursion","uri":"/golang-recursion01/"},{"categories":["文档"],"content":" go-work (figure) Golang context 实现原理 context的主要功能 异步场景中用于实现并发协调 对goroutine 的生命周期控制 有一定的数据存储能力 context 的数据结构 type Context interface { Deadline() (deadline time.Time, ok bool) Done() \u003c-chan struct{} Err() error Value(key any) any } Context 为interface， 定义了四个核心api Deadline： 返回context的过期时间 Done： 返回context中的channel Err： 返回错误 value： 返回context中的对应的key值 ","date":"2023-05-29","objectID":"/golang-context/:0:0","tags":["golang"],"title":"Golang Context 底层原理","uri":"/golang-context/"},{"categories":["文档"],"content":"标准 error var Canceled = errors.New(\"context canceled\") var DeadlineExceeded error = deadlineExceededError{} type deadlineExceededError struct{} func (deadlineExceededError) Error() string { return \"context deadline exceeded\" } func (deadlineExceededError) Timeout() bool { return true } func (deadlineExceededError) Temporary() bool { return true canceled： context 被canel时会报此错误 DeadlineExceeded: context 超时时会报此错误 ","date":"2023-05-29","objectID":"/golang-context/:0:1","tags":["golang"],"title":"Golang Context 底层原理","uri":"/golang-context/"},{"categories":["文档"],"content":"emptyCtx 类的实现 type emptyCtx int func (*emptyCtx) Deadline() (deadline time.Time, ok bool) { return } func (*emptyCtx) Done() \u003c-chan struct{} { return nil } func (*emptyCtx) Err() error { return nil } func (*emptyCtx) Value(key any) any { return } emptyCtx时一个空的context， 本质上类型为一个整型 Deadline 方法会返回一个公元元年时间以及 false 的 flag，标识当前 context 不存在过期时间； Done： 方法返回一个nil 值，用户无论在nil中写入或者读取数据，都会陷入阻塞 Err： 方法返回的错误永远为nil Value： 方法返回的value同样永远为nil ","date":"2023-05-29","objectID":"/golang-context/:0:2","tags":["golang"],"title":"Golang Context 底层原理","uri":"/golang-context/"},{"categories":["文档"],"content":"context.Background() \u0026 context.TODO() var ( background = new(emptyCtx) todo = new(emptyCtx) ) func Background() Context { return background } func TODO() Context { return todo } 常用的 context.Background() 和 context.TODO() 方法返回的均是 emptyCtx 类型的一个实例. ","date":"2023-05-29","objectID":"/golang-context/:0:3","tags":["golang"],"title":"Golang Context 底层原理","uri":"/golang-context/"},{"categories":["文档"],"content":"cancelCtx 数据结构 go-work (figure) type cancelCtx struct { Context mu sync.Mutex // protects following fields done atomic.Value // of chan struct{}, created lazily, closed by first cancel call children map[canceler]struct{} // set to nil by the first cancel call err error // set to non-nil by the first cancel call } type canceler interface { cancel(removeFromParent bool, err error) Done() \u003c-chan struct{} } embed 了context作为其父context， cancelCtx必然为某个context的子context 内置了一把锁， 用以协调并发场景下的资源获取 done： 实际类型为chan struct{}, 即用以反映 cancelCtx生命周期的通道 children： 一个set 指cancelCtx 的所有子context err： 记录了当前cancelCtx的错误， 必然为某一个context的子context ","date":"2023-05-29","objectID":"/golang-context/:1:0","tags":["golang"],"title":"Golang Context 底层原理","uri":"/golang-context/"},{"categories":["文档"],"content":"Deadline 方法 cancelCtx 未实现该方法， 仅时embed了一个带有 Deadline 方法的Context interface 因此直接 调用会报错 ","date":"2023-05-29","objectID":"/golang-context/:1:1","tags":["golang"],"title":"Golang Context 底层原理","uri":"/golang-context/"},{"categories":["文档"],"content":"Done 方法 go-work (figure) func (c *cancelCtx) Done() \u003c-chan struct{} { d := c.done.Load() if d != nil { return d.(chan struct{}) } c.mu.Lock() defer c.mu.Unlock() d = c.done.Load() if d == nil { d = make(chan struct{}) c.done.Store(d) } return d.(chan struct{}) } 基于atomic 包， 读取 cancelCtx中的chan； 倘若已存在，则直接返回 加锁后， 在此检查chan是否存在， 若存在则返回， 初始化 chan 存储到 aotmic.Value 当中，并返回.（懒加载机制） ","date":"2023-05-29","objectID":"/golang-context/:1:2","tags":["golang"],"title":"Golang Context 底层原理","uri":"/golang-context/"},{"categories":["文档"],"content":"Err 方法 func (c *cancelCtx) Err() error { c.mu.Lock() err := c.err c.mu.Unlock() return err } 加锁； 读取 cancelCtx.err； 解锁 返回结果 ","date":"2023-05-29","objectID":"/golang-context/:1:3","tags":["golang"],"title":"Golang Context 底层原理","uri":"/golang-context/"},{"categories":["文档"],"content":"Value方法 func (c *cancelCtx) Value(key any) any { if key == \u0026cancelCtxKey { return c } return value(c.Context, key) } 倘若 key 特定值 \u0026cancelCtxKey，则返回 cancelCtx 自身的指针； 否则遵循 valueCtx 的思路取值返回 ","date":"2023-05-29","objectID":"/golang-context/:1:4","tags":["golang"],"title":"Golang Context 底层原理","uri":"/golang-context/"},{"categories":["文档"],"content":"context.WithCancel() func WithCancel(parent Context) (ctx Context, cancel CancelFunc) { if parent == nil { panic(\"cannot create context from nil parent\") } c := newCancelCtx(parent) propagateCancel(parent, \u0026c) return \u0026c, func() { c.cancel(true, Canceled) } } 校验父 context 非空； 注入父 context 构造好一个新的 cancelCtx； 在 propagateCancel 方法内启动一个守护协程，以保证父 context 终止时，该 cancelCtx 也会被终止； 将 cancelCtx 返回，连带返回一个用以终止该 cancelCtx 的闭包函数. ","date":"2023-05-29","objectID":"/golang-context/:2:0","tags":["golang"],"title":"Golang Context 底层原理","uri":"/golang-context/"},{"categories":["文档"],"content":"newCancelCtx func newCancelCtx(parent Context) cancelCtx { return cancelCtx{Context: parent} } ","date":"2023-05-29","objectID":"/golang-context/:2:1","tags":["golang"],"title":"Golang Context 底层原理","uri":"/golang-context/"},{"categories":["文档"],"content":"propagateCancel go-work (figure) func propagateCancel(parent Context, child canceler) { done := parent.Done() if done == nil { return // parent is never canceled } select { case \u003c-done: // parent is already canceled child.cancel(false, parent.Err()) return default: } if p, ok := parentCancelCtx(parent); ok { p.mu.Lock() if p.err != nil { // parent has already been canceled child.cancel(false, p.err) } else { if p.children == nil { p.children = make(map[canceler]struct{}) } p.children[child] = struct{}{} } p.mu.Unlock() } else { atomic.AddInt32(\u0026goroutines, +1) go func() { select { case \u003c-parent.Done(): child.cancel(false, parent.Err()) case \u003c-child.Done(): } }() } } propagateCancel 用以传递父子 context 之间的 cancel 事件： • 倘若 parent 是不会被 cancel 的类型（如 emptyCtx），则直接返回； • 倘若 parent 已经被 cancel，则直接终止子 context，并以 parent 的 err 作为子 context 的 err； • 假如 parent 是 cancelCtx 的类型，则加锁，并将子 context 添加到 parent 的 children map 当中； • 假如 parent 不是 cancelCtx 类型，但又存在 cancel 的能力（比如用户自定义实现的 context），则启动一个协程，通过多路复用的方式监控 parent 状态，倘若其终止，则同时终止子 context，并透传 parent 的 err. ","date":"2023-05-29","objectID":"/golang-context/:2:2","tags":["golang"],"title":"Golang Context 底层原理","uri":"/golang-context/"},{"categories":["文档"],"content":"cancelCtx.cancel go-work (figure) func (c *cancelCtx) cancel(removeFromParent bool, err error) { if err == nil { panic(\"context: internal error: missing cancel error\") } c.mu.Lock() if c.err != nil { c.mu.Unlock() return // already canceled } c.err = err d, _ := c.done.Load().(chan struct{}) if d == nil { c.done.Store(closedchan) } else { close(d) } for child := range c.children { // NOTE: acquiring the child's lock while holding parent's lock. child.cancel(false, err) } c.children = nil c.mu.Unlock() if removeFromParent { removeChild(c.Context, c) } } cancelCtx.cancel 方法有两个入参，第一个 removeFromParent 是一个 bool 值，表示当前 context 是否需要从父 context 的 children set 中删除；第二个 err 则是 cancel 后需要展示的错误； 进入方法主体，首先校验传入的 err 是否为空，若为空则 panic； 加锁； 校验 cancelCtx 自带的 err 是否已经非空，若非空说明已被 cancel，则解锁返回； 将传入的 err 赋给 cancelCtx.err； 处理 cancelCtx 的 channel，若 channel 此前未初始化，则直接注入一个 closedChan，否则关闭该 channel； 遍历当前 cancelCtx 的 children set，依次将 children context 都进行 cancel； 解锁. 根据传入的 removeFromParent flag 判断是否需要手动把 cancelCtx 从 parent 的 children set 中移除. removeChild 方法中，观察如何将 cancelCtx 从 parent 的 children set 中移除： func removeChild(parent Context, child canceler) { p, ok := parentCancelCtx(parent) if !ok { return } p.mu.Lock() if p.children != nil { delete(p.children, child) } p.mu.Unlock() } 如果 parent 不是 cancelCtx，直接返回（因为只有 cancelCtx 才有 children set） 加锁； 从 parent 的 children set 中删除对应 child 解锁返回. ","date":"2023-05-29","objectID":"/golang-context/:3:0","tags":["golang"],"title":"Golang Context 底层原理","uri":"/golang-context/"},{"categories":["文档"],"content":"timerCtx类 go-work (figure) type timerCtx struct { cancelCtx timer *time.Timer // Under cancelCtx.mu. deadline time.Time } timerCtx 在 cancelCtx 基础上又做了一层封装，除了继承 cancelCtx 的能力之外，新增了一个 time.Timer 用于定时终止 context；另外新增了一个 deadline 字段用于字段 timerCtx 的过期时间 ","date":"2023-05-29","objectID":"/golang-context/:4:0","tags":["golang"],"title":"Golang Context 底层原理","uri":"/golang-context/"},{"categories":["文档"],"content":"valueCtx go-work (figure) type valueCtx struct { Context key, val any } valueCtx 同样继承了一个 parent context； 一个 valueCtx 中仅有一组 kv 对 ","date":"2023-05-29","objectID":"/golang-context/:5:0","tags":["golang"],"title":"Golang Context 底层原理","uri":"/golang-context/"},{"categories":["文档"],"content":"valueCtx.Value() go-work (figure) func (c *valueCtx) Value(key any) any { if c.key == key { return c.val } return value(c.Context, key) } 假如当前 valueCtx 的 key 等于用户传入的 key，则直接返回其 value； 假如不等，则从 parent context 中依次向上寻找. func value(c Context, key any) any { for { switch ctx := c.(type) { case *valueCtx: if key == ctx.key { return ctx.val } c = ctx.Context case *cancelCtx: if key == \u0026cancelCtxKey { return c } c = ctx.Context case *timerCtx: if key == \u0026cancelCtxKey { return \u0026ctx.cancelCtx } c = ctx.Context case *emptyCtx: return nil default: return c.Value(key) } } } 启动一个 for 循环，由下而上，由子及父，依次对 key 进行匹配； 其中 cancelCtx、timerCtx、emptyCtx 类型会有特殊的处理方式； 找到匹配的 key，则将该组 value 进行返回 ","date":"2023-05-29","objectID":"/golang-context/:5:1","tags":["golang"],"title":"Golang Context 底层原理","uri":"/golang-context/"},{"categories":["文档"],"content":" go-work (figure) 🔥Golang算法- 选择排序（Selection Sort) 在未排序序列中找到最小（大）元素，存放到排序序列的起始位置， 然后，再从剩余未排序元素中继续寻找最小（大）元素， 然后放到已排序序列的末尾。 以此类推，直到所有元素均排序完毕。 示例 package main import \"fmt\" func main() { arr := []int{5, 7, 1, 8, 3, 2, 6, 4, 9} arr = selectionSort(arr) fmt.Println(arr) } func findSmallest(arr []int) int { smallest := arr[0] smallestIndex := 0 for i := 0; i \u003c len(arr); i++ { if arr[i] \u003c smallest { smallest = arr[i] smallestIndex = i } } return smallestIndex } func selectionSort(arr []int) []int { result := []int{} count := len(arr) for i := 0; i \u003c count; i++ { smallestIndex := findSmallest(arr) result = append(result, arr[smallestIndex]) arr = append(arr[:smallestIndex], arr[smallestIndex+1:]...) } return result } 输出结果 go run main.go [1 2 3 4 5 6 7 8 9] ","date":"2023-05-29","objectID":"/golang-selectionsort/:0:0","tags":["golang","算法"],"title":"🔥Golang Selection Sort","uri":"/golang-selectionsort/"},{"categories":["文档"],"content":" 🔥Golang算法- 二分算法（Binary Search） 输入：排好序 的集合 如果要查询的元素在集合中： 返回位置（索引） 否则：返回空 ","date":"2023-05-27","objectID":"/golang-binarysearch/:0:0","tags":["golang","算法"],"title":"🚀Golang BinarySearch","uri":"/golang-binarysearch/"},{"categories":["文档"],"content":"Binary Search 介绍 针对拥有n个元素的一排序的集合 二分查找： log2n 简单查找： n ⚠️注意 二分查找只适用于已排序的集合 示例 package main import ( \"fmt\" \"math/rand\" \"time\" ) func main() { list := make([]int, 1_000_000) for i := 0; i \u003c 1_000_000; i++ { list = append(list, i+1) } rand.Seed(time.Now().UnixNano()) for i := 0; i \u003c 20; i++ { v := rand.Intn(1_000_000-1) + 1 fmt.Printf(\"针对 %d 进行二分查找： \\n\", v) idx := binarySearch(list, v) fmt.Printf(\"%d 的索引位置是：[%d]\\n\", v, idx) fmt.Println(\"-------------------------------\") } } func binarySearch(list []int, target int) int { low := 0 high := len(list) step := 0 for { step = step + 1 if low \u003c= high { mid := (low + high) / 2 guess := list[mid] if guess == target { fmt.Printf(\"共查找了 %d 次\\n\", step) return mid } if guess \u003e target { high = mid + 1 } else { low = mid - 1 } } } } 输出结果 go run main.go 针对 488291 进行二分查找： 共查找了 21 次 488291 的索引位置是：[1488290] ------------------------------- 针对 253611 进行二分查找： 共查找了 19 次 253611 的索引位置是：[1253610] ------------------------------- 针对 92000 进行二分查找： 共查找了 21 次 92000 的索引位置是：[1091999] ------------------------------- 针对 399702 进行二分查找： 共查找了 17 次 399702 的索引位置是：[1399701] ------------------------------- 针对 356459 进行二分查找： 共查找了 17 次 356459 的索引位置是：[1356458] ------------------------------- 针对 533248 进行二分查找： 共查找了 17 次 533248 的索引位置是：[1533247] ------------------------------- 针对 802470 进行二分查找： 共查找了 21 次 802470 的索引位置是：[1802469] ------------------------------- 针对 358966 进行二分查找： 共查找了 21 次 358966 的索引位置是：[1358965] ------------------------------- 针对 325215 进行二分查找： 共查找了 21 次 325215 的索引位置是：[1325214] ------------------------------- 针对 443265 进行二分查找： 共查找了 21 次 443265 的索引位置是：[1443264] ------------------------------- 针对 829382 进行二分查找： 共查找了 18 次 829382 的索引位置是：[1829381] ------------------------------- 针对 499513 进行二分查找： 共查找了 21 次 499513 的索引位置是：[1499512] ------------------------------- 针对 589792 进行二分查找： 共查找了 19 次 589792 的索引位置是：[1589791] ------------------------------- 针对 253817 进行二分查找： 共查找了 21 次 253817 的索引位置是：[1253816] ------------------------------- 针对 624237 进行二分查找： 共查找了 20 次 624237 的索引位置是：[1624236] ------------------------------- 针对 850665 进行二分查找： 共查找了 21 次 850665 的索引位置是：[1850664] ------------------------------- 针对 929880 进行二分查找： 共查找了 21 次 929880 的索引位置是：[1929879] ------------------------------- 针对 422010 进行二分查找： 共查找了 20 次 422010 的索引位置是：[1422009] ------------------------------- 针对 39939 进行二分查找： 共查找了 21 次 39939 的索引位置是：[1039938] ------------------------------- 针对 894763 进行二分查找： 共查找了 19 次 894763 的索引位置是：[1894762] ------------------------------- ","date":"2023-05-27","objectID":"/golang-binarysearch/:1:0","tags":["golang","算法"],"title":"🚀Golang BinarySearch","uri":"/golang-binarysearch/"},{"categories":["文档"],"content":" Golang 命令行参数os.Args 如何制作命令行应用 如何使用os.Args 获取命令行参数 ","date":"2023-05-27","objectID":"/golang-args/:0:0","tags":["golang"],"title":"Golang 命令行参数os.Args","uri":"/golang-args/"},{"categories":["文档"],"content":"使用的知识点 os包提供了用于处理操作系统的相关内容的函数/值 独立于平台的方式 os.Args 变量 获取命令行的参数 它是string slice 第一个值是命令本身 strings.Join 函数 将字符串切片中存在的所有元素连接为单个字符串 示例01 package main import ( \"fmt\" \"os\" ) func main() { var s, sep string for i := 0; i \u003c len(os.Args); i++ { s += sep + os.Args[i] sep = \" \" } fmt.Println(s) } 示例02 package main import ( \"fmt\" \"os\" ) func main() { s, sep := \"\", \"\" for _, args := range os.Args[1:] { s += sep + args sep = \" \" } fmt.Println(s) } 示例03 package main import ( \"fmt\" \"os\" \"strings\" ) func main() { fmt.Println(strings.Join(os.Args[1:], \" \")) } ","date":"2023-05-27","objectID":"/golang-args/:1:0","tags":["golang"],"title":"Golang 命令行参数os.Args","uri":"/golang-args/"},{"categories":["文档"],"content":"用户输入bufio package main import ( \"bufio\" \"fmt\" \"os\" ) func main() { fmt.Println(\"Waht's your name\") reader := bufio.NewReader(os.Stdin) text, _ := reader.ReadString('\\n') fmt.Printf(\"your name: %s\", text) } ","date":"2023-05-27","objectID":"/golang-args/:2:0","tags":["golang"],"title":"Golang 命令行参数os.Args","uri":"/golang-args/"},{"categories":["文档"],"content":" Golang TCP 端口扫描 非并发版 package main import ( \"fmt\" \"net\" ) func main() { for i := 21; i \u003c 120; i++ { address := fmt.Sprintf(\"192.168.0.2:%d\", i) conn, err := net.Dial(\"tcp\", address) if err != nil { fmt.Printf(\"%d 关闭了\\n\", address) continue } conn.Close() fmt.Printf(\"%d dakai了\\n\", address) } } 并发版 package main import ( \"fmt\" \"net\" \"sync\" \"time\" ) func main() { start := time.Now() var wg sync.WaitGroup for i := 21; i \u003c 120; i++ { wg.Add(1) go func(j int) { address := fmt.Sprintf(\"192.168.0.2:%d\", j) conn, err := net.Dial(\"tcp\", address) if err != nil { fmt.Printf(\"%d 关闭了\\n\", address) return } conn.Close() fmt.Printf(\"%d dakai了\\n\", address) }(i) wg.Wait() elapsed := time.Since(start) / 1e9 fmt.Printf(\"\\n\\n%d\\n\", elapsed) } } goroutine 池并发版 TCP 端口扫描器 go-work (figure) package main import ( \"fmt\" \"net\" \"sort\" ) func worker(ports chan int, results chan int) { for p := range ports { address := fmt.Sprintf(\"192.168.1.1:%d\", p) conn, err := net.Dial(\"tcp\", address) if err != nil { results \u003c- 0 fmt.Printf(\"%d 关闭了 \\n\", p) } conn.Close() fmt.Printf(\"%d 打开了\", p) results \u003c- p } } func main() { ports := make(chan int, 100) results := make(chan int) var openports []int var closeports []int for i := 0; i \u003c cap(ports); i++ { go worker(ports, results) } go func() { for i := 1; i \u003c 1024; i++ { ports \u003c- i } }() for i := 1; i \u003c 1024; i++ { port := \u003c- results if port != 0 { openports = append(openports, port) } else { closeports = append(closeports, port) } } close(ports) close(results) sort.Ints(openports) sort.Ints(closeports) for _, port := range openports { fmt.Printf(\"%d open\\n\", port) } for _, port := range closeports { fmt.Printf(\"%d close\\n\", port) } } 参考视频 ","date":"2023-05-26","objectID":"/golang-portscan/:0:0","tags":["golang"],"title":"Golang PortScan","uri":"/golang-portscan/"},{"categories":["文档"],"content":" K8s-GVK\u0026FVR ","date":"2023-05-26","objectID":"/k8s-gvk_gvr/:0:0","tags":["k8s"],"title":"K8s GVK_GVR","uri":"/k8s-gvk_gvr/"},{"categories":["文档"],"content":"GVK \u0026 GVR 介绍 GVK —— group 、version、 kind GVR —— group 、version 、resource ","date":"2023-05-26","objectID":"/k8s-gvk_gvr/:1:0","tags":["k8s"],"title":"K8s GVK_GVR","uri":"/k8s-gvk_gvr/"},{"categories":["文档"],"content":"kind 和 resource 概念 在编码过程中， 资源数据存储都是结构体存储 多版本version存储在（alpha1，beta1，v1等），不同版本中存储结构体的存在着差异 用 Kind 名（如 Deployment），并不能准确获取到其使用哪个版本结构体 采用 GVK 获取到一个具体的 存储结构体，也就是 GVK 的三个信息（group/verion/kind) 确定一个 Go type（结构体） Scheme 存储了 GVK 和 Go type 的映射关系 创建资源， 编写yaml，提交请求 编写 yaml 过程中，我们会写 apiversion 和 kind，其实就是 GVK 与 apiserver 通信是 http 形式，就是将请求发送到某一 http path http path 其实就是 GVR /apis/batch/v1/namespaces/default/job 这个就是表示 default 命名空间的 job 资源 ","date":"2023-05-26","objectID":"/k8s-gvk_gvr/:1:1","tags":["k8s"],"title":"K8s GVK_GVR","uri":"/k8s-gvk_gvr/"},{"categories":["文档"],"content":"相同名称 Kind 可以存在不同组 相同名称的kind不仅可以存在不同的Version， 也可以存在不同的group Ingress, NetworkPolicy同时在这个两个API Group： extensions、 networking.k8s.io Deployment, DaemonSet, ReplicaSet同时在这些API Group中：extensions、 apps Event同时在这些API Group中： core group and events.k8s.io ","date":"2023-05-26","objectID":"/k8s-gvk_gvr/:2:0","tags":["k8s"],"title":"K8s GVK_GVR","uri":"/k8s-gvk_gvr/"},{"categories":["文档"],"content":"API-group 资源分组 各组可以单独打开或者关闭 各组可以有自己独立的版本， 不影响其他组的情况下可以单独衍化 同一个资源可以同时存在于多个不同组中，这样就可以同时支持某个特定资源稳定版本与实验版本 kubernetes API 查看当前 kubernetes 集群支持的 API 版本 $ kubectl api-versions apiextensions.k8s.io/v1beta1 apiregistration.k8s.io/v1beta1 apps/v1beta1 apps/v1beta2 authentication.k8s.io/v1 authentication.k8s.io/v1beta1 authorization.k8s.io/v1 authorization.k8s.io/v1beta1 autoscaling/v1 autoscaling/v2beta1 batch/v1 batch/v1beta1 certificates.k8s.io/v1beta1 custom-metrics.metrics.k8s.io/v1alpha1 extensions/v1beta1 monitoring.coreos.com/v1 networking.k8s.io/v1 policy/v1beta1 rbac.authorization.k8s.io/v1 rbac.authorization.k8s.io/v1beta1 storage.k8s.io/v1 storage.k8s.io/v1beta1 v1 对于同一个资源对象的不同版本，API-Server 负责不同版本之间的无损切换，这点对于客户端来说是完全透明的（无感知）。 事实上，不同版本的同类型的资源在持久化层的数据可能是相同的。 例如，对于同一种资源类型支持 v1 和 v1beta1 两个 API 版本，以 v1beta1 版本创建该资源的对象，后续可以以v1 或者 v1beta1 来更新或者删除该资源对象 ","date":"2023-05-26","objectID":"/k8s-gvk_gvr/:3:0","tags":["k8s"],"title":"K8s GVK_GVR","uri":"/k8s-gvk_gvr/"},{"categories":["文档"],"content":"GVK 与 GVR 映射 kind 是API 顶级 资源对象类型，每个资源对象都需要kind来区分自身代表的类型 kind 字段 该资源对象的类型 单个的资源对象类型（pod） 资源对象列表类型， （podlist 或者 nodelist） 特殊类型以及非吃就好类型 （很多这种类型的资源是 subresource， 例如用于绑定资源的 /binding、更新资源状态的 /status 以及读写资源实例数量的 /scale） Resource 通过http协议以JSON格式发送或者读取的资源展现形式 单个资源 （…/namespaces/default） 列表资源（…/jobs） GVR 常用于组合成 RESTful API 请求路径 GET /apis/apps/v1/namespaces/{namespace}/deployments/{name} ","date":"2023-05-26","objectID":"/k8s-gvk_gvr/:4:0","tags":["k8s"],"title":"K8s GVK_GVR","uri":"/k8s-gvk_gvr/"},{"categories":["文档"],"content":"API 存储 API-Server 是无状态的，它需要与分布式存储系统 etcd 交互来实现资源对象的持久化操作 Kubernetes 资源对象是以JSON或 Protocol Buffers 格式存储在 etcd 中 以通过配置 kube-apiserver 的启动参数 –storage-media-type 来决定想要序列化数据存入 etcd 的格式 创建一个 pod，然后使用 etcdctl 工具来查看存储在 etcd 中数据 $ cat \u003c\u003c EOF | kubectl create -f - apiVersion: v1 kind: Pod metadata: name: webserver spec: containers: - name: nginx image: nginx ports: - containerPort: 80 EOF pod/webserver created $ etcdctl --endpoints=$ETCD_URL \\ --cert /etc/kubernetes/pki/etcd/server.crt \\ --key /etc/kubernetes/pki/etcd/server.key \\ --cacert /etc/kubernetes/pki/etcd/ca.crt \\ get /registry/pods/default/webserver --prefix -w simple /registry/pods/default/webserver ... 10.244.0.5\" 客户端工具创建资源对象到然后存储到 etcd 的流程 客户端工具(kubectl) 提供一个期望状态的资源对象的序列化表示，是一样yaml格式提供 kubectl 将YAML转换为JSON 格式， 并发送给API -server 对应同类型对象的不同版本，API- SERVER 执行无损转换，对于老版本不存在的字段则存储在annotations中 API- SERVER 将接收到的对象转换为规范存储版本，这个版本由API-Server启动参数指定，通常是最稳定的版本 最后将资源对象通过JSON 或YAML方式解析并通过一个特定的key 存入etcd中 ","date":"2023-05-26","objectID":"/k8s-gvk_gvr/:5:0","tags":["k8s"],"title":"K8s GVK_GVR","uri":"/k8s-gvk_gvr/"},{"categories":["文档"],"content":" Liveness\u0026Readines ","date":"2023-05-24","objectID":"/k8s-liveness_readines/:0:0","tags":["k8s"],"title":"K8s Liveness_Readines","uri":"/k8s-liveness_readines/"},{"categories":["文档"],"content":"需求来源 实时观察应用的健康状态 获取应用的资源使用情况 拿到应用的实时日志， 进行问题的诊断和分析 ","date":"2023-05-24","objectID":"/k8s-liveness_readines/:1:0","tags":["k8s"],"title":"K8s Liveness_Readines","uri":"/k8s-liveness_readines/"},{"categories":["文档"],"content":"Liveness probe 和 Readiness probe 介绍 livenness probe 是就绪指针，判断一个pod是否处于就绪状态。 当一个pod处于就绪状态的时候 才能对外提供对应的服务，接入层的流量才能打入相应的pod 当这个pod不处于就绪状态， 接入层灰吧相应的流量从这个pod上面剔除。 Liveness01 (figure) 这个pod指针一直处于失败， 接入层流量不会打到这个pod 这个 pod 的状态从 FAIL 的状态转换成 success 的状态时，它才能够真实地承载这个流量 这个时候会由上层的判断机制来判断这个 pod 是否需要被重新拉起。那如果上层配置的重启策略是 restart always 的话，那么此时这个 pod 会直接被重新拉起。 ","date":"2023-05-24","objectID":"/k8s-liveness_readines/:2:0","tags":["k8s"],"title":"K8s Liveness_Readines","uri":"/k8s-liveness_readines/"},{"categories":["文档"],"content":"应用健康状态-使用方式 ","date":"2023-05-24","objectID":"/k8s-liveness_readines/:3:0","tags":["k8s"],"title":"K8s Liveness_Readines","uri":"/k8s-liveness_readines/"},{"categories":["文档"],"content":"探测方式 liveness指针和Readkiness指针支持三种不同的探测方式 httpGet: 通过发送http 个体请求进行判断， 当返回码是200～399 ，标识这个应用是健康的 Exec: 执行容器中的一个命令判断当前容器是否正常，当返回时0，标识容器时健康的 tcpSocket： 通过探测容器的IP和Port 进行TCP健康检查， TCP能正常建立， 标识这个容器时健康的 ","date":"2023-05-24","objectID":"/k8s-liveness_readines/:3:1","tags":["k8s"],"title":"K8s Liveness_Readines","uri":"/k8s-liveness_readines/"},{"categories":["文档"],"content":"探测结果 Success: 标识Container 通过健康检查 Failure: container没有通过健康检查，此时会有一个相应的处理，Readiness——（service层将没有通过Readiness的pod进行移除）liveness 将这个pod重新拉起， 或者删除 Unknown: 当前的执行机制没有完成执行（超时或者一些脚本没有及时返回），等待下次的机制来进行校验 ","date":"2023-05-24","objectID":"/k8s-liveness_readines/:3:2","tags":["k8s"],"title":"K8s Liveness_Readines","uri":"/k8s-liveness_readines/"},{"categories":["文档"],"content":"应用健康状态检查方式-pod Probe spec ","date":"2023-05-24","objectID":"/k8s-liveness_readines/:4:0","tags":["k8s"],"title":"K8s Liveness_Readines","uri":"/k8s-liveness_readines/"},{"categories":["文档"],"content":"exec 通过cat 一个具体文件来判断当前Liveness probe 的状态，返回0 这个pod 处于健康状态 ","date":"2023-05-24","objectID":"/k8s-liveness_readines/:4:1","tags":["k8s"],"title":"K8s Liveness_Readines","uri":"/k8s-liveness_readines/"},{"categories":["文档"],"content":"httpGet ","date":"2023-05-24","objectID":"/k8s-liveness_readines/:4:2","tags":["k8s"],"title":"K8s Liveness_Readines","uri":"/k8s-liveness_readines/"},{"categories":["文档"],"content":"tcpSocket 参数说明： initialDelaySeconds： pod启动延迟多久进行一次检查 periodSeconds： 检查的时间间隔，默认值是10秒 timeoutSeconds： 检查的超时时间 successThreshold： pod从探测失败到再一次探测成功， 锁需要的阀值次数 failureThreshold： 探测失败的重启次数， 默认值是3 ","date":"2023-05-24","objectID":"/k8s-liveness_readines/:4:3","tags":["k8s"],"title":"K8s Liveness_Readines","uri":"/k8s-liveness_readines/"},{"categories":["文档"],"content":"Liveness 与 Readiness 总结 liveness: 判断容器是否处于running ,如果容器不健康，会通过kubelet 杀掉相应的pod Readiness： 判断容器是否启动完成，如果探测一个结果不成功， 会从pod上Endpoint上移除。 ","date":"2023-05-24","objectID":"/k8s-liveness_readines/:5:0","tags":["k8s"],"title":"K8s Liveness_Readines","uri":"/k8s-liveness_readines/"},{"categories":["文档"],"content":"适用场景 liveness： 支持可以重新拉起的应用 Readiness： 应对 启动后无法立即对外提供服务的应用。 ","date":"2023-05-24","objectID":"/k8s-liveness_readines/:5:1","tags":["k8s"],"title":"K8s Liveness_Readines","uri":"/k8s-liveness_readines/"},{"categories":["文档"],"content":"应用故障排除——状态机制 k8s 的状态机制， 通过yaml的方式定义个期望到达的状态。 这个yaml的真正执行过程 各种各样的controller来负责整体的状态之间的转换 一个 Pod 的一个生命周期。刚开始它处在一个 pending 的状态，那接下来可能会转换到类似像 running，也可能转换到 Unknown，甚至可以转换到 failed。然后，当 running 执行了一段时间之后，它可以转换到类似像 successded 或者是 failed，然后当出现在 unknown 这个状态时，可能由于一些状态的恢复，它会重新恢复到 running 或者 successded 或者是 failed。 k8s 整体的一个状态就是状态机制的转换 一个pod状态位的展现 ","date":"2023-05-24","objectID":"/k8s-liveness_readines/:6:0","tags":["k8s"],"title":"K8s Liveness_Readines","uri":"/k8s-liveness_readines/"},{"categories":["文档"],"content":"应用故障排除-场景应用异常 ","date":"2023-05-24","objectID":"/k8s-liveness_readines/:7:0","tags":["k8s"],"title":"K8s Liveness_Readines","uri":"/k8s-liveness_readines/"},{"categories":["文档"],"content":"pod停留在Pending 标识没有调度器进行介入 可能是资源或端口占用 由于node selector 造成的pod无法调度 ","date":"2023-05-24","objectID":"/k8s-liveness_readines/:7:1","tags":["k8s"],"title":"K8s Liveness_Readines","uri":"/k8s-liveness_readines/"},{"categories":["文档"],"content":"Pod 停留在 waiting 表示pod的镜像没有正常拉取 可能原因 私有镜像 没有配置pod secret 镜像地址不存在 ","date":"2023-05-24","objectID":"/k8s-liveness_readines/:7:2","tags":["k8s"],"title":"K8s Liveness_Readines","uri":"/k8s-liveness_readines/"},{"categories":["文档"],"content":"Pod 不断被拉取并且可以看到 crashing 标识pod已经调度完成， 但是启动失败 需要关注应用的自身状态 查看pod的具体日志 ","date":"2023-05-24","objectID":"/k8s-liveness_readines/:7:3","tags":["k8s"],"title":"K8s Liveness_Readines","uri":"/k8s-liveness_readines/"},{"categories":["文档"],"content":"Pod 处在 Runing 但是没有正常工作 常见问题——yaml信息里可能有拼写错误 apply-validate -f pod.yaml 判断当前的yaml是否正确 如果没有问题，诊断配置的端口是否正常，以及liveness或Readiness 配置是否正确 ","date":"2023-05-24","objectID":"/k8s-liveness_readines/:7:4","tags":["k8s"],"title":"K8s Liveness_Readines","uri":"/k8s-liveness_readines/"},{"categories":["文档"],"content":"Service 无法正常的工作 因为service和底层pod之间的关联是通过selector的方式进行匹配的， pod上面配置label， 然后service通过match label的方式和pod进行关联 如果lable配置有问题，可能会造成service无法找到后面的endpoint 造成相应的service无法对外提供服务 排除这种问题 首先 看service 后面的是不是有一个真正的endpoint 其次 看这个endpoint 是否可以对外提供正常的服务 ","date":"2023-05-24","objectID":"/k8s-liveness_readines/:7:5","tags":["k8s"],"title":"K8s Liveness_Readines","uri":"/k8s-liveness_readines/"},{"categories":["文档"],"content":"应用远程调试 ","date":"2023-05-24","objectID":"/k8s-liveness_readines/:8:0","tags":["k8s"],"title":"K8s Liveness_Readines","uri":"/k8s-liveness_readines/"},{"categories":["文档"],"content":"应用远程调试 - Pod 远程调试 进入容器里进行诊断 ","date":"2023-05-24","objectID":"/k8s-liveness_readines/:8:1","tags":["k8s"],"title":"K8s Liveness_Readines","uri":"/k8s-liveness_readines/"},{"categories":["文档"],"content":"应用远程调试 - Service 远程调试 service调试 分了两部分 将服务暴露到远程的一个集群之内，让远程集群的一些应用去调用本地的一个服务，这是一条反向的一个链路 让本地的服务能够远程调用服务， 这是一条正向的链路 将 Telepresence 的一个 Proxy 应用部署到远程的 K8s 集群里面。然后将远程单一个 deployment swap 到本地的一个 application，使用的命令就是 Telepresence-swap-deployment 然后以及远程的 DEPLOYMENT_NAME。通过这种方式就可以将本地一个 application 代理到远程的 service 之上、可以将应用在远程集群里面进行本地调试 使用方式是 kubectl port-forward，然后 service 加上远程的 service name，再加上相应的 namespace，后面还可以加上一些额外的参数，比如说端口的一个映射，通过这种机制就可以把远程的一个应用代理到本地的端口之上，此时通过访问本地端口就可以访问远程的服务。 ","date":"2023-05-24","objectID":"/k8s-liveness_readines/:8:2","tags":["k8s"],"title":"K8s Liveness_Readines","uri":"/k8s-liveness_readines/"},{"categories":["文档"],"content":"kubectl-debug kubectl-debug 这个工具是依赖于 Linux namespace 的方式来去做的，它可以 datash 一个 Linux namespace 到一个额外的 container，然后在这个 container 里面执行任何的 debug 动作，其实和直接去 debug 这个 Linux namespace 是一致的。这里有一个简单的操作 通过 kubectl-debug 这条命令来去诊断远程的一个 pod 执行debug的时候，首先会拉取一些镜像， 这个镜像里会默认带一些诊断工具 当这个镜像启用的时候，它会把这个 debug container 进行启动 这个 container 和相应的你要诊断的这个 container 的 namespace 进行挂靠，类似像网络站，或者是类似像内核的一些参数，可以在这个 debug container 里面实时地进行查看。 去查看类似像 hostname、进程、netstat 等等，这个容器和需要debug的pod在同一个环境里 进行 logout 的话，相当于会把相应的这个 debug pod 杀掉 ","date":"2023-05-24","objectID":"/k8s-liveness_readines/:9:0","tags":["k8s"],"title":"K8s Liveness_Readines","uri":"/k8s-liveness_readines/"},{"categories":["文档"],"content":"Etcd etcd 是一个开源的， 高可用的分布式的 key-value 存储系统， 可以用于配制共享和服务的注册和发现 etcd具有的特点 完全复制： 集群中的每个阶段都可以使用完整的文档 高可用性： Etcd可用于避免硬件的单点故障或网络问题 一致性： 每次读取都会返回跨多主机的最新写入 简单： 包括一个定义良好、面向用户的API（gRPC） 安全： 实现了带有可选的客户端证书身份验证的自动化TLS 快速： 每秒10000次写入的基准速度 可靠： 用Raft算法实现了强一致、高可用的服务存储目录 ","date":"2023-05-23","objectID":"/golang-etcd/:0:0","tags":["golang","etcd"],"title":"Golang Etcd","uri":"/golang-etcd/"},{"categories":["文档"],"content":"etcd 的应用场景 服务发现 服务发现要解决的也是分布式系统中最常见的问题之一，即在同一个分布式集群中的进程或服务，要如何才能找到对方并建立连接。本质上来说，服务发现就是想要了解集群中是否有进程在监听 udp 或 tcp 端口，并且通过名字就可以查找和连接。 Registry (figure) 配置中心 将一些配置存放在etcd 上集中管理 这类场景的使用方式通常是这样：应用在启动的时候主动从 etcd 获取一次配置信息，同时，在 etcd 节点上注册一个 Watcher 并等待，以后每次配置有更新的时候，etcd 都会实时通知订阅者，以此达到获取最新配置信息的目的 分布式锁 因为 etcd 使用 Raft 算法保持了数据的强一致性，某次操作存储到集群中的值必然是全局一致的，所以很容易实现分布式锁。锁服务有两种使用方式，一是保持独占，二是控制时序。 保持独占即所有获取锁的用户最终只有一个可以得到。etcd 为此提供了一套实现分布式锁原子操作 CAS（CompareAndSwap）的 API。通过设置prevExist值，可以保证在多个节点同时去创建某个目录时，只有一个成功。而创建成功的用户就可以认为是获得了锁。 控制时序，即所有想要获得锁的用户都会被安排执行，但是获得锁的顺序也是全局唯一的，同时决定了执行顺序。etcd 为此也提供了一套 API（自动创建有序键），对一个目录建值时指定为POST动作，这样 etcd 会自动在目录下生成一个当前最大的值为键，存储这个新的值（客户端编号）。同时还可以使用 API 按顺序列出所有当前目录下的键值。此时这些键的值就是客户端的时序，而这些键中存储的值可以是代表客户端的编号 etcd_lock (figure) ","date":"2023-05-23","objectID":"/golang-etcd/:1:0","tags":["golang","etcd"],"title":"Golang Etcd","uri":"/golang-etcd/"},{"categories":["文档"],"content":"go 操作etcd ","date":"2023-05-23","objectID":"/golang-etcd/:2:0","tags":["golang","etcd"],"title":"Golang Etcd","uri":"/golang-etcd/"},{"categories":["文档"],"content":"安装 go get go.etcd.io/etcd/client/v3 ","date":"2023-05-23","objectID":"/golang-etcd/:3:0","tags":["golang","etcd"],"title":"Golang Etcd","uri":"/golang-etcd/"},{"categories":["文档"],"content":"put和get 操作 package main import ( \"context\" \"fmt\" \"time\" clientv3 \"go.etcd.io/etcd/client/v3\" ) // etcd client put/get demo // use etcd/clientv3 func main() { cli, err := clientv3.New(clientv3.Config{ Endpoints: []string{\"127.0.0.1:2379\"}, DialTimeout: 5 * time.Second, }) if err != nil { // handle error! fmt.Printf(\"connect to etcd failed, err:%v\\n\", err) return } fmt.Println(\"connect to etcd success\") defer cli.Close() // put ctx, cancel := context.WithTimeout(context.Background(), time.Second) _, err = cli.Put(ctx, \"demo\", \"dsb\") cancel() if err != nil { fmt.Printf(\"put to etcd failed, err:%v\\n\", err) return } // get ctx, cancel = context.WithTimeout(context.Background(), time.Second) resp, err := cli.Get(ctx, \"demo\") cancel() if err != nil { fmt.Printf(\"get from etcd failed, err:%v\\n\", err) return } for _, ev := range resp.Kvs { fmt.Printf(\"%s:%s\\n\", ev.Key, ev.Value) } } ","date":"2023-05-23","objectID":"/golang-etcd/:4:0","tags":["golang","etcd"],"title":"Golang Etcd","uri":"/golang-etcd/"},{"categories":["文档"],"content":"watch操作 watch 用来获取未来更改的通知 package main import ( \"context\" \"fmt\" \"time\" clientv3 \"go.etcd.io/etcd/client/v3\" ) // watch demo func main() { cli, err := clientv3.New(clientv3.Config{ Endpoints: []string{\"127.0.0.1:2379\"}, DialTimeout: 5 * time.Second, }) if err != nil { fmt.Printf(\"connect to etcd failed, err:%v\\n\", err) return } fmt.Println(\"Connect to etcd successful\") defer cli.Close() // watch keys:demo changes rch := cli.Watch(context.Background(), \"demo\") for wresp := range rch { for _, ev := range wresp.Events { fmt.Printf(\"Type: %s Key:%s Value:%s\\n\", ev.Type, ev.Kv.Key, ev.Kv.Value) } } } 这个程序会等待 etcd 中 demo 这个key的变化 打开终端对 demo 这个命令 设置 etcdctl put demo \"dsb01\" OK etcdctl del demo 1 etcdctl put demo \"ddd03\" OK watch 会收到的通知 Connect to etcd successful Type: PUT Key:demo Value:dsb01 Type: DELETE Key:demo Value: Type: PUT Key:demo Value:ddd03 ","date":"2023-05-23","objectID":"/golang-etcd/:4:1","tags":["golang","etcd"],"title":"Golang Etcd","uri":"/golang-etcd/"},{"categories":["文档"],"content":"lease 租约 package main import ( \"context\" \"fmt\" \"log\" \"time\" clientv3 \"go.etcd.io/etcd/client/v3\" ) // watch demo func main() { cli, err := clientv3.New(clientv3.Config{ Endpoints: []string{\"127.0.0.1:2379\"}, DialTimeout: 5 * time.Second, }) if err != nil { fmt.Printf(\"connect to etcd failed, err:%v\\n\", err) return } fmt.Println(\"Connect to etcd successful\") defer cli.Close() //etcd lease // 创建一个5s的租约 resp, err := cli.Grant(context.TODO(), 5) if err != nil { log.Fatal(err.Error()) } // 5s之后， /demo/ 这个key就会被移除 _, err = cli.Put(context.TODO(), \"/demo/\", \"bbb\", clientv3.WithLease(resp.ID)) if err != nil { log.Fatal(err.Error()) } } ","date":"2023-05-23","objectID":"/golang-etcd/:5:0","tags":["golang","etcd"],"title":"Golang Etcd","uri":"/golang-etcd/"},{"categories":["文档"],"content":"keepAlive package main import ( \"context\" \"fmt\" \"log\" \"time\" clientv3 \"go.etcd.io/etcd/client/v3\" ) // watch demo func main() { cli, err := clientv3.New(clientv3.Config{ Endpoints: []string{\"127.0.0.1:2379\"}, DialTimeout: 5 * time.Second, }) if err != nil { fmt.Printf(\"connect to etcd failed, err:%v\\n\", err) return } fmt.Println(\"Connect to etcd successful\") defer cli.Close() //etcd lease // 创建一个5s的租约 resp, err := cli.Grant(context.TODO(), 5) if err != nil { log.Fatal(err.Error()) } // 5s之后， /demo/ 这个key就会被移除 _, err = cli.Put(context.TODO(), \"/demo/\", \"bbb\", clientv3.WithLease(resp.ID)) if err != nil { log.Fatal(err.Error()) } // the key 'foo' will be kept forever ch, haerr := cli.KeepAlive(context.TODO(), resp.ID) if haerr != nil { log.Fatal(err.Error()) } for { ha := \u003c-ch fmt.Println(\"ttl: \", ha.TTL) } } ","date":"2023-05-23","objectID":"/golang-etcd/:6:0","tags":["golang","etcd"],"title":"Golang Etcd","uri":"/golang-etcd/"},{"categories":["文档"],"content":"基于etcd 实现分布式锁 go.etcd.io/etcd/client/v3/concurrency 在etcd之上实现并发操作， 如分布式锁/屏障和选举 倒入包 import \"go.etcd.io/etcd/client/v3/concurrency\" 基于etcd 实现分布式锁的示例 package main import ( \"context\" \"fmt\" \"log\" \"time\" clientv3 \"go.etcd.io/etcd/client/v3\" \"go.etcd.io/etcd/client/v3/concurrency\" ) // watch demo func main() { cli, err := clientv3.New(clientv3.Config{ Endpoints: []string{\"127.0.0.1:2379\"}, DialTimeout: 5 * time.Second, }) if err != nil { fmt.Printf(\"connect to etcd failed, err:%v\\n\", err) return } fmt.Println(\"Connect to etcd successful\") defer cli.Close() // 创建两个单独的会话来演示竞争锁 s1, err := concurrency.NewSession(cli) if err != nil { log.Fatal(err.Error()) } defer s1.Close() m1 := concurrency.NewMutex(s1, \"/my-lock/\") s2, err := concurrency.NewSession(cli) if err != nil { log.Fatal(err.Error()) } defer s2.Close() m2 := concurrency.NewMutex(s2, \"/my-lock/\") // 会话s1 获取锁 if err := m1.Lock(context.TODO()); err != nil { log.Fatal(err.Error()) } fmt.Println(\"acquired lock for s1\") m2Locked := make(chan struct{}) go func() { defer close(m2Locked) // 等待之后会话s1 释放了/my-lock/的锁 if err := m2.Lock(context.TODO()); err != nil { log.Fatal(err.Error()) } fmt.Println(\"acquired lock for s2\") }() if err := m1.Unlock(context.TODO()); err != nil { log.Fatal(err.Error()) } fmt.Println(\"release lock for s1\") \u003c-m2Locked fmt.Println(\"release lock for s2\") } 输出结果 Connect to etcd successful acquired lock for s1 release lock for s1 acquired lock for s2 release lock for s2 参考链接 https://pkg.go.dev/go.etcd.io/etcd/clientv3/concurrency https://github.com/etcd-io/etcd/tree/main/client/v3 ","date":"2023-05-23","objectID":"/golang-etcd/:7:0","tags":["golang","etcd"],"title":"Golang Etcd","uri":"/golang-etcd/"},{"categories":["文档"],"content":"MongoDB ","date":"2023-05-23","objectID":"/golang-mongodb/:0:0","tags":["golang","mongoDB"],"title":"Golang MangoDB","uri":"/golang-mongodb/"},{"categories":["文档"],"content":"MongoDB介绍 mongoDB是基于分布式文件存储的数据库，是一个介于关系型数据库和非关系数据库之间的产品 mongoDB将一条数据存储为一个文档， 数据结构由键值对组成， 其中文档类似我们编辑中用到的JSON对象，文档中的字段值可以包含其他文档/数组及文档数组 MongoDB术语 说明 SQL术语 database 数据库 database collection 集合 table document 文档 row field 字段 column index index 索引 primary key 主键 MongoDB自动将_id字段设置为主键 primary key ","date":"2023-05-23","objectID":"/golang-mongodb/:1:0","tags":["golang","mongoDB"],"title":"Golang MangoDB","uri":"/golang-mongodb/"},{"categories":["文档"],"content":"mongoDB安装 docker pull mongo:latest docker run -itd --name mongo -p 27017:27017 mongo --auth 参数说明 -p 27017:27017 ：映射容器服务的 27017 端口到宿主机的 27017 端口。外部可以直接通过 宿主机 ip:27017 访问到 mongo 的服务。 –auth：需要密码才能访问容器服务。 使用以下命令添加用户和设置密码，并且尝试连接 $ docker exec -it mongo mongosh admin # 创建一个名为 admin，密码为 123456 的用户。 \u003e db.createUser({ user:'admin',pwd:'123456',roles:[ { role:'userAdminAnyDatabase', db: 'admin'},\"readWriteAnyDatabase\"]}); # 尝试使用上面创建的用户信息进行连接。 \u003e db.auth('admin', '123456') 连接 mongo docker exec -it mongo mongosh admin ","date":"2023-05-23","objectID":"/golang-mongodb/:2:0","tags":["golang","mongoDB"],"title":"Golang MangoDB","uri":"/golang-mongodb/"},{"categories":["文档"],"content":"golang 操作mongo DB 安装mongoDB Go驱动包 go get github.com/mongodb/mongo-go-driver Go代码连接mongoDB package main import ( \"context\" \"fmt\" \"log\" \"go.mongodb.org/mongo-driver/mongo\" \"go.mongodb.org/mongo-driver/mongo/options\" ) func main() { // 设置客户端连接配置 clientOptions := options.Client().ApplyURI(\"mongodb://192.168.0.9:27017\") // 连接到MongoDB client, err := mongo.Connect(context.TODO(), clientOptions) if err != nil { log.Fatal(err) } // 检查连接 err = client.Ping(context.TODO(), nil) if err != nil { log.Fatal(err) } fmt.Println(\"Connected to MongoDB!\") } 处理数据集 // 指定获取要操作的数据集 collection := client.Database(\"demo\").Collection(\"student\") 处理完任务之后可以通过下面的命令断开与MongoDB的连接 // 断开连接 err = client.Disconnect(context.TODO()) if err != nil { log.Fatal(err) } fmt.Println(\"Connection to MongoDB closed.\") ","date":"2023-05-23","objectID":"/golang-mongodb/:3:0","tags":["golang","mongoDB"],"title":"Golang MangoDB","uri":"/golang-mongodb/"},{"categories":["文档"],"content":"连接池模式 import ( \"context\" \"time\" \"go.mongodb.org/mongo-driver/mongo\" \"go.mongodb.org/mongo-driver/mongo/options\" ) func ConnectToDB(uri, name string, timeout time.Duration, num uint64) (*mongo.Database, error) { ctx, cancel := context.WithTimeout(context.Background(), timeout) defer cancel() o := options.Client().ApplyURI(uri) o.SetMaxPoolSize(num) client, err := mongo.Connect(ctx, o) if err != nil { return nil, err } return client.Database(name), nil } ","date":"2023-05-23","objectID":"/golang-mongodb/:4:0","tags":["golang","mongoDB"],"title":"Golang MangoDB","uri":"/golang-mongodb/"},{"categories":["文档"],"content":"BSON mongoDB中的JSON文档存储在BSON的二进制表示中 BSON编码拓展了JSON表示，使其包含额外的类型如 int\\long\\date\\浮点数和decimal128， 是应用程序更容易可靠的处理、排序和比较数据 要使用BSON 需要倒入包 import \"go.mongodb.org/mongo-driver/bson\" 使用D类型构建的过滤文档的理智， 它可以用来查询name字段与’张三’或’李四’匹配的文档 bson.D{{ \"name\", bson.D{{ \"$in\", bson.A{\"张三\", \"李四\"}, }}, }} ","date":"2023-05-23","objectID":"/golang-mongodb/:5:0","tags":["golang","mongoDB"],"title":"Golang MangoDB","uri":"/golang-mongodb/"},{"categories":["文档"],"content":"CURD 定义一个Student类型 type Student struct { Name string Age int } 准备数据 s1 := Student{\"张三\", 12} s2 := Student{\"李四\", 10} s3 := Student{\"王五\", 11} 插入一条文档记录 insertResult, err := collection.InsertOne(context.TODO(), s1) if err != nil { log.Fatal(err) } fmt.Println(\"Inserted a single document: \", insertResult.InsertedID) 插入多条文档 students := []interface{}{s2, s3} insertManyResult, err := collection.InsertMany(context.TODO(), students) if err != nil { log.Fatal(err) } fmt.Println(\"Inserted multiple documents: \", insertManyResult.InsertedIDs) ","date":"2023-05-23","objectID":"/golang-mongodb/:6:0","tags":["golang","mongoDB"],"title":"Golang MangoDB","uri":"/golang-mongodb/"},{"categories":["文档"],"content":"更新文档 updateone() 方法允许你更新当个文档，需要一个筛选器文档来批评数据库中的文档， 并需要一个更新文档来描述更新操作， 使用bson.D 类型来构建筛选文档和更新文档 filter := bson.D{{\"name\", \"小兰\"}} update := bson.D{ {\"$inc\", bson.D{ {\"age\", 1}, }}, } updateResult, err := collection.UpdateOne(context.TODO(), filter, update) if err != nil { log.Fatal(err) } fmt.Printf(\"Matched %v documents and updated %v documents.\\n\", updateResult.MatchedCount, updateResult.ModifiedCount) ","date":"2023-05-23","objectID":"/golang-mongodb/:6:1","tags":["golang","mongoDB"],"title":"Golang MangoDB","uri":"/golang-mongodb/"},{"categories":["文档"],"content":"查找文档 找到一个文档，需要一个filter文档， 以及一个指向可以将结构解码为其值的指针 要查找单个文档， 使用collection.FindOne()。这个方法返回一个可以解码为值的结果 // 创建一个Student变量用来接收查询的结果 var result Student err = collection.FindOne(context.TODO(), filter).Decode(\u0026result) if err != nil { log.Fatal(err) } fmt.Printf(\"Found a single document: %+v\\n\", result) 要查找多个文档，请使用collection.Find()。此方法返回一个游标。游标提供了一个文档流，你可以通过它一次迭代和解码一个文档。当游标用完之后，应该关闭游标。下面的示例将使用options包设置一个限制以便只返回两个文档。 // 查询多个 // 将选项传递给Find() findOptions := options.Find() findOptions.SetLimit(2) // 定义一个切片用来存储查询结果 var results []*Student // 把bson.D{{}}作为一个filter来匹配所有文档 cur, err := collection.Find(context.TODO(), bson.D{{}}, findOptions) if err != nil { log.Fatal(err) } // 查找多个文档返回一个光标 // 遍历游标允许我们一次解码一个文档 for cur.Next(context.TODO()) { // 创建一个值，将单个文档解码为该值 var elem Student err := cur.Decode(\u0026elem) if err != nil { log.Fatal(err) } results = append(results, \u0026elem) } if err := cur.Err(); err != nil { log.Fatal(err) } // 完成后关闭游标 cur.Close(context.TODO()) fmt.Printf(\"Found multiple documents (array of pointers): %#v\\n\", results) ","date":"2023-05-23","objectID":"/golang-mongodb/:7:0","tags":["golang","mongoDB"],"title":"Golang MangoDB","uri":"/golang-mongodb/"},{"categories":["文档"],"content":"删除文档 使用collection.DeleteOne()或collection.DeleteMany()删除文档。如果你传递bson.D{{}}作为过滤器参数，它将匹配数据集中的所有文档。还可以使用collection. drop()删除整个数据集。 // 删除名字是小黄的那个 deleteResult1, err := collection.DeleteOne(context.TODO(), bson.D{{\"name\",\"小黄\"}}) if err != nil { log.Fatal(err) } fmt.Printf(\"Deleted %v documents in the trainers collection\\n\", deleteResult1.DeletedCount) // 删除所有 deleteResult2, err := collection.DeleteMany(context.TODO(), bson.D{{}}) if err != nil { log.Fatal(err) } fmt.Printf(\"Deleted %v documents in the trainers collection\\n\", deleteResult2.DeletedCount) 参考链接 https://pkg.go.dev/go.mongodb.org/mongo-driver/mongo ","date":"2023-05-23","objectID":"/golang-mongodb/:8:0","tags":["golang","mongoDB"],"title":"Golang MangoDB","uri":"/golang-mongodb/"},{"categories":["文档"],"content":"Redis ","date":"2023-05-23","objectID":"/golang-redis/:0:0","tags":["golang","redis"],"title":"Golang Redis","uri":"/golang-redis/"},{"categories":["文档"],"content":"Redis 介绍 Redis是一个开源的内存数据库，提供了多种不同的数据结构， 通过复制、持久化/客户端分片等特性， 方便的将Redis 拓展成一个包含数百GB的数据， 处理上百万次请求 Redis 支持的数据结构 string hashe list set sortedset bitmap stream Redis 应用场景 缓存系统，减轻mysql的压力 计数系统， 热门排行榜 利用LIST 实现队列功能 利用HyperLog 统计UV、PV等数据 使用geospatial index 进行地理位置相关的查询 ","date":"2023-05-23","objectID":"/golang-redis/:1:0","tags":["golang","redis"],"title":"Golang Redis","uri":"/golang-redis/"},{"categories":["文档"],"content":"docker 安装Reids 启动redis docker run --name redis507 -p 6379:6379 -d redis:5.0.7 连接redis server docker run -it --network host --rm redis:5.0.7 redis-cli ","date":"2023-05-23","objectID":"/golang-redis/:2:0","tags":["golang","redis"],"title":"Golang Redis","uri":"/golang-redis/"},{"categories":["文档"],"content":"go-redis库 安装 go get github.com/go-redis/redis/v8 连接 ","date":"2023-05-23","objectID":"/golang-redis/:3:0","tags":["golang","redis"],"title":"Golang Redis","uri":"/golang-redis/"},{"categories":["文档"],"content":"普通模式连接 使用redis.NewClient 函数连接Redis服务器 rdb := redis.NewClient(\u0026redis.Options{ Addr: \"localhost:6379\", Password: \"\", // 密码 DB: 0, // 数据库 PoolSize: 20, // 连接池大小 }) 谁也redis.ParseURL 函数表示数据源的字符串解析Redis opt, err := redis.ParseURL(\"redis://\u003cuser\u003e:\u003cpass\u003e@localhost:6379/\u003cdb\u003e\") if err != nil { panic(err) } rdb := redis.NewClient(opt) TLS 模式 rdb := redis.NewClient(\u0026redis.Options{ TLSConfig: \u0026tls.Config{ MinVersion: tls.VersionTLS12, // Certificates: []tls.Certificate{cert}, // ServerName: \"your.domain.com\", }, }) Redis Sentinel模式 rdb := redis.NewFailoverClient(\u0026redis.FailoverOptions{ MasterName: \"master-name\", SentinelAddrs: []string{\":9126\", \":9127\", \":9128\"}, }) Redis Cluster模式 rdb := redis.NewClusterClient(\u0026redis.ClusterOptions{ Addrs: []string{\":7000\", \":7001\", \":7002\", \":7003\", \":7004\", \":7005\"}, // 若要根据延迟或随机路由命令，请启用以下命令之一 // RouteByLatency: true, // RouteRandomly: true, }) ","date":"2023-05-23","objectID":"/golang-redis/:3:1","tags":["golang","redis"],"title":"Golang Redis","uri":"/golang-redis/"},{"categories":["文档"],"content":"基本使用 redis基础操作 // doCommand go-redis基本使用示例 func doCommand() { ctx, cancel := context.WithTimeout(context.Background(), 500*time.Millisecond) defer cancel() // 执行命令获取结果 val, err := rdb.Get(ctx, \"key\").Result() fmt.Println(val, err) // 先获取到命令对象 cmder := rdb.Get(ctx, \"key\") fmt.Println(cmder.Val()) // 获取值 fmt.Println(cmder.Err()) // 获取错误 // 直接执行命令获取错误 err = rdb.Set(ctx, \"key\", 10, time.Hour).Err() // 直接执行命令获取值 value := rdb.Get(ctx, \"key\").Val() fmt.Println(value) } 执行任意命令 Do方法可以形象任意命令 // doDemo rdb.Do 方法使用示例 func doDemo() { ctx, cancel := context.WithTimeout(context.Background(), 500*time.Millisecond) defer cancel() // 直接执行命令获取错误 err := rdb.Do(ctx, \"set\", \"key\", 10, \"EX\", 3600).Err() fmt.Println(err) // 执行命令获取结果 val, err := rdb.Do(ctx, \"get\", \"key\").Result() fmt.Println(val, err) } Redis.Nil Nil错误来表示Key不存在的错误 // getValueFromRedis redis.Nil判断 func getValueFromRedis(key, defaultValue string) (string, error) { ctx, cancel := context.WithTimeout(context.Background(), 500*time.Millisecond) defer cancel() val, err := rdb.Get(ctx, key).Result() if err != nil { // 如果返回的错误是key不存在 if errors.Is(err, redis.Nil) { return defaultValue, nil } // 出其他错了 return \"\", err } return val, nil } ","date":"2023-05-23","objectID":"/golang-redis/:4:0","tags":["golang","redis"],"title":"Golang Redis","uri":"/golang-redis/"},{"categories":["文档"],"content":"zset示例 go-redis 操作zset // zsetDemo 操作zset示例 func zsetDemo() { // key zsetKey := \"language_rank\" // value languages := []*redis.Z{ {Score: 90.0, Member: \"Golang\"}, {Score: 98.0, Member: \"Java\"}, {Score: 95.0, Member: \"Python\"}, {Score: 97.0, Member: \"JavaScript\"}, {Score: 99.0, Member: \"C/C++\"}, } ctx, cancel := context.WithTimeout(context.Background(), 500*time.Millisecond) defer cancel() // ZADD err := rdb.ZAdd(ctx, zsetKey, languages...).Err() if err != nil { fmt.Printf(\"zadd failed, err:%v\\n\", err) return } fmt.Println(\"zadd success\") // 把Golang的分数加10 newScore, err := rdb.ZIncrBy(ctx, zsetKey, 10.0, \"Golang\").Result() if err != nil { fmt.Printf(\"zincrby failed, err:%v\\n\", err) return } fmt.Printf(\"Golang's score is %f now.\\n\", newScore) // 取分数最高的3个 ret := rdb.ZRevRangeWithScores(ctx, zsetKey, 0, 2).Val() for _, z := range ret { fmt.Println(z.Member, z.Score) } // 取95~100分的 op := \u0026redis.ZRangeBy{ Min: \"95\", Max: \"100\", } ret, err = rdb.ZRangeByScoreWithScores(ctx, zsetKey, op).Result() if err != nil { fmt.Printf(\"zrangebyscore failed, err:%v\\n\", err) return } for _, z := range ret { fmt.Println(z.Member, z.Score) } } ","date":"2023-05-23","objectID":"/golang-redis/:5:0","tags":["golang","redis"],"title":"Golang Redis","uri":"/golang-redis/"},{"categories":["文档"],"content":"扫描遍历所有Key 使用KEYS prefix:* 获取前缀获取所有key vals, err := rdb.Keys(ctx, \"prefix*\").Result() // scanKeysDemo1 按前缀查找所有key示例 func scanKeysDemo1() { ctx, cancel := context.WithTimeout(context.Background(), 500*time.Millisecond) defer cancel() var cursor uint64 for { var keys []string var err error // 按前缀扫描key keys, cursor, err = rdb.Scan(ctx, cursor, \"prefix:*\", 0).Result() if err != nil { panic(err) } for _, key := range keys { fmt.Println(\"key\", key) } if cursor == 0 { // no more keys break } } } 简化 // scanKeysDemo2 按前缀扫描key示例 func scanKeysDemo2() { ctx, cancel := context.WithTimeout(context.Background(), 500*time.Millisecond) defer cancel() // 按前缀扫描key iter := rdb.Scan(ctx, 0, \"prefix:*\", 0).Iterator() for iter.Next(ctx) { fmt.Println(\"keys\", iter.Val()) } if err := iter.Err(); err != nil { panic(err) } } 支持将所有匹配指定的模式key删除的示例 // delKeysByMatch 按match格式扫描所有key并删除 func delKeysByMatch(match string, timeout time.Duration) { ctx, cancel := context.WithTimeout(context.Background(), timeout) defer cancel() iter := rdb.Scan(ctx, 0, match, 0).Iterator() for iter.Next(ctx) { err := rdb.Del(ctx, iter.Val()).Err() if err != nil { panic(err) } } if err := iter.Err(); err != nil { panic(err) } } 支持 set 、 hash、zset 数据类型， 遍历 iter := rdb.SScan(ctx, \"set-key\", 0, \"prefix:*\", 0).Iterator() iter := rdb.HScan(ctx, \"hash-key\", 0, \"prefix:*\", 0).Iterator() iter := rdb.ZScan(ctx, \"sorted-hash-key\", 0, \"prefix:*\", 0).Iterator( ","date":"2023-05-23","objectID":"/golang-redis/:6:0","tags":["golang","redis"],"title":"Golang Redis","uri":"/golang-redis/"},{"categories":["文档"],"content":"Pipeline Redis Pipeline 允许通过使用单个 client-server-client 往返执行多个命令来提高性能。区别于一个接一个地执行100个命令，你可以将这些命令放入 pipeline 中，然后使用1次读写操作像执行单个命令一样执行它们。这样做的好处是节省了执行命令的网络往返时间（RTT）。 pipe := rdb.Pipeline() incr := pipe.Incr(ctx, \"pipeline_counter\") pipe.Expire(ctx, \"pipeline_counter\", time.Hour) cmds, err := pipe.Exec(ctx) if err != nil { panic(err) } // 在执行pipe.Exec之后才能获取到结果 fmt.Println(incr.Val()) 使用Pipelined 方法，它会在函数退出时调用 Exec var incr *redis.IntCmd cmds, err := rdb.Pipelined(ctx, func(pipe redis.Pipeliner) error { incr = pipe.Incr(ctx, \"pipelined_counter\") pipe.Expire(ctx, \"pipelined_counter\", time.Hour) return nil }) if err != nil { panic(err) } // 在pipeline执行后获取到结果 fmt.Println(incr.Val()) 遍历 pipeline 命令的返回值依次获取每个命令的结果。下方的示例代码中使用pipiline一次执行了100个 Get 命令，在pipeline 执行后遍历取出100个命令的执行结果。 cmds, err := rdb.Pipelined(ctx, func(pipe redis.Pipeliner) error { for i := 0; i \u003c 100; i++ { pipe.Get(ctx, fmt.Sprintf(\"key%d\", i)) } return nil }) if err != nil { panic(err) } for _, cmd := range cmds { fmt.Println(cmd.(*redis.StringCmd).Val()) } ","date":"2023-05-23","objectID":"/golang-redis/:7:0","tags":["golang","redis"],"title":"Golang Redis","uri":"/golang-redis/"},{"categories":["文档"],"content":"事务 使用 TxPipeline 或 TxPipelined 方法将 pipeline 命令使用 MULTI 和EXEC包裹起来。 // TxPipeline demo pipe := rdb.TxPipeline() incr := pipe.Incr(ctx, \"tx_pipeline_counter\") pipe.Expire(ctx, \"tx_pipeline_counter\", time.Hour) _, err := pipe.Exec(ctx) fmt.Println(incr.Val(), err) // TxPipelined demo var incr2 *redis.IntCmd _, err = rdb.TxPipelined(ctx, func(pipe redis.Pipeliner) error { incr2 = pipe.Incr(ctx, \"tx_pipeline_counter\") pipe.Expire(ctx, \"tx_pipeline_counter\", time.Hour) return nil }) fmt.Println(incr2.Val(), err) ","date":"2023-05-23","objectID":"/golang-redis/:8:0","tags":["golang","redis"],"title":"Golang Redis","uri":"/golang-redis/"},{"categories":["文档"],"content":"Watch 搭配 WATCH命令来执行事务操作。从使用WATCH命令监视某个 key 开始，直到执行EXEC命令的这段时间里，如果有其他用户抢先对被监视的 key 进行了替换、更新、删除等操作，那么当用户尝试执行EXEC的时候，事务将失败并返回一个错误，用户可以根据这个错误选择重试事务或者放弃事务。 Watch方法接收一个函数和一个或多个key作为参数。 Watch(fn func(*Tx) error, keys ...string) error Watch 方法搭配 TxPipelined 的使用示例 // watchDemo 在key值不变的情况下将其值+1 func watchDemo(ctx context.Context, key string) error { return rdb.Watch(ctx, func(tx *redis.Tx) error { n, err := tx.Get(ctx, key).Int() if err != nil \u0026\u0026 err != redis.Nil { return err } // 假设操作耗时5秒 // 5秒内我们通过其他的客户端修改key，当前事务就会失败 time.Sleep(5 * time.Second) _, err = tx.TxPipelined(ctx, func(pipe redis.Pipeliner) error { pipe.Set(ctx, key, n+1, time.Hour) return nil }) return err }, key) } ","date":"2023-05-23","objectID":"/golang-redis/:9:0","tags":["golang","redis"],"title":"Golang Redis","uri":"/golang-redis/"},{"categories":["文档"],"content":"一个 go-redis 官方文档中使用 GET 、SET和WATCH命令实现一个 INCR 命令的完整示例。 const routineCount = 100 increment := func(key string) error { txf := func(tx *redis.Tx) error { // 获得当前值或零值 n, err := tx.Get(key).Int() if err != nil \u0026\u0026 err != redis.Nil { return err } // 实际操作（乐观锁定中的本地操作） n++ // 仅在监视的Key保持不变的情况下运行 _, err = tx.Pipelined(func(pipe redis.Pipeliner) error { // pipe 处理错误情况 pipe.Set(key, n, 0) return nil }) return err } for retries := routineCount; retries \u003e 0; retries-- { err := rdb.Watch(txf, key) if err != redis.TxFailedErr { return err } // 乐观锁丢失 } return errors.New(\"increment reached maximum number of retries\") } var wg sync.WaitGroup wg.Add(routineCount) for i := 0; i \u003c routineCount; i++ { go func() { defer wg.Done() if err := increment(\"counter3\"); err != nil { fmt.Println(\"increment error:\", err) } }() } wg.Wait() n, err := rdb.Get(\"counter3\").Int() fmt.Println(\"ended with\", n, err) 在这个示例中使用了 redis.TxFailedErr 来检查事务是否失败。 参考链接 https://pkg.go.dev/github.com/go-redis/redis https://www.liwenzhou.com/posts/Go/redis/#autoid-1-2-0 ","date":"2023-05-23","objectID":"/golang-redis/:10:0","tags":["golang","redis"],"title":"Golang Redis","uri":"/golang-redis/"},{"categories":["文档"],"content":"sqlx 库的使用 ","date":"2023-05-23","objectID":"/golang-sqlx/:0:0","tags":["golang","mysql"],"title":"Golang Sqlx","uri":"/golang-sqlx/"},{"categories":["文档"],"content":"sqlx 的介绍 sqlx 是内置database/sql 软件包的基础上提供了一组拓展 兼容sql原生包，提供了更加优雅的查询，插入函数 ","date":"2023-05-23","objectID":"/golang-sqlx/:1:0","tags":["golang","mysql"],"title":"Golang Sqlx","uri":"/golang-sqlx/"},{"categories":["文档"],"content":"sqlx 安装 go get github.com/jmoiron/sqlx ","date":"2023-05-23","objectID":"/golang-sqlx/:2:0","tags":["golang","mysql"],"title":"Golang Sqlx","uri":"/golang-sqlx/"},{"categories":["文档"],"content":"连接数据库 var db *sqlx.DB func initDB() (err error) { dsn := \"user:password@tcp(127.0.0.1:3306)/sql_test?charset=utf8mb4\u0026parseTime=True\" // 也可以使用MustConnect连接不成功就panic db, err = sqlx.Connect(\"mysql\", dsn) if err != nil { fmt.Printf(\"connect DB failed, err:%v\\n\", err) return } // 设置与数据库最大的打开连接数 db.SetMaxOpenConns(20) // 设置空闲的最大连接数 db.SetMaxIdleConns(10) return } ","date":"2023-05-23","objectID":"/golang-sqlx/:3:0","tags":["golang","mysql"],"title":"Golang Sqlx","uri":"/golang-sqlx/"},{"categories":["文档"],"content":"查询 查询单行的数据示例 // 查询单条数据示例 func queryRowDemo() { sqlStr := \"select id, name, age from user where id=?\" var u user err := db.Get(\u0026u, sqlStr, 1) if err != nil { fmt.Printf(\"get failed, err:%v\\n\", err) return } fmt.Printf(\"id:%d name:%s age:%d\\n\", u.ID, u.Name, u.Age) } 查询多条数据 // 查询多条数据示例 func queryMultiRowDemo() { sqlStr := \"select id, name, age from user where id \u003e ?\" var users []user err := db.Select(\u0026users, sqlStr, 0) if err != nil { fmt.Printf(\"query failed, err:%v\\n\", err) return } fmt.Printf(\"users:%#v\\n\", users) } ","date":"2023-05-23","objectID":"/golang-sqlx/:4:0","tags":["golang","mysql"],"title":"Golang Sqlx","uri":"/golang-sqlx/"},{"categories":["文档"],"content":"插入、更新和删除 sqlx的exec方法与原生sql中的exec使用一致 插入数据 // 插入数据 func insertRowDemo() { sqlStr := \"insert into user(name, age) values (?,?)\" ret, err := db.Exec(sqlStr, \" 张三\", 18) if err != nil { fmt.Printf(\"insert failed, err:%v\\n\", err) return } theID, err := ret.LastInsertId() // 新插入数据的id if err != nil { fmt.Printf(\"get lastinsert ID failed, err:%v\\n\", err) return } fmt.Printf(\"insert success, the id is %d.\\n\", theID) } 更新数据 // 更新数据 func updateRowDemo() { sqlStr := \"update user set age=? where id = ?\" ret, err := db.Exec(sqlStr, 18, 1) if err != nil { fmt.Printf(\"update failed, err:%v\\n\", err) return } n, err := ret.RowsAffected() // 操作影响的行数 if err != nil { fmt.Printf(\"get RowsAffected failed, err:%v\\n\", err) return } fmt.Printf(\"update success, affected rows:%d\\n\", n) } 删除数据 // 删除数据 func deleteRowDemo() { sqlStr := \"delete from user where id = ?\" ret, err := db.Exec(sqlStr, 6) if err != nil { fmt.Printf(\"delete failed, err:%v\\n\", err) return } n, err := ret.RowsAffected() // 操作影响的行数 if err != nil { fmt.Printf(\"get RowsAffected failed, err:%v\\n\", err) return } fmt.Printf(\"delete success, affected rows:%d\\n\", n) } ","date":"2023-05-23","objectID":"/golang-sqlx/:5:0","tags":["golang","mysql"],"title":"Golang Sqlx","uri":"/golang-sqlx/"},{"categories":["文档"],"content":"NameExec DB.NameExec 方法用来绑定的SQL语句与结构体或map中的同名字段 func insertUserDemo()(err error){ sqlStr := \"INSERT INTO user (name,age) VALUES (:name,:age)\" _, err = db.NamedExec(sqlStr, map[string]interface{}{ \"name\": \"张三\", \"age\": 18, }) return } ","date":"2023-05-23","objectID":"/golang-sqlx/:6:0","tags":["golang","mysql"],"title":"Golang Sqlx","uri":"/golang-sqlx/"},{"categories":["文档"],"content":"NameQuery 使用此数据库进行命名查询。任何命名的占位符参数都被arg中的字段替换。 func namedQuery() { sqlStr := \"SELECT * FROM user WHERE name=:name\" // 使用map做命名查询 rows, err := db.NamedQuery(sqlStr, map[string]interface{}{\"name\": \"张三\"}) if err != nil { fmt.Printf(\"db.NamedQuery failed, err:%v\\n\", err) return } defer rows.Close() for rows.Next() { var u user err := rows.StructScan(\u0026u) if err != nil { fmt.Printf(\"scan failed, err:%v\\n\", err) continue } fmt.Printf(\"user:%#v\\n\", u) } u := user{ Name: \"张三\", } // 使用结构体命名查询，根据结构体字段的 db tag进行映射 rows, err = db.NamedQuery(sqlStr, u) if err != nil { fmt.Printf(\"db.NamedQuery failed, err:%v\\n\", err) return } defer rows.Close() for rows.Next() { var u user err := rows.StructScan(\u0026u) if err != nil { fmt.Printf(\"scan failed, err:%v\\n\", err) continue } fmt.Printf(\"user:%#v\\n\", u) } } ","date":"2023-05-23","objectID":"/golang-sqlx/:7:0","tags":["golang","mysql"],"title":"Golang Sqlx","uri":"/golang-sqlx/"},{"categories":["文档"],"content":"事务操作 对于事物操作， 使用sqlx中提供 db.Begin() 和 tx.Exec() 方法 func transactionDemo2()(err error) { tx, err := db.Beginx() // 开启事务 if err != nil { fmt.Printf(\"begin trans failed, err:%v\\n\", err) return err } defer func() { if p := recover(); p != nil { tx.Rollback() panic(p) // re-throw panic after Rollback } else if err != nil { fmt.Println(\"rollback\") tx.Rollback() // err is non-nil; don't change it } else { err = tx.Commit() // err is nil; if Commit returns error update err fmt.Println(\"commit\") } }() sqlStr1 := \"Update user set age=20 where id=?\" rs, err := tx.Exec(sqlStr1, 1) if err!= nil{ return err } n, err := rs.RowsAffected() if err != nil { return err } if n != 1 { return errors.New(\"exec sqlStr1 failed\") } sqlStr2 := \"Update user set age=50 where i=?\" rs, err = tx.Exec(sqlStr2, 5) if err!=nil{ return err } n, err = rs.RowsAffected() if err != nil { return err } if n != 1 { return errors.New(\"exec sqlStr1 failed\") } return err } ","date":"2023-05-23","objectID":"/golang-sqlx/:8:0","tags":["golang","mysql"],"title":"Golang Sqlx","uri":"/golang-sqlx/"},{"categories":["文档"],"content":"sqlx.In sqlx.In的批量插入示例 创建一个user表 CREATE TABLE `user` ( `id` BIGINT(20) NOT NULL AUTO_INCREMENT, `name` VARCHAR(20) DEFAULT '', `age` INT(11) DEFAULT '0', PRIMARY KEY(`id`) )ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8mb4; ","date":"2023-05-23","objectID":"/golang-sqlx/:9:0","tags":["golang","mysql"],"title":"Golang Sqlx","uri":"/golang-sqlx/"},{"categories":["文档"],"content":"结构体 定义一个结构体 type User struct { Name string `db:\"name\"` Age int `db:\"age\"` } ","date":"2023-05-23","objectID":"/golang-sqlx/:9:1","tags":["golang","mysql"],"title":"Golang Sqlx","uri":"/golang-sqlx/"},{"categories":["文档"],"content":"bingvars (绑定变量) 查询占位符**？**在内部成为 bindvars（查询占位符） MySQL中使用? PostgreSQL使用枚举的$1、$2等bindvar语法 SQLite中?和$1的语法都支持 Oracle中使用:name的语法 ","date":"2023-05-23","objectID":"/golang-sqlx/:9:2","tags":["golang","mysql"],"title":"Golang Sqlx","uri":"/golang-sqlx/"},{"categories":["文档"],"content":"自己拼接语句 // BatchInsertUsers 自行构造批量插入的语句 func BatchInsertUsers(users []*User) error { // 存放 (?, ?) 的slice valueStrings := make([]string, 0, len(users)) // 存放values的slice valueArgs := make([]interface{}, 0, len(users) * 2) // 遍历users准备相关数据 for _, u := range users { // 此处占位符要与插入值的个数对应 valueStrings = append(valueStrings, \"(?, ?)\") valueArgs = append(valueArgs, u.Name) valueArgs = append(valueArgs, u.Age) } // 自行拼接要执行的具体语句 stmt := fmt.Sprintf(\"INSERT INTO user (name, age) VALUES %s\", strings.Join(valueStrings, \",\")) _, err := DB.Exec(stmt, valueArgs...) return err } ","date":"2023-05-23","objectID":"/golang-sqlx/:9:3","tags":["golang","mysql"],"title":"Golang Sqlx","uri":"/golang-sqlx/"},{"categories":["文档"],"content":"使用sqlx.In 实现批量插入 实现结构体 driver.Valuer 接口 func (u User) Value() (driver.Value, error) { return []interface{}{u.Name, u.Age}, nil } // BatchInsertUsers2 使用sqlx.In帮我们拼接语句和参数, 注意传入的参数是[]interface{} func BatchInsertUsers2(users []interface{}) error { query, args, _ := sqlx.In( \"INSERT INTO user (name, age) VALUES (?), (?), (?)\", users..., // 如果arg实现了 driver.Valuer, sqlx.In 会通过调用 Value()来展开它 ) fmt.Println(query) // 查看生成的querystring fmt.Println(args) // 查看生成的args _, err := DB.Exec(query, args...) return err } ","date":"2023-05-23","objectID":"/golang-sqlx/:9:4","tags":["golang","mysql"],"title":"Golang Sqlx","uri":"/golang-sqlx/"},{"categories":["文档"],"content":"使用NamedExec实现批量插入 // BatchInsertUsers3 使用NamedExec实现批量插入 func BatchInsertUsers3(users []*User) error { _, err := DB.NamedExec(\"INSERT INTO user (name, age) VALUES (:name, :age)\", users) return err } ","date":"2023-05-23","objectID":"/golang-sqlx/:9:5","tags":["golang","mysql"],"title":"Golang Sqlx","uri":"/golang-sqlx/"},{"categories":["文档"],"content":"三种方法的示例 func main() { err := initDB() if err != nil { panic(err) } defer DB.Close() u1 := User{Name: \"张三\", Age: 18} u2 := User{Name: \"李四\", Age: 19} u3 := User{Name: \"王五\", Age: 20} // 方法1 users := []*User{\u0026u1, \u0026u2, \u0026u3} err = BatchInsertUsers(users) if err != nil { fmt.Printf(\"BatchInsertUsers failed, err:%v\\n\", err) } // 方法2 users2 := []interface{}{u1, u2, u3} err = BatchInsertUsers2(users2) if err != nil { fmt.Printf(\"BatchInsertUsers2 failed, err:%v\\n\", err) } // 方法3 users3 := []*User{\u0026u1, \u0026u2, \u0026u3} err = BatchInsertUsers3(users3) if err != nil { fmt.Printf(\"BatchInsertUsers3 failed, err:%v\\n\", err) } } ","date":"2023-05-23","objectID":"/golang-sqlx/:10:0","tags":["golang","mysql"],"title":"Golang Sqlx","uri":"/golang-sqlx/"},{"categories":["文档"],"content":"sqlx.in 的查询示例 ","date":"2023-05-23","objectID":"/golang-sqlx/:11:0","tags":["golang","mysql"],"title":"Golang Sqlx","uri":"/golang-sqlx/"},{"categories":["文档"],"content":"in查询 查询id在给定id集合的数据 // QueryByIDs 根据给定ID查询 func QueryByIDs(ids []int)(users []User, err error){ // 动态填充id query, args, err := sqlx.In(\"SELECT name, age FROM user WHERE id IN (?)\", ids) if err != nil { return } // sqlx.In 返回带 `?` bindvar的查询语句, 我们使用Rebind()重新绑定它 query = DB.Rebind(query) err = DB.Select(\u0026users, query, args...) return } ","date":"2023-05-23","objectID":"/golang-sqlx/:11:1","tags":["golang","mysql"],"title":"Golang Sqlx","uri":"/golang-sqlx/"},{"categories":["文档"],"content":"in查询和FIND_IN_SET 函数 查询ID在给定ID集合的数据并维持给定id集合的顺序 // QueryAndOrderByIDs 按照指定id查询并维护顺序 func QueryAndOrderByIDs(ids []int)(users []User, err error){ // 动态填充id strIDs := make([]string, 0, len(ids)) for _, id := range ids { strIDs = append(strIDs, fmt.Sprintf(\"%d\", id)) } query, args, err := sqlx.In(\"SELECT name, age FROM user WHERE id IN (?) ORDER BY FIND_IN_SET(id, ?)\", ids, strings.Join(strIDs, \",\")) if err != nil { return } // sqlx.In 返回带 `?` bindvar的查询语句, 我们使用Rebind()重新绑定它 query = DB.Rebind(query) err = DB.Select(\u0026users, query, args...) return } 参考链接 https://www.liwenzhou.com/posts/Go/sqlx/ https://pkg.go.dev/github.com/jmoiron/sqlx ","date":"2023-05-23","objectID":"/golang-sqlx/:12:0","tags":["golang","mysql"],"title":"Golang Sqlx","uri":"/golang-sqlx/"},{"categories":["文档"],"content":"Go 操作 sql server docker 安装 sqlserver #拉取镜像 docker pull mcr.microsoft.com/azure-sql-edge #启动容器 docker run --name azuresqledge -e 'ACCEPT_EULA=Y' -e 'SA_PASSWORD=yourStrong(!)Password' -d -p 1433:1433 mcr.microsoft.com/azure-sql-edge 连接SQL数据库，要加载目标数据库的驱动，驱动里面包含了与数据库交互的逻辑 sql.Open() 数据库驱动的名称 数据源名称 得到一个指向sql.DB这个struct的指针 sql.DB 时用来操作数据库的，它代码0个或多个底层连接的池，这些连接由sql包来维护，sql包自动的创建和释放这些连接 它对于多个goroutine并发的使用时安全的 package main import ( \"context\" \"database/sql\" \"fmt\" \"log\" _ \"github.com/denisenkom/go-mssqldb\" ) var db *sql.DB const ( server = \"localhost\" port = \"1433\" user = \"sa\" password = \"Password\" database = \"go-db\" ) func main() { connStr := fmt.Sprintf(\"server=%s;user id=%s;password=%s;port=%s;database=%s;\", server, user, password, port, database) db, err := sql.Open(\"sqlserver\", connStr) if err != nil { log.Fatalln(err.Error()) } ctx := context.Background() err = db.PingContext(ctx) if err != nil { log.Fatalln(err.Error()) } fmt.Println(\"Connected!\") } note Open() 函数并不会连接到数据库，甚至不会验证参数，它只是把后续连接到数据库锁必须的struct给设置好 而真正的连接时在被需要的时候才进行懒设置的 sql.DB 不需要进行关闭 它就是用来连接数据库的， 而不是实际的连接 这个抽象保护了数据库连的池， 对此进行维护 使用sql.DB 的时候，可以定义它的全局变量进行使用， 也可以将它传递给函数/方法里 ","date":"2023-05-21","objectID":"/golang-mysql-crud/:0:0","tags":["golang","mysql"],"title":"Golang Mysql CRUD","uri":"/golang-mysql-crud/"},{"categories":["文档"],"content":"如何获取驱动 正常的做法是使用sql.Register() 函数， 数据库驱动的名称和一个实现了driver.Driver 接口的struct， 来注册数据的驱动 sql.Register(“sqlserver”, \u0026drv{}) 为什么例子中没有这句话 因为 sql 驱动， 在这个包别引入的时候进行自我注册 _ \"github.com/denisenkom/go-mssqldb\" ","date":"2023-05-21","objectID":"/golang-mysql-crud/:1:0","tags":["golang","mysql"],"title":"Golang Mysql CRUD","uri":"/golang-mysql-crud/"},{"categories":["文档"],"content":"驱动自我注册 在go-mssqldb包被引入的时候， 它的init函数将会运行并进行自我注册 在引入go-mssqldb 包的时候， 把该包的名称设置为下划线_，这是因为我们不能直接使用数据库驱动 未来升级驱动， 无需改变代码 Go语言没有提供官方的数据库驱动， 所有的数据库驱动都是第三方驱动，都遵循sql.driver包里面定义的接口 ","date":"2023-05-21","objectID":"/golang-mysql-crud/:2:0","tags":["golang","mysql"],"title":"Golang Mysql CRUD","uri":"/golang-mysql-crud/"},{"categories":["文档"],"content":"func (db *DB) PingContext(ctx context.Context) PingContext函数用来验证与数据库的连接是否仍然生效， ，如有必要则建立一个连接 这个韩式需要一个Context（上下文）类型的参数， 这种类型可以携带 截止时间。取消信号和其他请求范围的值，并且可以横跨API边界和进程 上例中， 创建context使用的context.Background()函数， 该函数返回一个非nil的空context，它不会被取消，它没有值，没有截止时间 通常在main函数， 初始化或测试中 作为传入请求的context ","date":"2023-05-21","objectID":"/golang-mysql-crud/:3:0","tags":["golang","mysql"],"title":"Golang Mysql CRUD","uri":"/golang-mysql-crud/"},{"categories":["文档"],"content":"查询 sql.Db 类型用于查询的方法有 Query QueryRow QueryContext QueryRowContext ","date":"2023-05-21","objectID":"/golang-mysql-crud/:4:0","tags":["golang","mysql"],"title":"Golang Mysql CRUD","uri":"/golang-mysql-crud/"},{"categories":["文档"],"content":"Rows 返回类型 type Rows struct { // contains filtered or unexported fields } Rows的方法 func (*Rows) Close error func (rs *Rows) ColumnTypes() ([]*ColumnType, error) func (rs *Rows) Columns() ([]string, error) func (rs *Rows) Err() error func (rs *Rows) Next() bool func (rs *Rows) NextResultSet() bool func (rs *Rows) Scan(dest …any) error ","date":"2023-05-21","objectID":"/golang-mysql-crud/:4:1","tags":["golang","mysql"],"title":"Golang Mysql CRUD","uri":"/golang-mysql-crud/"},{"categories":["文档"],"content":"QueryRow 返回类型是 type Row struct { // contains filtered or unexported fields } Row的方法 func (r *Row) Err() error func (r *Row) Scan(dest …any) error ","date":"2023-05-21","objectID":"/golang-mysql-crud/:4:2","tags":["golang","mysql"],"title":"Golang Mysql CRUD","uri":"/golang-mysql-crud/"},{"categories":["文档"],"content":"单条查询 func getone(id int)(a app,err error) { a = app{} err = db.QueryRow(\"SELECT Id, Name, Status, Level, Order From dbo.App WHERE Id=@Id\", sql.Named(\"Id\", id)). Scan(\u0026a.ID, \u0026a.name, \u0026a.status, \u0026a.level, \u0026a.order) return } ","date":"2023-05-21","objectID":"/golang-mysql-crud/:4:3","tags":["golang","mysql"],"title":"Golang Mysql CRUD","uri":"/golang-mysql-crud/"},{"categories":["文档"],"content":"多条查询 func getMany(id int) (apps []app, err error) { rows, err := db.Query(\"SELECT Id, Name, Status, Level, Order From dbo.App WHERE Id\u003e@Id\", sql.Named(\"Id\", id)) for rows.Next() { a := app{} err = rows.Scan(\u0026a.ID, \u0026a.name, \u0026a.status, \u0026a.level, \u0026a.order) if err != nil { log.Fatalln(err.Error()) } apps = append(apps, a) } return } ","date":"2023-05-21","objectID":"/golang-mysql-crud/:4:4","tags":["golang","mysql"],"title":"Golang Mysql CRUD","uri":"/golang-mysql-crud/"},{"categories":["文档"],"content":"更新 sql.DB 类型上用于更新的方法 Exec ExecContext func (a *app) update() (err error) { _, err = db.Exec(\"UPDATE dbo.App SET Name=@Name, Order=@Order WHERE Id=@Id\", sql.Named(\"Name\", a.name), sql.Named(\"Order\", a.order), sql.Named(\"Id\", a.ID)) if err != nil { log.Fatalln(err.Error()) } return } ","date":"2023-05-21","objectID":"/golang-mysql-crud/:5:0","tags":["golang","mysql"],"title":"Golang Mysql CRUD","uri":"/golang-mysql-crud/"},{"categories":["文档"],"content":"删除 func (a *app) delete() (err error) { _, err = db.Exec(\"DELETE FROM dbo.App WHERE Id=@Id\", sql.Named(\"Id\", a.ID)) if err != nil { log.Fatalln(err.Error()) } return } ","date":"2023-05-21","objectID":"/golang-mysql-crud/:6:0","tags":["golang","mysql"],"title":"Golang Mysql CRUD","uri":"/golang-mysql-crud/"},{"categories":["文档"],"content":"其他 Prepare prepareContext Transactions Begin BeginTx ","date":"2023-05-21","objectID":"/golang-mysql-crud/:7:0","tags":["golang","mysql"],"title":"Golang Mysql CRUD","uri":"/golang-mysql-crud/"},{"categories":["文档"],"content":"Prepare // 预处理查询示例 func prepareQueryDemo() { sqlStr := \"select id, name, age from user where id \u003e ?\" stmt, err := db.Prepare(sqlStr) if err != nil { fmt.Printf(\"prepare failed, err:%v\\n\", err) return } defer stmt.Close() rows, err := stmt.Query(0) if err != nil { fmt.Printf(\"query failed, err:%v\\n\", err) return } defer rows.Close() // 循环读取结果集中的数据 for rows.Next() { var u user err := rows.Scan(\u0026u.id, \u0026u.name, \u0026u.age) if err != nil { fmt.Printf(\"scan failed, err:%v\\n\", err) return } fmt.Printf(\"id:%d name:%s age:%d\\n\", u.id, u.name, u.age) } } ","date":"2023-05-21","objectID":"/golang-mysql-crud/:7:1","tags":["golang","mysql"],"title":"Golang Mysql CRUD","uri":"/golang-mysql-crud/"},{"categories":["文档"],"content":"Transactions // 事务操作示例 func transactionDemo() { tx, err := db.Begin() // 开启事务 if err != nil { if tx != nil { tx.Rollback() // 回滚 } fmt.Printf(\"begin trans failed, err:%v\\n\", err) return } sqlStr1 := \"Update user set age=30 where id=?\" ret1, err := tx.Exec(sqlStr1, 2) if err != nil { tx.Rollback() // 回滚 fmt.Printf(\"exec sql1 failed, err:%v\\n\", err) return } affRow1, err := ret1.RowsAffected() if err != nil { tx.Rollback() // 回滚 fmt.Printf(\"exec ret1.RowsAffected() failed, err:%v\\n\", err) return } sqlStr2 := \"Update user set age=40 where id=?\" ret2, err := tx.Exec(sqlStr2, 3) if err != nil { tx.Rollback() // 回滚 fmt.Printf(\"exec sql2 failed, err:%v\\n\", err) return } affRow2, err := ret2.RowsAffected() if err != nil { tx.Rollback() // 回滚 fmt.Printf(\"exec ret1.RowsAffected() failed, err:%v\\n\", err) return } fmt.Println(affRow1, affRow2) if affRow1 == 1 \u0026\u0026 affRow2 == 1 { fmt.Println(\"事务提交啦...\") tx.Commit() // 提交事务 } else { tx.Rollback() fmt.Println(\"事务回滚啦...\") } fmt.Println(\"exec trans success!\") } ","date":"2023-05-21","objectID":"/golang-mysql-crud/:7:2","tags":["golang","mysql"],"title":"Golang Mysql CRUD","uri":"/golang-mysql-crud/"},{"categories":["文档"],"content":"docker常用命令整理 ","date":"2023-05-21","objectID":"/docker-command/:0:0","tags":["docker"],"title":"Docker Command","uri":"/docker-command/"},{"categories":["文档"],"content":"docker images docker image pull ：下载镜像 docker image ls：列出本地存储的镜像,参数 –digests查看镜像的SHA26签名 docker image inspect:展示镜像细节。包括镜像层数据和元数据。 docker image rm：删除镜像。 docker提供参数 –filter 来过滤docker image ls 命令返回镜像列表的内容 返回悬虚(dangling)镜像 lhf@lhf-virtual-machine:~$ docker image ls --filter dangling=true REPOSITORY TAG IMAGE ID CREATED SIZE \u003cnone\u003e \u003cnone\u003e 没有标签的镜像称为悬虚镜像，列表显示: 使用docker image prune 移除全部悬虚镜像。加-a参数，Docker会额外移除没有被使用的镜像。 ","date":"2023-05-21","objectID":"/docker-command/:1:0","tags":["docker"],"title":"Docker Command","uri":"/docker-command/"},{"categories":["文档"],"content":"docker支持的过滤方式 dangling： 可以指定true或false，返回悬虚镜像(true)和非悬虚镜像(false). before: 需要镜像名称和ID作为参数，返回在之前被创建的镜像 since: before类似，返回需要指定镜像之后创建的全部镜像 label: 根据备注（label）的名称或者值 reference: 过滤标签lastest镜像 lhf@lhf-virtual-machine:~$ docker image ls --filter=reference=\"*:latest\" REPOSITORY TAG IMAGE ID CREATED SIZE test latest e63fd667d16a 2 days ago 71.4MB alpine latest 965ea09ff2eb 4 days ago 5.55MB ubuntu latest cf0f3ca922e0 7 days ago 64.2MB centos latest 0f3e07c0138f 3 weeks ago 220MB 通过–format 参数来通过go模板对输出内容格式化 只返回docker主机上镜像的大小属性 lhf@lhf-virtual-machine:~$ docker image ls --format \"{{.Size}}\" 71.4MB 5.55MB 64.2MB 220MB 只返回显示仓库、标签和大小的信息 lhf@lhf-virtual-machine:~$ docker image ls --format \"{{.Repository}}:{{.Tag}}:{{.Size}}\" test:latest:71.4MB alpine:latest:5.55MB ubuntu:latest:64.2MB centos:latest:220MB ","date":"2023-05-21","objectID":"/docker-command/:1:1","tags":["docker"],"title":"Docker Command","uri":"/docker-command/"},{"categories":["文档"],"content":"通过CLI方式搜索Docker Hub lhf@lhf-virtual-machine:~$ docker search alpine NAME DESCRIPTION STARS OFFICIAL AUTOMATED alpine A minimal Docker image based on Alpine Linux… 5757 [OK] mhart/alpine-node Minimal Node.js built on Alpine Linux 444 anapsix/alpine-java Oracle Java 8 (and 7) with GLIBC 2.28 over A… 427 \u003csnip\u003e lhf@lhf-virtual-machine:~$ docker search alpine --filter \"is-official=true\" NAME DESCRIPTION STARS OFFICIAL AUTOMATED alpine A minimal Docker image based on Alpine Linux… 5757 [OK] 使用参数 –digests 在本地查看镜像摘要 lhf@lhf-virtual-machine:~$ docker image ls --digests alpine REPOSITORY TAG DIGEST IMAGE ID CREATED SIZE alpine latest sha256:c19173c5ada610a5989151111163d28a67368362762534d8a8121ce95cf2bd5a 965ea09ff2eb 4 days ago 5.55MB 删除docker主机的全部镜像 lhf@lhf-virtual-machine:~$ docker image rm $(docker image ls -q) -f ","date":"2023-05-21","objectID":"/docker-command/:1:2","tags":["docker"],"title":"Docker Command","uri":"/docker-command/"},{"categories":["文档"],"content":"docker container docker container run:启动rongq Ctrl-PQ:断开Shell与容器的连接 docker container ls:列出运行状态的容器 docker container exec:允许用户在运行状态的容器，启动一个新的进程。 docker container stop：停止运行中的容器。 docker container start:重启处于停止状态的容器。 docker container rm：删除停止状态的容器。 docker container inspect:显示容器的配置细节和运行时信息。 -it参数： 使当前重点连接到容器的shell终端上 $ docker container run -it ubuntu /bin/bash 快速清理容器 $ docker container rm $(docker container ls -aq) -f ","date":"2023-05-21","objectID":"/docker-command/:2:0","tags":["docker"],"title":"Docker Command","uri":"/docker-command/"},{"categories":["文档"],"content":"docker应用容器化 docker image build ：读取Dockerfile文件,将应用程序容器化 使用-t参数文件镜像打标签 使用-f参数指定任意路径下的Dockerfile Dockerfile中FROM指令，指定构建镜像的一个基础层 Dockerfile中RUN指令，在镜像中执行命令，创建新的镜像层 Dockerfile中COPY指令，将文件作为新的层添加到镜像中 Dockerfile中EXPOSR指令，记录应用所使用的的网络端口 Dockerfile中ENTRYPOINT指令，指定镜像已容器的方式启动后默认运行程序 查看镜像构建执行了那些指令 $ docker image history lhfdocker/web:latest 查看镜像的构建详情 $ docker image inspect lhfdocker/web:latest ","date":"2023-05-21","objectID":"/docker-command/:3:0","tags":["docker"],"title":"Docker Command","uri":"/docker-command/"},{"categories":["文档"],"content":"Docker Compose docker-compose up ：部署一个compose应用。默认读取docker-compose.yml文件，可以使有-f参数指定文件,-d 参数在后台启动 docker-compose stop：停止compose应用的相关容器。可以通过docker-compose restart重新启动 docker-compose rm：删除已停止的compose应用的容器，会删除容器和网络，不会删除卷和镜像。 docker-compose restart 重启compose应用 如果compose应用进行了变更,需要重启才能生效 docker-compose ps:列出compose应用的容器 输出内容包括：状态、容器的运行命令，已经网络端口 docker-compose down:停止并删除运行中compose 的应用。会删除容器和网络，不会删除卷和镜像 ","date":"2023-05-21","objectID":"/docker-command/:4:0","tags":["docker"],"title":"Docker Command","uri":"/docker-command/"},{"categories":["文档"],"content":"docker Swarm docker swarm init 创建一个新的swarm,执行这个命令的节点称为管理节点 docker swarm join-token 查询接入管理节点和工作节点到现有swarm时所使用的命令和Token 增加管理节点——docker swarm join-token manager 增加工作节点——docker swarm join-token work docker node ls 列出swarm所有节点及相关信息 docker service create 创建新服务 docker service ls 列出swarm中运行的服务 docker service ps 获取更多关于服务服务的信息 docker service inspect 获取服务的详细信息 docker service scale 用于对服务副本数量进行增减 docker service update 对运行中的服务进行属性变更 docker service logs 查看服务的日志 docker service rm 从swarm删除服务 ","date":"2023-05-21","objectID":"/docker-command/:5:0","tags":["docker"],"title":"Docker Command","uri":"/docker-command/"},{"categories":["文档"],"content":"docker network docker network ls ：列出运行在本地的docker主机的全部网络 docker network create :创建新的docker网络。默认采用的是bridge 加-d参数指定(网络类型) docker network inspect:提供docker网络的详细配置信息。 docker network prune:删除docker主机上全部未使用的网络。 docker network rm :删除docker主机上指定的网络 ","date":"2023-05-21","objectID":"/docker-command/:6:0","tags":["docker"],"title":"Docker Command","uri":"/docker-command/"},{"categories":["文档"],"content":"docker volume docker volume create ：创建新卷，默认使用的local驱动，加-d参数指定不同驱动 docker volume ls :查看docker主机的全部卷 docker volume inspect: 查看卷的详细信息 docker volume prune ：删除未被容器和服务使用的卷 docker volume rm:删除指定卷 ","date":"2023-05-21","objectID":"/docker-command/:7:0","tags":["docker"],"title":"Docker Command","uri":"/docker-command/"},{"categories":["文档"],"content":"Docker Stack docker stack deploy： 用于根据stack文件部署和更新stack服务 docker stack ls ：列出swarm集群中所有的stack docker stack ps: 列出某个已经部署的stack的相关信息。 docker stack rm：从swarm集群中移除stack ","date":"2023-05-21","objectID":"/docker-command/:8:0","tags":["docker"],"title":"Docker Command","uri":"/docker-command/"},{"categories":["文档"],"content":" Lighthouse (figure) PV、PVC、StorageClass Kubernetes 处理容器持久化存储的核心原理 PV： 持久化存储数据卷 pv 一般有运维人员事先创建之后使用， 定义一个NFS类型的PV apiVersion: v1 kind: PersistentVolume metadata: name: nfs spec: storageClassName: manual capacity: storage: 1Gi accessModes: - ReadWriteMany nfs: server: 10.244.1.4 path: \"/\" PVC： pod所希望使用的持久化存储的属性 一般有开发人员创建， Volume存储的大小，可读写的权限 apiVersion: v1 kind: PersistentVolumeClaim metadata: name: nfs spec: accessModes: - ReadWriteMany storageClassName: manual resources: requests: storage: 1Gi ","date":"2023-05-20","objectID":"/sc-pv-pvc/:0:0","tags":["k8s"],"title":"Kubernets-Sc\u0026Pv\u0026Pvc","uri":"/sc-pv-pvc/"},{"categories":["文档"],"content":"PVC与PV绑定使用的条件 PV和PVC的spec字段，PV的存储大小， 就必须满足PVC的要求 PV 和 PVC 的 storageClassName 字段必须一样 YAML 文件里声明使用这个 PVC 了 apiVersion: v1 kind: Pod metadata: labels: role: web-frontend spec: containers: - name: web image: nginx ports: - name: web containerPort: 80 volumeMounts: - name: nfs mountPath: \"/usr/share/nginx/html\" volumes: - name: nfs persistentVolumeClaim: claimName: nfs ","date":"2023-05-20","objectID":"/sc-pv-pvc/:1:0","tags":["k8s"],"title":"Kubernets-Sc\u0026Pv\u0026Pvc","uri":"/sc-pv-pvc/"},{"categories":["文档"],"content":"PersistentVolumeController 专门处理持久化存储的控制器， 会不断地查看当前每一个 PVC，是不是已经处于 Bound（已绑定）状态。如果不是，那它就会遍历所有的、可用的 PV，并尝试将其与这个“单身”的 PVC 进行绑定 所谓容器的 Volume，其实就是将一个宿主机上的目录，跟一个容器里的目录绑定挂载在了一起 而所谓的“持久化 Volume”，指的就是这个宿主机上的目录，具备“持久性” 这个准备“持久化”宿主机目录的过程，我们可以形象地称为“两阶段处理 一个Pod调度到一个节点上之后， kubelet就要负责这个Pod创建的它的Volume目录，默认这个情况下，kubelet 为 Volume 创建的目录是如下所示的一个宿主机上的路径： /var/lib/kubelet/pods/\u003cPod 的 ID\u003e/volumes/kubernetes.io~\u003cVolume 类型 \u003e/\u003cVolume 名字 \u003e 这一步为虚拟机挂载远程磁盘的操作，对应的正是“两阶段处理”的第一阶段。在 Kubernetes 中，我们把这个阶段称为 Attach 将磁盘设备格式化并挂载到 Volume 宿主机目录的操作，对应的正是“两阶段处理”的第二个阶段，我们一般称为：Mount。 在这一步，kubelet 需要作为 client，将远端 NFS 服务器的目录（比如：“/”目录），挂载到 Volume 的宿主机目录上，即相当于执行如下所示的命令： $ mount -t nfs \u003cNFS 服务器地址 \u003e:/ /var/lib/kubelet/pods/\u003cPod 的 ID\u003e/volumes/kubernetes.io~\u003cVolume 类型 \u003e/\u003cVolume 名字 \u003e kubelet 只要把这个 Volume 目录通过 CRI 里的 Mounts 参数，传递给 Docker，然后就可以为 Pod 里的容器挂载这个“持久化”的 Volume 了。其实，这一步相当于执行了如下所示的命令 $ docker run -v /var/lib/kubelet/pods/\u003cPod 的 ID\u003e/volumes/kubernetes.io~\u003cVolume 类型 \u003e/\u003cVolume 名字 \u003e:/\u003c 容器内的目标目录 \u003e 我的镜像 ... PV 的“两阶段处理”流程，是靠独立于 kubelet 主控制循环（Kubelet Sync Loop）之外的两个控制循环来实现的 StorageClass k8s提供了一套自动创建PV的机制， Dynamic Provisioning storageClass对象的作用， 其实就是创建PV的模板 主要定义两部分 PV的属性， （存储类型， Volume的大小） 创建这种PV需要用到的存储插件， （nfs、Ceph） apiVersion: storage.k8s.io/v1 kind: StorageClass metadata: name: block-service provisioner: kubernetes.io/gce-pd parameters: type: pd-ssd apiVersion: ceph.rook.io/v1beta1 kind: Pool metadata: name: replicapool namespace: rook-ceph spec: replicated: size: 3 --- apiVersion: storage.k8s.io/v1 kind: StorageClass metadata: name: block-service provisioner: ceph.rook.io/block parameters: pool: replicapool #The value of \"clusterNamespace\" MUST be the same as the one in which your rook cluster exist clusterNamespace: rook-ceph Lighthouse (figure) PVC描述的， 是Pod想要使用的持久化存储的属性（存储的大小、读写权限） PV的描述， 一个具体的Volume的属性， （Volume的类型， 挂载目录。 远程存储服务地址） StorageClass 的作用， 充当PV的模板， 只有属于一个StorageClass的PV和PVC才可以绑定子啊一起 ","date":"2023-05-20","objectID":"/sc-pv-pvc/:2:0","tags":["k8s"],"title":"Kubernets-Sc\u0026Pv\u0026Pvc","uri":"/sc-pv-pvc/"},{"categories":["文档"],"content":"Operator 工作原理解读 operator的工作原理和编写方法 ","date":"2023-05-20","objectID":"/operator/:0:0","tags":["k8s"],"title":"Kubernets-Operator","uri":"/operator/"},{"categories":["文档"],"content":"第一步，将这个 Operator 的代码 Clone 到本地： git clone https://github.com/coreos/etcd-operator ","date":"2023-05-20","objectID":"/operator/:0:1","tags":["k8s"],"title":"Kubernets-Operator","uri":"/operator/"},{"categories":["文档"],"content":"第二步，将这个 Etcd Operator 部署在 Kubernetes 集群里 example/rbac/create_role.sh 这个脚本为 Etcd Operator 创建 RBAC 规则， 因为 Etcd Operator 需要访问Kubernetes的APIServer来创建对象 对Pod， service，PVC， Deployment， Secret等API对象， 有所有权限 对CRD对象， 有所有权限 对属于etcd.database.coreos.com 这个 API Group 的 CR（Custom Resource）对象，有所有权限。 Etcd Operator 本身 是一个Deployment apiVersion: extensions/v1beta1 kind: Deployment metadata: name: etcd-operator spec: replicas: 1 template: metadata: labels: name: etcd-operator spec: containers: - name: etcd-operator image: quay.io/coreos/etcd-operator:v0.9.2 command: - etcd-operator env: - name: MY_POD_NAMESPACE valueFrom: fieldRef: fieldPath: metadata.namespace - name: MY_POD_NAME valueFrom: fieldRef: fieldPath: metadata.name 创建 Etcd Operator kubectl create -f example/deployment.yaml pod进入Running 状态， 有一个CRD被自动创建出来 $ kubectl get pods NAME READY STATUS RESTARTS AGE etcd-operator-649dbdb5cb-bzfzp 1/1 Running 0 20s $ kubectl get crd NAME CREATED AT etcdclusters.etcd.database.coreos.com 2018-09-18T11:42:55Z 通过 kubectl describe 命令看到它的细节，如下所示： $ kubectl describe crd etcdclusters.etcd.database.coreos.com ... Group: etcd.database.coreos.com Names: Kind: EtcdCluster List Kind: EtcdClusterList Plural: etcdclusters Short Names: etcd Singular: etcdcluster Scope: Namespaced Version: v1beta2 ... ","date":"2023-05-20","objectID":"/operator/:1:0","tags":["k8s"],"title":"Kubernets-Operator","uri":"/operator/"},{"categories":["文档"],"content":"编写EtcdClutser的Yaml， $ kubectl apply -f example/example-etcd-cluster.yaml 这个 example-etcd-cluster.yaml 文件里描述的，是一个 3 个节点的 Etcd 集群 kubectl get pods NAME READY STATUS RESTARTS AGE example-etcd-cluster-dp8nqtjznc 1/1 Running 0 1m example-etcd-cluster-mbzlg6sd56 1/1 Running 0 2m example-etcd-cluster-v6v6s6stxd 1/1 Running 0 2m apiVersion: \"etcd.database.coreos.com/v1beta2\" kind: \"EtcdCluster\" metadata: name: \"example-etcd-cluster\" spec: size: 3 version: \"3.2.13\" ","date":"2023-05-20","objectID":"/operator/:2:0","tags":["k8s"],"title":"Kubernets-Operator","uri":"/operator/"},{"categories":["文档"],"content":"Operator 的工作原理： 实际上利用了Kubernetes的自定义API资源（CRD），来描述我们想要不熟的“有状态应用”，然后再自定义控制器里， 根据自定义API对象的变化， 来完成具体的部署和运维工作 tcd Operator 在业务逻辑的实现方式上 第一个工作只在该CLuster对象第一次被创建的时候会执行， 这个工作， 就是我们前面提到Bootstrap，即：创建一个单节点的种子集群。 Bootstrap，即：创建一个单节点的种子集群。 ","date":"2023-05-20","objectID":"/operator/:3:0","tags":["k8s"],"title":"Kubernets-Operator","uri":"/operator/"},{"categories":["文档"],"content":"基于角色的权限控制：RBAC 在kubernetes项目中 负责完成授权的（Authorization）工作的记住， 就是RBAC， 基于角色的访问控制（Role-based Access Control） 三个基本概念 Role： 角色，它其实是一组规则， 定义了一组对Kubernetes API对象的操作权限 Subject： 被作用者，即可以是“人”， 也可以是“机器” RoleBinding： 定义了“被作用者”和“角色”的绑定关系 ","date":"2023-05-20","objectID":"/rbac/:0:0","tags":["k8s"],"title":"Kubernets-Rbac","uri":"/rbac/"},{"categories":["文档"],"content":"Role kind: Role apiVersion: rbac.authorization.k8s.io/v1 metadata: namespace: mynamespace name: example-role rules: - apiGroups: [\"\"] resources: [\"pods\"] verbs: [\"get\", \"watch\", \"list\"] ","date":"2023-05-20","objectID":"/rbac/:0:1","tags":["k8s"],"title":"Kubernets-Rbac","uri":"/rbac/"},{"categories":["文档"],"content":"Subject是如何指定的 通过RoleBinding来实现的 kind: RoleBinding apiVersion: rbac.authorization.k8s.io/v1 metadata: name: example-rolebinding namespace: mynamespace subjects: - kind: User name: example-user apiGroup: rbac.authorization.k8s.io roleRef: kind: Role name: example-role apiGroup: rbac.authorization.k8s.io ","date":"2023-05-20","objectID":"/rbac/:1:0","tags":["k8s"],"title":"Kubernets-Rbac","uri":"/rbac/"},{"categories":["文档"],"content":"User是从哪里来的？ kubernetes 的User ， 只是一个授权系统的系统里的逻辑概念。 通过外部认证服务，比如 keystone 直接给APIServer指定一个用户名、密码文件 RoleBinding对象就可以直接通过名字， 来引用前面定义的Role对象， 从而定义了“被作用者（Subject）”和“角色（Role）”之间的绑定关系 ","date":"2023-05-20","objectID":"/rbac/:2:0","tags":["k8s"],"title":"Kubernets-Rbac","uri":"/rbac/"},{"categories":["文档"],"content":"ClusterRole 和 ClusterRolebind kind: ClusterRole apiVersion: rbac.authorization.k8s.io/v1 metadata: name: example-clusterrole rules: - apiGroups: [\"\"] resources: [\"pods\"] verbs: [\"get\", \"watch\", \"list\"] 赋予用户所有权限 verbs: [\"get\", \"list\", \"watch\", \"create\", \"update\", \"patch\", \"delete\"] 针对某一具体对象进行权限设置 rules: - apiGroups: [\"\"] resources: [\"configmaps\"] resourceNames: [\"my-config\"] verbs: [\"get\"] kind: ClusterRoleBinding apiVersion: rbac.authorization.k8s.io/v1 metadata: name: example-clusterrolebinding subjects: - kind: User name: example-user apiGroup: rbac.authorization.k8s.io roleRef: kind: ClusterRole name: example-clusterrole apiGroup: rbac.authorization.k8s.io 这个由 Kubernetes 负责管理的“内置用户”，正是我们前面曾经提到过的：ServiceAccount。 ","date":"2023-05-20","objectID":"/rbac/:3:0","tags":["k8s"],"title":"Kubernets-Rbac","uri":"/rbac/"},{"categories":["文档"],"content":"定义一个ServiceAccount apiVersion: v1 kind: ServiceAccount metadata: namespace: mynamespace name: example-sa 编写RoleBinding的Yaml 文件， 为这个ServiceAccount分配权限 kind: RoleBinding apiVersion: rbac.authorization.k8s.io/v1 metadata: name: example-rolebinding namespace: mynamespace subjects: - kind: ServiceAccount name: example-sa namespace: mynamespace roleRef: kind: Role name: example-role apiGroup: rbac.authorization.k8s.io 创建这个对象 $ kubectl create -f svc-account.yaml $ kubectl create -f role-binding.yaml $ kubectl create -f role.yaml 查看详情 $ kubectl get sa -n mynamespace -o yaml - apiVersion: v1 kind: ServiceAccount metadata: creationTimestamp: 2018-09-08T12:59:17Z name: example-sa namespace: mynamespace resourceVersion: \"409327\" ... secrets: - name: example-sa-token-vmfg6 ","date":"2023-05-20","objectID":"/rbac/:4:0","tags":["k8s"],"title":"Kubernets-Rbac","uri":"/rbac/"},{"categories":["文档"],"content":"声明式API与Kubernetes编码范式 kubectl create 再replace的操作， 称为命令式配置文件操作 声明式API https://hugbz2.51cg3.co/archives/25451 /https://hugbz2.51cg3.co/archives/4081/ kuberctl apply 命令就是 声明式API ","date":"2023-05-20","objectID":"/%E5%A3%B0%E6%98%8E%E5%BC%8Fapi/:0:0","tags":["k8s"],"title":"Kubernets-声明式API","uri":"/%E5%A3%B0%E6%98%8E%E5%BC%8Fapi/"},{"categories":["文档"],"content":"apply 与 replace命令的本质区别 replace： 是使用新的YAML文件中的API对象，替换原来的API对象 apply： 执行了一个对原有的API对象的PATCH操作 对于kube-apiserver在响应命令式请求的时候 replace： 只能处理一个写请求， 否则会有产生冲突的可能 apply： 一次能处理多个写操作， 并且具备Merge能力 Istio Istio最根本的组件， 是运行在每一个应用Pod里的Envoy容器 Istio项目， 代理服务以sidecar容器的方式， 运行在每一个被治理的应用Pod中， Envoy容器就能够通过配置Pod里的iptables规则， 把整个Pod的进出流量接管下来 Istio 的控制层里的Pilot组件，就能够调用每个Envoy容器的API， 对这个Envoy代理进行配置， 从而实现微服务治理。 ","date":"2023-05-20","objectID":"/%E5%A3%B0%E6%98%8E%E5%BC%8Fapi/:0:1","tags":["k8s"],"title":"Kubernets-声明式API","uri":"/%E5%A3%B0%E6%98%8E%E5%BC%8Fapi/"},{"categories":["文档"],"content":"Istio项目使用的， 是kubernetes中一个非常重要的功能Dynamic Adminssion Control Kubernetes 项目为我们额外提供了一种“热插拔”式的 Admission 机制，它就是 Dynamic Admission Control，也叫作：Initializer。 现在，我给你举个例子。比如，我有如下所示的一个应用 Pod： apiVersion: v1 kind: Pod metadata: name: myapp-pod labels: app: myapp spec: containers: - name: myapp-container image: busybox command: ['sh', '-c', 'echo Hello Kubernetes! \u0026\u0026 sleep 3600'] Istio项目要做的， 就是在这个Pod Yaml被提交给kubernetes之后， 它对应的API对象字段加上Envoy容器的配置， apiVersion: v1 kind: Pod metadata: name: myapp-pod labels: app: myapp spec: containers: - name: myapp-container image: busybox command: ['sh', '-c', 'echo Hello Kubernetes! \u0026\u0026 sleep 3600'] - name: envoy image: lyft/envoy:845747b88f102c0fd262ab234308e9e22f693a1 command: [\"/usr/local/bin/envoy\"] ... Istio 要做的，就是编写一个用来为 Pod“自动注入”Envoy 容器的 Initializer。 首先， Istio会将这个Envoy容器本身的定义， 以ConfigMap方式保存在Kubernetes当前 apiVersion: v1 kind: ConfigMap metadata: name: envoy-initializer data: config: | containers: - name: envoy image: lyft/envoy:845747db88f102c0fd262ab234308e9e22f693a1 command: [\"/usr/local/bin/envoy\"] args: - \"--concurrency 4\" - \"--config-path /etc/envoy/envoy.json\" - \"--mode serve\" ports: - containerPort: 80 protocol: TCP resources: limits: cpu: \"1000m\" memory: \"512Mi\" requests: cpu: \"100m\" memory: \"64Mi\" volumeMounts: - name: envoy-conf mountPath: /etc/envoy volumes: - name: envoy-conf configMap: name: envoy Initializer 更新用户的P大对象的时候， 必须使用PATCH API 来完成， 而这种PATCH API 正式声明式API的主要能力 Istio 将一个编写好的Initializer， 作为一个Pod部署在kubernetes中 apiVersion: v1 kind: Pod metadata: labels: app: envoy-initializer name: envoy-initializer spec: containers: - name: envoy-initializer image: envoy-initializer:0.0.1 imagePullPolicy: Always 不断获取“实际状态”， 然后“期望状态”做对比 initializer的控制器， 不断获取的“实际状态”用户新创建的Pod “期望状态” 就是破的被添加的Envoy容器的定义 有了这个 TwoWayMergePatch 之后，Initializer 的代码就可以使用这个 patch 的数据，调用 Kubernetes 的 Client，发起一个 PATCH 请求 Istio项目的核心， 就是由无数个运行在应用Pod中的Envoy容器组成的服务代理网格。 ","date":"2023-05-20","objectID":"/%E5%A3%B0%E6%98%8E%E5%BC%8Fapi/:0:2","tags":["k8s"],"title":"Kubernets-声明式API","uri":"/%E5%A3%B0%E6%98%8E%E5%BC%8Fapi/"},{"categories":["文档"],"content":"kubernetes “声明式API”的独到之处 首先， 所谓“声明式”， 我们定义个定义好的API对象来“声明”， 所期望的状态是什么样子的 其次， “声明式API”允许有多个API写端， 以PATCH的方式对API对象进行修改，而无需关心本地原始的YAML文件的内容 最后， Kubernetes项目才可以基于对API对象的增、删、该、查， 在完全无需外界干扰的情况下， 完成对“实际状态”和“期望状态”的协调过程 ","date":"2023-05-20","objectID":"/%E5%A3%B0%E6%98%8E%E5%BC%8Fapi/:1:0","tags":["k8s"],"title":"Kubernets-声明式API","uri":"/%E5%A3%B0%E6%98%8E%E5%BC%8Fapi/"},{"categories":["文档"],"content":"Kubernetes 编程范式 如何使用控制器模式，同Kubernetes里API对象“增、删、改、查”进行协作，完成用户业务逻辑的编写过程 ","date":"2023-05-20","objectID":"/%E5%A3%B0%E6%98%8E%E5%BC%8Fapi/:2:0","tags":["k8s"],"title":"Kubernets-声明式API","uri":"/%E5%A3%B0%E6%98%8E%E5%BC%8Fapi/"},{"categories":["文档"],"content":"为 Network 这个自定义 API 对象编写一个自定义控制器（Custom Controller） 你好， 监控看到15、16、17这三台机器资源使用率和负载都太不高。 目前现在我们这边资源需求较多，计划3月8号（下周三）回收这3台GPU机器。请知悉。 ","date":"2023-05-20","objectID":"/%E5%A3%B0%E6%98%8E%E5%BC%8Fapi/:3:0","tags":["k8s"],"title":"Kubernets-声明式API","uri":"/%E5%A3%B0%E6%98%8E%E5%BC%8Fapi/"},{"categories":["文档"],"content":"自定义控制器的原理 控制器的工作流程 从kubernetes的APISerer里获取它所关心的对象， 就是自定义的Network informer与API 对象时——对应的， 所以我传递给自定义控制器的， 是Network对象informer Network Informer跟APIServer建立连接， 是informer所使用的Reflector包 Reflector 使用的ListAndWatch的方法，来“获取”并“监听”这些Network对象实例的变化 在ListAndWatch机制下， 一旦APIServer端有新的Network实例被创建、删除或者更新Reflector都会收到“事件通知”， 会放进一个Delta FIFO Queue（增量先进先出队列）中 informe会不断从这个Delta FIFO Queue 读取增量， 每拿到一个增量， informer 判断这个增量的事件类型。 然后创建或者更新本地对象的缓存。（这个缓存在kubernetes里叫Store） informer职责 同步本地缓存的工作 根据这些事件的类型，触发事先注册号的ResourceEventHandler informer 是一个钓友本地缓存和索引机制的 可以注册的EventHandler的client ","date":"2023-05-20","objectID":"/%E5%A3%B0%E6%98%8E%E5%BC%8Fapi/:4:0","tags":["k8s"],"title":"Kubernets-声明式API","uri":"/%E5%A3%B0%E6%98%8E%E5%BC%8Fapi/"},{"categories":["文档"],"content":"Job 与 CronJob ","date":"2023-05-20","objectID":"/job_cronjob/:0:0","tags":["k8s"],"title":"Kubernets-Job_Cronjob","uri":"/job_cronjob/"},{"categories":["文档"],"content":"Job API apiVersion: batch/v1 kind: Job metadata: name: pi spec: template: spec: containers: - name: pi image: resouer/ubuntu-bc command: [\"sh\", \"-c\", \"echo 'scale=10000; 4*a(1)' | bc -l \"] restartPolicy: Never backoffLimit: 4 计算π值的容器。而通过 scale=10000，我指定了输出的小数点后的位数是 10000 ","date":"2023-05-20","objectID":"/job_cronjob/:0:1","tags":["k8s"],"title":"Kubernets-Job_Cronjob","uri":"/job_cronjob/"},{"categories":["文档"],"content":"创建job $ kubectl create -f job.yaml 查看job 对象 $ kubectl describe jobs/pi Name: pi Namespace: default Selector: controller-uid=c2db599a-2c9d-11e6-b324-0209dc45a495 Labels: controller-uid=c2db599a-2c9d-11e6-b324-0209dc45a495 job-name=pi Annotations: \u003cnone\u003e Parallelism: 1 Completions: 1 .. Pods Statuses: 0 Running / 1 Succeeded / 0 Failed Pod Template: Labels: controller-uid=c2db599a-2c9d-11e6-b324-0209dc45a495 job-name=pi Containers: ... Volumes: \u003cnone\u003e Events: FirstSeen LastSeen Count From SubobjectPath Type Reason Message --------- -------- ----- ---- ------------- -------- ------ ------- 1m 1m 1 {job-controller } Normal SuccessfulCreate Created pod: pi-rq5rl pod模板， 会自动加上一个controller-uid= 随机字符串 job对象本身， 也会自动加上label的对应的Selector， 保证job与他所管理的Pod之间的匹配关系 这种自动生成的Label对用户来说并不友好， 所以不太适合推广到Deployment等长作业编排对象上。 事实上， restartPolicy在job对象里只允许被设置为Never 和 OnFailure 而在deployment对象里， restartPolicy则只允许被设置为Always ","date":"2023-05-20","objectID":"/job_cronjob/:0:2","tags":["k8s"],"title":"Kubernets-Job_Cronjob","uri":"/job_cronjob/"},{"categories":["文档"],"content":"查看pod日志 $ kubectl logs pi-rq5rl 3.141592653589793238462643383279... ","date":"2023-05-20","objectID":"/job_cronjob/:0:3","tags":["k8s"],"title":"Kubernets-Job_Cronjob","uri":"/job_cronjob/"},{"categories":["文档"],"content":"离线作业失败了怎么办？ job 定义了 restartPolicy=Never， 那么离线作业失败后 job Controller 就会不断尝试创建一个新的pod 在job对象的spec.backoffLimit字段字段里定义了重试次数为 4（即，backoffLimit=4）， 默认为6 重新创建Pod的间隔是呈指数增加的， 重新创建Pod的发生在 10 s、20 s、40 s 定义 restartPolicy=OnFailure, 那么离线作业失败后， JOb Controller就不会尝试创建新的Pod， 但是会不断尝试重启Pod的容器 在 spec.activeDeadlineSeconds 字段可以设置最长运行时间 spec: backoffLimit: 5 activeDeadlineSeconds: 100 一旦运行了100s, 这个Job的所有Pod都会被终止 你可以在 Pod 的状态里看到终止的原因是 reason: DeadlineExceeded。 ","date":"2023-05-20","objectID":"/job_cronjob/:0:4","tags":["k8s"],"title":"Kubernets-Job_Cronjob","uri":"/job_cronjob/"},{"categories":["文档"],"content":"Job Controller 对并行作业的控制方法 负责控制并行控制的两个参数 spec.parallelism: 定义一个Job在任意时间最多可以启动多少个Pod同事运行 spec.completions: 定义Job至少要完成的Pod数目， 即Job的最小完成数 创建一个参数例子 apiVersion: batch/v1 kind: Job metadata: name: pi spec: parallelism: 2 completions: 4 template: spec: containers: - name: pi image: resouer/ubuntu-bc command: [\"sh\", \"-c\", \"echo 'scale=5000; 4*a(1)' | bc -l \"] restartPolicy: Never backoffLimit: 4 创建job $ kubectl create -f job.yaml 查看job $ kubectl get job NAME DESIRED SUCCESSFUL AGE pi 4 0 3s DESIRED的值 正是completions定义的最小完成数 $ kubectl get pods NAME READY STATUS RESTARTS AGE pi-gmcq5 0/1 Completed 0 40s pi-84ww8 0/1 Pending 0 0s pi-5mt88 0/1 Completed 0 41s pi-62rbt 0/1 Pending 0 0s $ kubectl get pods NAME READY STATUS RESTARTS AGE pi-gmcq5 0/1 Completed 0 40s pi-84ww8 0/1 ContainerCreating 0 0s pi-5mt88 0/1 Completed 0 41s pi-62rbt 0/1 ContainerCreating 0 0s 由于所有Pod均成功退出, job执行完成, 看懂SuCCESSFUL为4 $ kubectl get pods NAME READY STATUS RESTARTS AGE pi-5mt88 0/1 Completed 0 5m pi-62rbt 0/1 Completed 0 4m pi-84ww8 0/1 Completed 0 4m pi-gmcq5 0/1 Completed 0 5m $ kubectl get job NAME DESIRED SUCCESSFUL AGE pi 4 4 5m ","date":"2023-05-20","objectID":"/job_cronjob/:1:0","tags":["k8s"],"title":"Kubernets-Job_Cronjob","uri":"/job_cronjob/"},{"categories":["文档"],"content":"Job Controller的工作原理 首先 job Controller的控制对象直接就是 Pod 其次, job Controller在控制循环中进行的协调操作, 是根据实际的Running状态Pod额数目,已经成功退出的Pod的数目, 以及 parallelism、 conpletions 参数的值共同计算出在这个周期里，应该创建或者删除的Pod数目，然后调用Kubernetes API执行这个操作 ","date":"2023-05-20","objectID":"/job_cronjob/:1:1","tags":["k8s"],"title":"Kubernets-Job_Cronjob","uri":"/job_cronjob/"},{"categories":["文档"],"content":"第一种： 外部管理器+Job模板 apiVersion: batch/v1 kind: Job metadata: name: process-item-$ITEM labels: jobgroup: jobexample spec: template: metadata: name: jobexample labels: jobgroup: jobexample spec: containers: - name: c image: busybox command: [\"sh\", \"-c\", \"echo Processing item $ITEM \u0026\u0026 sleep 5\"] restartPolicy: Never 控制这种 Job 时，我们只要注意如下两个方面即可： 创建 Job 时，替换掉 $ITEM 这样的变量； 所有来自于同一个模板的 Job，都有一个 jobgroup: jobexample 标签，也就是说这一组 Job 使用这样一个相同的标识。 $ mkdir ./jobs $ for i in apple banana cherry do cat job-tmpl.yaml | sed \"s/\\$ITEM/$i/\" \u003e ./jobs/job-$i.yaml done $ kubectl create -f ./jobs $ kubectl get pods -l jobgroup=jobexample NAME READY STATUS RESTARTS AGE process-item-apple-kixwv 0/1 Completed 0 4m process-item-banana-wrsf7 0/1 Completed 0 4m process-item-cherry-dnfu9 0/1 Completed 0 4m ","date":"2023-05-20","objectID":"/job_cronjob/:1:2","tags":["k8s"],"title":"Kubernets-Job_Cronjob","uri":"/job_cronjob/"},{"categories":["文档"],"content":"第二种： 拥有固定任务数目的并行Job apiVersion: batch/v1 kind: Job metadata: name: job-wq-1 spec: completions: 8 parallelism: 2 template: metadata: name: job-wq-1 spec: containers: - name: c image: myrepo/job-wq-1 env: - name: BROKER_URL value: amqp://guest:guest@rabbitmq-service:5672 - name: QUEUE value: job1 restartPolicy: OnFailure ","date":"2023-05-20","objectID":"/job_cronjob/:1:3","tags":["k8s"],"title":"Kubernets-Job_Cronjob","uri":"/job_cronjob/"},{"categories":["文档"],"content":"第三种： 指定并行度（parallelism）， 但不设置固定的completions 这种情况 ， 任务的总数是未知的， 所以不仅需要一个工作队列来负责任务分发， 还需要判断工作列表已经为空。 apiVersion: batch/v1 kind: Job metadata: name: job-wq-2 spec: parallelism: 2 template: metadata: name: job-wq-2 spec: containers: - name: c image: gcr.io/myproject/job-wq-2 env: - name: BROKER_URL value: amqp://guest:guest@rabbitmq-service:5672 - name: QUEUE value: job2 restartPolicy: OnFailure ","date":"2023-05-20","objectID":"/job_cronjob/:1:4","tags":["k8s"],"title":"Kubernets-Job_Cronjob","uri":"/job_cronjob/"},{"categories":["文档"],"content":"CronJob（定时任务） CronJob是一个专门用来管理Job对象的控制器， 它的创建和删除job的依据， 是schedule字段的定义一个标准的Unix Cron格式的表达式。 apiVersion: batch/v1beta1 kind: CronJob metadata: name: hello spec: schedule: \"*/1 * * * *\" jobTemplate: spec: template: spec: containers: - name: hello image: busybox args: - /bin/sh - -c - date; echo Hello from the Kubernetes cluster restartPolicy: OnFailure 由于定时任务的特殊性， 某个job还没有执行完， 另一个新的job就产生了， 通过spec.concurrencyPolicy 字段来定义具体的处理策略 concurrencyPolicy=Allow， 默认情况， 意味着这些job可以同时存在 concurrencyPolicy=Forbid， 意味着不会创建新的pod， 该创建周期被跳过 concurrencyPolicy=Replace， 意味着新产生的job会替换旧的、没有执行完的job 如果某一次 Job 创建失败，这次创建就会被标记为“miss”。当在指定的时间窗口内，miss 的数目达到 100 时，那么 CronJob 会停止再创建这个 Job 这个时间窗口，可以由 spec.startingDeadlineSeconds 字段指定。比如 startingDeadlineSeconds=200，意味着在过去 200 s 里，如果 miss 的数目达到了 100 次，那么这个 Job 就不会被创建执行了。 ","date":"2023-05-20","objectID":"/job_cronjob/:2:0","tags":["k8s"],"title":"Kubernets-Job_Cronjob","uri":"/job_cronjob/"},{"categories":["文档"],"content":"StatefulSet ","date":"2023-05-20","objectID":"/stateful/:0:0","tags":["k8s"],"title":"Kubernets-StatefulSet","uri":"/stateful/"},{"categories":["文档"],"content":"概念 StatefulSet 的设计其实非常容器理解， 它把真实世界里的应用状态， 抽象为两个情况 拓扑状态：这种情况意味着， 应用的多个实例之间不是完全对等的关系， 这些应用实例， 不行按照某些顺序启动，比如应用的主节点A要先于节点B启动， 而如果你把A和B两个Pod删除调， 他们再次被创建出来也必须严格安装这个顺序才行， 并且， 新创建出来的Pod，必须和原理的Pod的网络标识一样， 这样原先的访问者才能使用同样的方法， 访问到这个新Pod。 存储状态：这种情况， 应用的多个实例分别绑定了不同的存储数据， 对于这些应用实例来说，Pod A第一次读取到的数据， 和隔了十分钟之后再次读取到的数据， 应该是同一份，哪怕再次期间Pod A被重新创建过， 这个情况 就是一个数据库应用的多个存储实例 StatefulSet的核心功能， 就是通过某种方式记录这些状态，然后再Pod被重新创建时， 能够为新的Pod恢复这些状态 ","date":"2023-05-20","objectID":"/stateful/:0:1","tags":["k8s"],"title":"Kubernets-StatefulSet","uri":"/stateful/"},{"categories":["文档"],"content":"Headless Service Service的VIP方式：当我访问 10.0.23.1 这个 Service 的 IP 地址时，10.0.23.1 其实就是一个 VIP，它会把请求转发到该 Service 所代理的某一个 Pod 上 **Service的DNS方式：**这时候，只要我访问“my-svc.my-namespace.svc.cluster.local”这条 DNS 记录，就可以访问到名叫 my-svc 的 Service 所代理的某一个 Pod。 Normal Service： 你访问“my-svc.my-namespace.svc.cluster.local”解析到的，正是 my-svc 这个 Service 的 VIP Headless Service： 你访问“my-svc.my-namespace.svc.cluster.local”解析到的，就是my-svc代理的某个Pod的IP地址， 区别在于Headless Service不需要分配一个VIP， 而是直接以DNS记录方式解析出被代理的Pod的IP地址 ","date":"2023-05-20","objectID":"/stateful/:0:2","tags":["k8s"],"title":"Kubernets-StatefulSet","uri":"/stateful/"},{"categories":["文档"],"content":"Headless Service 对应的 YAML 文件： apiVersion: v1 kind: Service metadata: name: nginx labels: app: nginx spec: ports: - port: 80 name: web clusterIP: None selector: app: nginx Headless Service \u003cpod-name\u003e.\u003csvc-name\u003e.\u003cnamespace\u003e.svc.cluster.local ","date":"2023-05-20","objectID":"/stateful/:0:3","tags":["k8s"],"title":"Kubernets-StatefulSet","uri":"/stateful/"},{"categories":["文档"],"content":"StatefulSet 又是如何使用这个DNS记录来维持Pod的拓扑状态的？ apiVersion: apps/v1 kind: StatefulSet metadata: name: web spec: serviceName: \"nginx\" replicas: 2 selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.9.1 ports: - containerPort: 80 name: web serviceName=nginx 字段，告诉 StatefulSet控制器， 在执行控制循环（Control Loop）的时候， 请使用nginx 这个 Headless Service 来保证 Pod 的“可解析身份”。 $ kubectl run -i --tty --image busybox dns-test --restart=Never --rm /bin/sh $ nslookup web-0.nginx Server: 10.0.0.10 Address 1: 10.0.0.10 kube-dns.kube-system.svc.cluster.local Name: web-0.nginx Address 1: 10.244.1.8 $ nslookup web-1.nginx Server: 10.0.0.10 Address 1: 10.0.0.10 kube-dns.kube-system.svc.cluster.local Name: web-1.nginx Address 1: 10.244.2.8 Kubernetes 就是成功地将Pod的拓扑状态（比如：哪个节点先启动，哪个节点后启动），按照 Pod 的“名字 + 编号”的方式固定了下来 ","date":"2023-05-20","objectID":"/stateful/:0:4","tags":["k8s"],"title":"Kubernets-StatefulSet","uri":"/stateful/"},{"categories":["文档"],"content":"总结 StatefulSet 这个控制器主要作用之一： 就是使用Pod模板创建Pod的时候，对他们进行编号， 并且按照编号顺序逐一完成创建工作， 而当StatefulSet 的”控制循环”发现Pod的“实际状态”与“期望状态”不一致， 需要新建或者删除Pod进行 “调谐”的时候，它会严格按照这些 Pod 编号的顺序，逐一完成这些操作。 深入理解StatefulSet（二）：存储状态 ","date":"2023-05-20","objectID":"/stateful/:0:5","tags":["k8s"],"title":"Kubernets-StatefulSet","uri":"/stateful/"},{"categories":["文档"],"content":"工作原理 首信， StatefulSet的控制器直接管理的是Pod， ， 因为StatefulSet里的不同的Pod实例， 不想ReplicaSet中那样都是完全一样的， 而是有了细微区别的， 比如， 每个Pod的hostanme、名字等都是不同的， 携带了标红。 而statefulSet，区分这些实例的方式， 通过在Pod的名字里加上事先约定号的编号。 其次， Kubernetes通过headless ， 为这些有编号的Pod， 在DNS服务器中生成带有同样标红的DNS记录， 只有StatefulSet能够保证这些Pod的名字的编号不变， 那么Service里类似于 web-0.nginx.default.svc.cluster.local 这样的 DNS 记录也就不会变， 而这条记录解析出来的Pod的IP地址， 则会随着后端Pod的删除和再创建而自动更新， 这当然是Service机制本身的能力， 不需要StatefulSet操心 最后， StatefulSet 还为每个Pod分配并创建一个同样编号的PVC，， 这样 kubernetes 就可以通过Persistent Volume 机制为这个PVC绑定上毒药的PV， 从而保证了每个Pode都拥有一个独立的Volume ","date":"2023-05-20","objectID":"/stateful/:0:6","tags":["k8s"],"title":"Kubernets-StatefulSet","uri":"/stateful/"},{"categories":["文档"],"content":"总结 StatefulSet 其实就是一种特殊的 Deployment，而其独特之处在于，它的每个 Pod 都被编号了。而且，这个编号会体现在 Pod 的名字和 hostname 等标识信息上，这不仅代表了 Pod 的创建顺序，也是 Pod 的重要网络标识（即：在整个集群里唯一的、可被的访问身份）。 有了这个编号后，StatefulSet 就使用 Kubernetes 里的两个标准功能：Headless Service 和 PV/PVC，实现了对 Pod 的拓扑状态和存储状态的维护。 ","date":"2023-05-20","objectID":"/stateful/:0:7","tags":["k8s"],"title":"Kubernets-StatefulSet","uri":"/stateful/"},{"categories":["文档"],"content":"DaemonSet ","date":"2023-05-20","objectID":"/daemonset/:0:0","tags":["k8s"],"title":"Kubernets-DaemonSet","uri":"/daemonset/"},{"categories":["文档"],"content":"主要作用 在kubernetes集群里， 运行一个Daemon Pod， 所以， 这个Pod有如下三个特征 这个Pod运载kubernetes集群里的每个节点（Node） 上 每个节点上只有一个这样的Pod实例 当有新的节点加入Kubernetes集群后， 该Pod 会自动的再新节点上被创建出来， 而当节点被删除后， 它上面的Pod也相应会被回收调。 ","date":"2023-05-20","objectID":"/daemonset/:0:1","tags":["k8s"],"title":"Kubernets-DaemonSet","uri":"/daemonset/"},{"categories":["文档"],"content":"Daemon Pod 的例子 各种网络插件的Agent组件， 都必须运行在每个节点上， 用来处理这个节点上的容器网络 各种存储的插件的Agent组件， 也必须运行在每个节点上， 用来在这个节点上挂载远程存储目录，操作容器的Volume目录 各种监控组件和日志组件， 也必须运行在每个节点上，复制这个节点上监控信息和日志搜索 API apiVersion: apps/v1 kind: DaemonSet metadata: name: fluentd-elasticsearch namespace: kube-system labels: k8s-app: fluentd-logging spec: selector: matchLabels: name: fluentd-elasticsearch template: metadata: labels: name: fluentd-elasticsearch spec: tolerations: - key: node-role.kubernetes.io/master effect: NoSchedule containers: - name: fluentd-elasticsearch image: k8s.gcr.io/fluentd-elasticsearch:1.20 resources: limits: memory: 200Mi requests: cpu: 100m memory: 200Mi volumeMounts: - name: varlog mountPath: /var/log - name: varlibdockercontainers mountPath: /var/lib/docker/containers readOnly: true terminationGracePeriodSeconds: 30 volumes: - name: varlog hostPath: path: /var/log - name: varlibdockercontainers hostPath: path: /var/lib/docker/containers ","date":"2023-05-20","objectID":"/daemonset/:0:2","tags":["k8s"],"title":"Kubernets-DaemonSet","uri":"/daemonset/"},{"categories":["文档"],"content":"Daemonset 如何确保每个Node上有且只有一个被管理的Pod？ Daemonset Controller ， 首先从Etcd 里获取所有的Node列表，然后遍历所有的Node， 这时， 它就可以很容器的去检查， 当前这个Node上是不是携带了name=fluentd-elasticsearch 标签的 Pod 在运行。 检查结果有三种情况 没有每种Pod， 那么就意味着这个Node创建这样一个Pod 有这种Pod， 但是数量大于1， 那就说明 多余的Pod从这个Node删除掉 正好只有一个这种Pod， 说明这个节点是正常的 ","date":"2023-05-20","objectID":"/daemonset/:1:0","tags":["k8s"],"title":"Kubernets-DaemonSet","uri":"/daemonset/"},{"categories":["文档"],"content":"nodeAffinity apiVersion: v1 kind: Pod metadata: name: with-node-affinity spec: affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: metadata.name operator: In values: - node-geektime ","date":"2023-05-20","objectID":"/daemonset/:2:0","tags":["k8s"],"title":"Kubernets-DaemonSet","uri":"/daemonset/"},{"categories":["文档"],"content":"含义 requiredDuringSchedulingIgnoredDuringExecution：这个nodeAffunuty 必须在每个调度的时候给予考虑， 同时 意味着可以设置在某个情况下不考虑这个nodeAffinity 这个Pod, 将来只允许允许在“metadata.name是“node-geektime”的节点上 Daemonset Controller 会在创建Pod的时候， 自动在这个Pod的API对象里， 加上这样一个nodeAffinity定义 ","date":"2023-05-20","objectID":"/daemonset/:2:1","tags":["k8s"],"title":"Kubernets-DaemonSet","uri":"/daemonset/"},{"categories":["文档"],"content":"tolerations 这个字段： 意味着这个Pod， 会“容忍”（Toleration）某些Node的污点（Taint） apiVersion: v1 kind: Pod metadata: name: with-toleration spec: tolerations: - key: node.kubernetes.io/unschedulable operator: Exists effect: NoSchedule ","date":"2023-05-20","objectID":"/daemonset/:3:0","tags":["k8s"],"title":"Kubernets-DaemonSet","uri":"/daemonset/"},{"categories":["文档"],"content":"含义 toleration： “容忍”所有被标记为unschedulable“污点”的Node， “容忍”的效果是允许调度 在 Kubernetes 项目中，当一个节点的网络插件尚未安装时，这个节点就会被自动加上名为node.kubernetes.io/network-unavailable的“污点”。 而通过这样一个 Toleration，调度器在调度这个 Pod 的时候，就会忽略当前节点上的“污点”，从而成功地将网络插件的 Agent 组件调度到这台机器上启动起来。 ","date":"2023-05-20","objectID":"/daemonset/:3:1","tags":["k8s"],"title":"Kubernets-DaemonSet","uri":"/daemonset/"},{"categories":["文档"],"content":"Deployment ","date":"2023-05-20","objectID":"/deployment/:0:0","tags":["k8s"],"title":"Kubernets-Deployment","uri":"/deployment/"},{"categories":["文档"],"content":"Deployment Pod 的 “水平扩展、收缩” ","date":"2023-05-20","objectID":"/deployment/:0:1","tags":["k8s"],"title":"Kubernets-Deployment","uri":"/deployment/"},{"categories":["文档"],"content":"ReplicaSet apiVersion: apps/v1 kind: ReplicaSet metadata: name: nginx-set labels: app: nginx spec: replicas: 3 selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.7.9 一个ReplicaSet对象， 其实就是由副本数目的定义和一个Pod模板组合， 更重要的是 Deployment控制器实际操纵的， 正是ReplicasSet对象， 而不是Pod对象 ","date":"2023-05-20","objectID":"/deployment/:0:2","tags":["k8s"],"title":"Kubernets-Deployment","uri":"/deployment/"},{"categories":["文档"],"content":"Deployment apiVersion: apps/v1 kind: Deployment metadata: name: nginx-deployment labels: app: nginx spec: replicas: 3 selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.7.9 ports: - containerPort: 80 ","date":"2023-05-20","objectID":"/deployment/:0:3","tags":["k8s"],"title":"Kubernets-Deployment","uri":"/deployment/"},{"categories":["文档"],"content":"Deployment 、 ReplicaSet、 Pod的关系 ","date":"2023-05-20","objectID":"/deployment/:0:4","tags":["k8s"],"title":"Kubernets-Deployment","uri":"/deployment/"},{"categories":["文档"],"content":"水平扩展、收缩的操作 $ kubectl scale deployment nginx-deployment --replicas=4 deployment.apps/nginx-deployment scaled ","date":"2023-05-20","objectID":"/deployment/:0:5","tags":["k8s"],"title":"Kubernets-Deployment","uri":"/deployment/"},{"categories":["文档"],"content":"滚动更新 $ kubectl create -f nginx-deployment.yaml --record -record 参数： 记录每次操作的执行命令， 方便后面查看 检查一下 nginx-deployment 创建后的状态信息 $ kubectl get deployments NAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGE nginx-deployment 3 0 0 0 1s 状态含义 DESIERD：用户期望的Pod 副本个数 CURRENT：当前处于Running状态的Pod的个数 UP-TO-DATE： 当前处于最新版的Pod的个数， （Pod的Spec部分与Deployment的Pod模板的定义的一致） AVALABLE： 当前已经可用的Pod的个数， 既是 Running 状态，又是最新版本，并且已经处于 Ready（健康检查正确）状态的 Pod 的个数。 查看Deployment对象的状态变化kubectl rollout status $ kubectl rollout status deployment/nginx-deployment Waiting for rollout to finish: 2 out of 3 new replicas have been updated... deployment.apps/nginx-deployment successfully rolled out ","date":"2023-05-20","objectID":"/deployment/:0:6","tags":["k8s"],"title":"Kubernets-Deployment","uri":"/deployment/"},{"categories":["文档"],"content":"Deployment对应进行版本控制的具体原理 这个镜像名字修改成为了一个错误的名字，比如：nginx:1.91。这样，这个 Deployment 就会出现一个升级失败的版本。 $ kubectl set image deployment/nginx-deployment nginx=nginx:1.91 deployment.extensions/nginx-deployment image updated 由于这个 nginx:1.91 镜像在 Docker Hub 中并不存在，所以这个 Deployment 的“滚动更新”被触发后，会立刻报错并停止。 这时，我们来检查一下 ReplicaSet 的状态，如下所示： $ kubectl get rs NAME DESIRED CURRENT READY AGE nginx-deployment-1764197365 2 2 2 24s nginx-deployment-3167673210 0 0 0 35s nginx-deployment-2156724341 2 2 0 7s 回滚到一起的旧版本 $ kubectl rollout undo deployment/nginx-deployment deployment.extensions/nginx-deployment 要使用 kubectl rollout history 命令，查看每次 Deployment 变更对应的版本 $ kubectl rollout history deployment/nginx-deployment deployments \"nginx-deployment\" REVISION CHANGE-CAUSE 1 kubectl create -f nginx-deployment.yaml --record 2 kubectl edit deployment/nginx-deployment 3 kubectl set image deployment/nginx-deployment nginx=nginx:1.91 查看每个版本对应的Deployment的API对象的细节 $ kubectl rollout history deployment/nginx-deployment --revision=2 可以在kubectl roolout undo 命令加上回滚的版本号， 指定版本回滚 $ kubectl rollout undo deployment/nginx-deployment --to-revision=2 deployment.extensions/nginx-deployment 对Deployment的多次更新操作， 最后只生成一个ReplicaSet， $ kubectl rollout pause deployment/nginx-deployment deployment.extensions/nginx-deployment paused 是Deployment进入一个暂定状态， 可以随意使用 kubectl edit 或者 kubectl set image 指令，修改这个 Deployment 的内容了。 操作完成之后将Deployment 恢复回来 $ kubectl rollout resume deploy/nginx-deployment deployment.extensions/nginx-deployment resumed ","date":"2023-05-20","objectID":"/deployment/:0:7","tags":["k8s"],"title":"Kubernets-Deployment","uri":"/deployment/"},{"categories":["文档"],"content":"如何控制“历史的” ReplicaSet数量 Deployment 对象有一个字段，叫作 spec.revisionHistoryLimit，就是 Kubernetes 为 Deployment 保留的“历史版本”个数。所以，如果把它设置为 0，你就再也不能做回滚操作了 ","date":"2023-05-20","objectID":"/deployment/:0:8","tags":["k8s"],"title":"Kubernets-Deployment","uri":"/deployment/"},{"categories":["文档"],"content":"pod ","date":"2023-05-17","objectID":"/pod/:0:0","tags":["k8s"],"title":"Kubernets-Pod","uri":"/pod/"},{"categories":["文档"],"content":"pod 的属性 凡是调度、网络、存储、以及安全相关的属性， 都是pod级别的 ","date":"2023-05-17","objectID":"/pod/:0:1","tags":["k8s"],"title":"Kubernets-Pod","uri":"/pod/"},{"categories":["文档"],"content":"NodeSelector 用户将Pod 与Node进行绑定的字段 apiVersion: v1 kind: Pod ... spec: nodeSelector: disktype: ssd ","date":"2023-05-17","objectID":"/pod/:0:2","tags":["k8s"],"title":"Kubernets-Pod","uri":"/pod/"},{"categories":["文档"],"content":"NodeName 一旦pod 这个字段被赋值， Kubernetes项目就会被认为这个POd以及经过调度， 调度的结果就是复制的节点名字 ","date":"2023-05-17","objectID":"/pod/:0:3","tags":["k8s"],"title":"Kubernets-Pod","uri":"/pod/"},{"categories":["文档"],"content":"HostAliases 定义了Pod的Hosts文件**（比如 /etc/hosts）里的内容**，用法如下： apiVersion: v1 kind: Pod ... spec: hostAliases: - ip: \"10.1.2.3\" hostnames: - \"foo.remote\" - \"bar.remote\" ... pod启动之后、 /etc/hosts 文件内容如下 cat /etc/hosts # Kubernetes-managed hosts file. 127.0.0.1 localhost ... 10.244.135.10 hostaliases-pod 10.1.2.3 foo.remote 10.1.2.3 bar.remote ","date":"2023-05-17","objectID":"/pod/:0:4","tags":["k8s"],"title":"Kubernets-Pod","uri":"/pod/"},{"categories":["文档"],"content":"shareProcessNamespace=true： apiVersion: v1 kind: Pod metadata: name: nginx spec: shareProcessNamespace: true containers: - name: nginx image: nginx - name: shell image: busybox stdin: true tty: true pod 的容器共享 PID Namespace ","date":"2023-05-17","objectID":"/pod/:0:5","tags":["k8s"],"title":"Kubernets-Pod","uri":"/pod/"},{"categories":["文档"],"content":"ImagePullPolicy 默认是Always ，每次都出重新拉取 Never： 意味着Pod永远不会主动拉取这个镜像， IfNotPresent： 只在宿主机不存在这个镜像时才拉取 ","date":"2023-05-17","objectID":"/pod/:0:6","tags":["k8s"],"title":"Kubernets-Pod","uri":"/pod/"},{"categories":["文档"],"content":"lifecycle 在容器发生变化的时候触发一系列“钩子” apiVersion: v1 kind: Pod metadata: name: lifecycle-demo spec: containers: - name: lifecycle-demo-container image: nginx lifecycle: postStart: exec: command: [\"/bin/sh\", \"-c\", \"echo Hello from the postStart handler \u003e /usr/share/message\"] preStop: exec: command: [\"/usr/sbin/nginx\",\"-s\",\"quit\"] ","date":"2023-05-17","objectID":"/pod/:0:7","tags":["k8s"],"title":"Kubernets-Pod","uri":"/pod/"},{"categories":["文档"],"content":"pod对象在kubernetes中的生命周期 Pending：这个状态意味着， Pod的Yaml 文件以及提交给了kubernetes， API对象已经被创建并保存在Etcd 当中， 但是， 这个Pod 里有些容器因为某些原因不能被顺利创建， 比如， 调度不成功 Running： Pod已经调度成功， 跟一个具体的节点绑定，它包含的容器已经被创建，并且至少有一个已经运行成功 Succeeded： Pod的所有容器都运行成功， 并且已经退出， Failed： 这个状态下， Pod 里至少有一个容器以不正常的状态退出， 这个砖头的出现， 意味着你想办法Debug这个容器的应用， unknown： 异常状态， 意味着Pod的状态不能持续的被kubelet汇报给kube-apiserver， 很有可能是主从节点的通信出现了问题 ","date":"2023-05-17","objectID":"/pod/:0:8","tags":["k8s"],"title":"Kubernets-Pod","uri":"/pod/"},{"categories":["文档"],"content":"projected Volume 四种 Secret ConfigMap Downward API ServiceAccountToken ","date":"2023-05-17","objectID":"/pod/:0:9","tags":["k8s"],"title":"Kubernets-Pod","uri":"/pod/"},{"categories":["文档"],"content":"secret 把Pod想要访问的加密数据存在Etcd 中， 可以通过Pod的容器挂载Volume的方式， 访问这些Secret 保存的信息 ","date":"2023-05-17","objectID":"/pod/:0:10","tags":["k8s"],"title":"Kubernets-Pod","uri":"/pod/"},{"categories":["文档"],"content":"configmap 保存的是不需要加密的， 应用所需的配置信息 ","date":"2023-05-17","objectID":"/pod/:0:11","tags":["k8s"],"title":"Kubernets-Pod","uri":"/pod/"},{"categories":["文档"],"content":"Downward API 让Pod里的容器能够直接获取到这个Pod API对象本身的信息 apiVersion: v1 kind: Pod metadata: name: test-downwardapi-volume labels: zone: us-est-coast cluster: test-cluster1 rack: rack-22 spec: containers: - name: client-container image: k8s.gcr.io/busybox command: [\"sh\", \"-c\"] args: - while true; do if [[ -e /etc/podinfo/labels ]]; then echo -en '\\n\\n'; cat /etc/podinfo/labels; fi; sleep 5; done; volumeMounts: - name: podinfo mountPath: /etc/podinfo readOnly: false volumes: - name: podinfo projected: sources: - downwardAPI: items: - path: \"labels\" fieldRef: fieldPath: metadata.labels 支持的字段 spec.nodeName - 宿主机名字 status.hostIP - 宿主机 IP metadata.name - Pod 的名字 metadata.namespace - Pod 的 Namespace status.podIP - Pod 的 IP ","date":"2023-05-17","objectID":"/pod/:0:12","tags":["k8s"],"title":"Kubernets-Pod","uri":"/pod/"},{"categories":["文档"],"content":"Service Account Service Account 对象的作用，就是 Kubernetes 系统内置的一种“服务账户”，它是 Kubernetes 进行权限分配的对象 Service Account 的授权信息和文件，实际上保存在它所绑定的一个特殊的 Secret 对象里的。这个特殊的 Secret 对象，就叫作ServiceAccountToken 这种把 Kubernetes 客户端以容器的方式运行在集群里，然后使用 default Service Account 自动授权的方式，被称作“InClusterConfig”，也是我最推荐的进行 Kubernetes API 编程的授权方式。 ","date":"2023-05-17","objectID":"/pod/:0:13","tags":["k8s"],"title":"Kubernets-Pod","uri":"/pod/"},{"categories":["文档"],"content":"容器的健康检查和恢复机制 容器定义一个监控检查“探针”， kubelet就会根据这个Probe的返回值决定这个容器的状态，而不是直接以容器进行是否运行（来自 Docker 返回的信息）作为依据。这种机制，是生产环境中保证应用健康存活的重要手段。 apiVersion: v1 kind: Pod metadata: labels: test: liveness name: test-liveness-exec spec: containers: - name: liveness image: busybox args: - /bin/sh - -c - touch /tmp/healthy; sleep 30; rm -rf /tmp/healthy; sleep 600 livenessProbe: exec: command: - cat - /tmp/healthy initialDelaySeconds: 5 ## 在容器启动后5s后开始执行 periodSeconds: 5 ## 每5s执行一次 Kubernetes 里的Pod 恢复机制，也叫 restartPolicy ","date":"2023-05-17","objectID":"/pod/:0:14","tags":["k8s"],"title":"Kubernets-Pod","uri":"/pod/"},{"categories":["文档"],"content":"基本原理 只有Pod 的 restartPolicy 指定的策略允许重启的容器， 那么这个Pod就会保持Running状态，并进行容器重启 对于包含多个容器的Pod，只有它里面所有的容器都进入异常状态后，Pod 才会进入 Failed 状态 。在此之前，Pod 都是 Running 状态。此时，Pod 的 READY 字段会显示正常容器的个数 ","date":"2023-05-17","objectID":"/pod/:0:15","tags":["k8s"],"title":"Kubernets-Pod","uri":"/pod/"},{"categories":["文档"],"content":"PodPreset PodPreset里定义的内容， 只会在Pod API对象被创建之前追加这个对象本身上， 而不会影响热河Pod的控制的定义 PodPreset 这样专门用来对 Pod 进行批量化、自动化修改的工具对象 ","date":"2023-05-17","objectID":"/pod/:0:16","tags":["k8s"],"title":"Kubernets-Pod","uri":"/pod/"}]